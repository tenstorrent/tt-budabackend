# git checkout 4d373f6ae
# pytest pybuda/test/model_demos/high_prio/cnn/pytorch/test_yolo_v5.py::test_yolov5_320x320[Wormhole_B0-yolov5n]

devices:
  arch: wormhole_b0

queues:

  # input
  ims_1:                                                                                     {input: HOST, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 800], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x20]]}

  # output
  pt_yolov5n_320x320.output_concatenate_259:                                                 {input: concatenate_259.dc.sparse_matmul.4.lc2_output_nop_0, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [197, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x32c860]]}

  # parameter
  model.model.model.0.conv.weight_0_fork_clone1818:                                          {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40112480], [1, 0x32eab00], [1, 0x400d6180]]}
  model.model.model.0.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32ea2c0], [1, 0x400d5940], [2, 0x2290da0]]}
  model.model.model.0.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40111c40]]}
  model.model.model.0.conv.weight_0_fork_clone1816:                                          {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e9a80], [1, 0x400d5100], [2, 0x2290560]]}
  model.model.model.1.conv.weight_0_fork_clone430:                                           {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40110bc0], [1, 0x32e9240], [1, 0x400d48c0]]}
  model.model.model.1.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e8a00], [1, 0x400d4080], [2, 0x228ece0]]}
  model.model.model.1.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40110380]]}
  model.model.model.1.conv.weight_0_fork_clone428:                                           {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e81c0], [1, 0x400d3840], [2, 0x228e4a0]]}
  model.model.model.2.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2293ee0]]}
  model.model.model.2.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400d8280]]}
  model.model.model.2.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22d82c0]]}
  model.model.model.2.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400c4620]]}
  model.model.model.2.m.0.cv2.conv.weight_0_fork_clone488:                                   {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40113d40], [1, 0x32ec3c0], [1, 0x400d7a40]]}
  model.model.model.2.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32ebb80], [1, 0x400d7200], [2, 0x2292e60]]}
  model.model.model.2.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40113500]]}
  model.model.model.2.m.0.cv2.conv.weight_0_fork_clone486:                                   {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32eb340], [1, 0x400d69c0], [2, 0x2292620]]}
  model.model.model.2.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22d08e0]]}
  model.model.model.2.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3375360]]}
  model.model.model.2.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400c72a0]]}
  model.model.model.2.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2289300]]}
  model.model.model.3.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [9, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3370a20], [5, 0x400b51c0]]}
  model.model.model.3.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d06dc0], [4, 0x400d3760]]}
  model.model.model.4.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22882a0]]}
  model.model.model.4.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400d1740]]}
  model.model.model.4.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22cdb60]]}
  model.model.model.4.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400b4980]]}
  model.model.model.4.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [9, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d08680]]}
  model.model.model.4.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400b9f80]]}
  model.model.model.4.m.1.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x228dc60]]}
  model.model.model.4.m.1.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400d3000]]}
  model.model.model.4.m.1.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [9, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400d47e0]]}
  model.model.model.4.m.1.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d07e40]]}
  model.model.model.4.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400c7ae0]]}
  model.model.model.4.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22936a0]]}
  model.model.model.4.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4010d260]]}
  model.model.model.4.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40119e80]]}
  model.model.model.5.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40145a80], [1, 0x332b460]]}
  model.model.model.5.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4012f0c0]]}
  model.model.model.6.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33a0b20]]}
  model.model.model.6.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4010eb00]]}
  model.model.model.6.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6d0f460]]}
  model.model.model.6.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3327320]]}
  model.model.model.6.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [3, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22c4360], [2, 0x400e6f20]]}
  model.model.model.6.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40120d00]]}
  model.model.model.6.m.1.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40131500]]}
  model.model.model.6.m.1.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6d1e860]]}
  model.model.model.6.m.1.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [3, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4010fb60], [5, 0x33a4c40]]}
  model.model.model.6.m.1.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x401304a0]]}
  model.model.model.6.m.2.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40118dc0]]}
  model.model.model.6.m.2.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x338c8e0]]}
  model.model.model.6.m.2.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [3, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4011af60], [1, 0x3307ae0]]}
  model.model.model.6.m.2.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22deb60]]}
  model.model.model.6.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6cf0fa0]]}
  model.model.model.6.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d5ef60]]}
  model.model.model.6.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400d2d00]]}
  model.model.model.6.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2294720]]}
  model.model.model.7.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [9, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400c3900], [4, 0x6d15d40]]}
  model.model.model.7.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400e1ac0]]}
  model.model.model.8.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d79660], [4, 0x400ff280]]}
  model.model.model.8.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40120060]]}
  model.model.model.8.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40138700], [1, 0x3323200]]}
  model.model.model.8.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22e5ca0]]}
  model.model.model.8.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [6, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400f82c0], [2, 0x229b920]]}
  model.model.model.8.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3321160]]}
  model.model.model.8.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d6d320], [4, 0x400f2f40]]}
  model.model.model.8.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4011aee0]]}
  model.model.model.8.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401241c0], [1, 0x3310d40]]}
  model.model.model.8.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2289b40]]}
  model.model.model.9.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c812c0], [4, 0x4006b3a0]]}
  model.model.model.9.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400618c0]]}
  model.model.model.9.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [2, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21de980], [0, 0x40054e00]]}
  model.model.model.9.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4003c2e0]]}
  model.model.model.10.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40050c80], [3, 0x6c71a40]]}
  model.model.model.10.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x21f8c20]]}
  model.model.model.13.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4006b040]]}
  model.model.model.13.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x329ace0]]}
  model.model.model.13.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4005b5c0]]}
  model.model.model.13.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32cd960]]}
  model.model.model.13.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [3, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3291a80], [1, 0x40061de0]]}
  model.model.model.13.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4007e0a0]]}
  model.model.model.13.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32c5740]]}
  model.model.model.13.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400735c0]]}
  model.model.model.13.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c7edc0]]}
  model.model.model.13.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40051180]]}
  model.model.model.14.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21a1180]]}
  model.model.model.14.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40000840]]}
  model.model.model.17.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40004940], [2, 0x21a1140]]}
  model.model.model.17.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3250940]]}
  model.model.model.17.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40000000]]}
  model.model.model.17.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3250100]]}
  model.model.model.17.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [9, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40000000]]}
  model.model.model.17.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3250100]]}
  model.model.model.17.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c713c0]]}
  model.model.model.17.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40053220]]}
  model.model.model.17.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x21f6b80]]}
  model.model.model.17.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4005a380]]}
  model.model.model.24.m.0.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [2, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32aa560], [5, 0x40036620]]}
  model.model.model.24.m.0.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c6f320], [4, 0x4005a460]]}
  model.model.model.18.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [3, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x21fc560], [2, 0x4005e000]]}
  model.model.model.18.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4008fc60]]}
  model.model.model.20.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32c2780]]}
  model.model.model.20.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400b7fe0]]}
  model.model.model.20.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3346180]]}
  model.model.model.20.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400a9700]]}
  model.model.model.20.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [3, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22899e0], [0, 0x400aed80]]}
  model.model.model.20.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40071840]]}
  model.model.model.20.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6ccc940]]}
  model.model.model.20.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4008e7c0]]}
  model.model.model.20.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400b0080]]}
  model.model.model.20.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6ce34c0]]}
  model.model.model.24.m.1.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400c1320]]}
  model.model.model.24.m.1.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e1fa0]]}
  model.model.model.21.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [18, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x222b200]]}
  model.model.model.21.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4005e6a0]]}
  model.model.model.23.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cabdc0]]}
  model.model.model.23.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4007bfc0]]}
  model.model.model.23.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2221f00]]}
  model.model.model.23.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x221fe60]]}
  model.model.model.23.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [18, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32ce9c0]]}
  model.model.model.23.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40081980]]}
  model.model.model.23.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c89d60]]}
  model.model.model.23.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40069fe0]]}
  model.model.model.23.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400a6b60], [1, 0x32b9520], [1, 0x4008ffa0], [2, 0x223ab40]]}
  model.model.model.23.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22858c0]]}
  model.model.model.24.m.2.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x227d6a0], [0, 0x4009e940], [1, 0x32b1300], [1, 0x40087d80]]}
  model.model.model.24.m.2.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40069600]]}

  # constant
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 6], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x40075620], [1, 0x32901e0], [1, 0x40060540], [2, 0x21fbd00]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x22915e0], [2, 0x400ce4c0], [3, 0x6cecfa0], [3, 0x400bf900]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 6], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x400dcf40], [5, 0x337aa00], [5, 0x400c1320], [0, 0x22d57c0]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400cd480], [3, 0x6cebf60], [3, 0x400be8c0], [4, 0x6d10d00]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 6], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x400dc6e0], [5, 0x337a1a0], [5, 0x400c0ac0], [0, 0x22d4f60]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400cc440], [3, 0x6ceaf20], [3, 0x400bd880], [4, 0x6d0fcc0]]}
  dc.input_tensor.sigmoid_1.0:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40111400]]}
  dc.input_tensor.sigmoid_1.1:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4010fb40]]}
  lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x6d0f040], [4, 0x400dba60], [5, 0x3379520], [5, 0x400bfe40]]}
  lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x228f520], [2, 0x400cb400], [3, 0x6ce9ee0], [3, 0x400bc840]]}
  lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x400dade0], [5, 0x33788a0], [5, 0x400bf1c0], [0, 0x22d3aa0]]}
  lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400ca3c0], [3, 0x6ce8ea0], [3, 0x400bb800], [4, 0x6d0e000]]}
  lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x400da160], [5, 0x3377c20], [5, 0x400be540], [0, 0x22d2e20]]}
  lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400c9380], [3, 0x6ce7e60], [3, 0x400ba7c0], [4, 0x6d0cfc0]]}
  dc.input_tensor.sigmoid_4.0:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22d4720]]}
  dc.input_tensor.sigmoid_4.1:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400d24c0]]}
  dc.input_tensor.sigmoid_7.0:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32ecc00]]}
  dc.input_tensor.sigmoid_7.1:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40114580]]}
  dc.input_tensor.sigmoid_10.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x337dd00]]}
  dc.input_tensor.sigmoid_10.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400e0240]]}
  lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 11], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x400d1580], [3, 0x6cf0060], [3, 0x400c29c0], [4, 0x6d14e00]]}
  lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x6d11d40], [4, 0x400dd7a0], [5, 0x337b260], [5, 0x400c1b80]]}
  lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 11], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x400df300], [5, 0x337cdc0], [5, 0x400c36e0], [0, 0x22d7380]]}
  lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400d0540], [3, 0x6cef020], [3, 0x400c1980], [4, 0x6d13dc0]]}
  lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 8], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x400de7e0], [5, 0x337c2a0], [5, 0x400c2bc0], [0, 0x22d6860]]}
  lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400cf500], [3, 0x6cedfe0], [3, 0x400c0940], [4, 0x6d12d80]]}
  dc.input_tensor.sigmoid_13.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40112cc0]]}
  dc.input_tensor.sigmoid_13.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22d6020]]}
  dc.input_tensor.sigmoid_17.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400d3fa0]]}
  dc.input_tensor.sigmoid_17.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d07600]]}
  lc.input_tensor.concatenate_19.dc.sparse_matmul.5.0:                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x400b9300]]}
  lc.input_tensor.concatenate_19.dc.sparse_matmul.5.1:                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x6ce5da0]]}
  dc.input_tensor.sigmoid_21.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400d1f80]]}
  dc.input_tensor.sigmoid_21.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e6900]]}
  lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 39], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x40109ca0]]}
  lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x400d2720]]}
  dc.input_tensor.sigmoid_24.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400b82a0]]}
  dc.input_tensor.sigmoid_24.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400c6a60], [3, 0x6ce5560]]}
  dc.input_tensor.sigmoid_27.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e60c0]]}
  dc.input_tensor.sigmoid_27.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40109460]]}
  dc.input_tensor.sigmoid_30.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33701e0]]}
  dc.input_tensor.sigmoid_30.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22ce3a0]]}
  lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x400bc840], [0, 0x22d1120]]}
  lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x400d9120], [5, 0x3376be0]]}
  dc.input_tensor.sigmoid_33.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6ce7620]]}
  dc.input_tensor.sigmoid_33.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400c8b40]]}
  dc.input_tensor.sigmoid_37.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e7980]]}
  dc.input_tensor.sigmoid_37.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4010f300]]}
  lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x400b9b00], [0, 0x22cebe0]]}
  lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x3375ba0], [5, 0x400bb800]]}
  dc.input_tensor.sigmoid_40.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400b9740]]}
  dc.input_tensor.sigmoid_40.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6ce6de0]]}
  dc.input_tensor.sigmoid_44.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400d27c0]]}
  dc.input_tensor.sigmoid_44.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32e7140]]}
  dc.input_tensor.sigmoid_48.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40107a60]]}
  dc.input_tensor.sigmoid_48.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x230b640]]}
  lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 86], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x6d81880], [4, 0x401074a0]]}
  lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x22eff60], [0, 0x40144a40]]}
  dc.input_tensor.sigmoid_51.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22f0fa0]]}
  dc.input_tensor.sigmoid_51.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400ed3c0]]}
  dc.input_tensor.sigmoid_54.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d88ee0]]}
  dc.input_tensor.sigmoid_54.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40123140]]}
  dc.input_tensor.sigmoid_57.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22cd5c0]]}
  dc.input_tensor.sigmoid_57.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40121d60]]}
  dc.input_tensor.conv2d_59.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3328380]]}
  lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 33], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x339dda0], [5, 0x400ea640]]}
  lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x6d0e420], [3, 0x40122100]]}
  dc.input_tensor.sigmoid_60.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400f0180]]}
  dc.input_tensor.sigmoid_60.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6da35a0]]}
  dc.input_tensor.sigmoid_64.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40100260]]}
  dc.input_tensor.sigmoid_64.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22dd6a0]]}
  dc.input_tensor.conv2d_66.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40131160]]}
  lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 33], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x22da920], [2, 0x400fd4e0]]}
  lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x40157f20], [1, 0x333d900]]}
  dc.input_tensor.sigmoid_67.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6d11500]]}
  dc.input_tensor.sigmoid_67.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d96240]]}
  dc.input_tensor.sigmoid_71.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400e5be0]]}
  dc.input_tensor.sigmoid_71.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d5ffc0]]}
  dc.input_tensor.conv2d_73.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4011cf80]]}
  lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 33], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x400daf20], [3, 0x6d02420]]}
  lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400f3160], [2, 0x22967c0]]}
  dc.input_tensor.sigmoid_74.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400caec0]]}
  dc.input_tensor.sigmoid_74.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x337f580]]}
  dc.input_tensor.sigmoid_78.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4010cb20]]}
  dc.input_tensor.sigmoid_78.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6cf50c0]]}
  dc.input_tensor.sigmoid_82.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400d8ac0]]}
  dc.input_tensor.sigmoid_82.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32ed440]]}
  dc.input_tensor.conv2d_84.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40114dc0]]}
  lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 70], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x400c4e60], [0, 0x22d8b00]]}
  lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x400e0a80], [5, 0x337e540]]}
  dc.input_tensor.sigmoid_85.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22e7d40], [0, 0x4013c820]]}
  dc.input_tensor.sigmoid_85.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3395b80], [5, 0x400e2420]]}
  dc.input_tensor.sigmoid_88.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400e2e00], [3, 0x6d0a300]]}
  dc.input_tensor.sigmoid_88.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4011cbe0], [2, 0x22c0240]]}
  dc.input_tensor.sigmoid_91.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3391a60], [5, 0x400de300]]}
  dc.input_tensor.sigmoid_91.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d75540], [4, 0x400fb160]]}
  lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 23], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x400d8220], [0, 0x22dfbc0]]}
  lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400e1dc0], [3, 0x6d092c0]]}
  dc.input_tensor.sigmoid_94.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22e1b80], [0, 0x401345e0]]}
  dc.input_tensor.sigmoid_94.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x338d940], [5, 0x400da1e0]]}
  dc.input_tensor.sigmoid_98.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400ddca0], [3, 0x6d051a0]]}
  dc.input_tensor.sigmoid_98.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400f41a0], [2, 0x2297800]]}
  dc.input_tensor.sigmoid_102.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2204de0], [0, 0x40075e80]]}
  dc.input_tensor.sigmoid_102.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32bd520], [5, 0x40046040]]}
  dc.input_tensor.sigmoid_105.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40059ee0], [3, 0x6c7aca0]]}
  dc.input_tensor.sigmoid_105.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6cc3ca0], [3, 0x4009cb80]]}
  lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.0:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 67], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x40040400], [0, 0x21ff1a0]]}
  lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.1:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x4006a360], [5, 0x32bc4e0]]}
  lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.0:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 67], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x4005bc80], [4, 0x6c7b680]]}
  lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.1:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x40058ea0], [3, 0x6c79c60]]}
  lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.0:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 67], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x4005c500], [5, 0x32ae680]]}
  lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.1:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x328f1a0], [1, 0x4005f500]]}
  dc.input_tensor.sigmoid_112.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40062140], [5, 0x32b42c0]]}
  dc.input_tensor.sigmoid_112.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40053a60], [4, 0x6c73460]]}
  dc.input_tensor.sigmoid_115.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x328b080], [1, 0x4005b3e0]]}
  dc.input_tensor.sigmoid_115.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21da860], [0, 0x40050ce0]]}
  lc.input_tensor.resize2d_117.dc.sparse_matmul.3.0:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 20], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x4003a740]]}
  lc.input_tensor.resize2d_117.dc.sparse_matmul.3.1:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x21facc0]]}
  dc.input_tensor.sigmoid_120.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4007f100]]}
  dc.input_tensor.sigmoid_120.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x221a360]]}
  dc.input_tensor.sigmoid_123.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40074620]]}
  dc.input_tensor.sigmoid_123.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c96840]]}
  dc.input_tensor.conv2d_125.dc.pad.8.0:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40070cc0]]}
  lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 33], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x40067260], [3, 0x6c86fe0]]}
  lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x3290a40], [1, 0x40060da0]]}
  dc.input_tensor.sigmoid_126.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x220d000]]}
  dc.input_tensor.sigmoid_126.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4004e260]]}
  dc.input_tensor.sigmoid_129.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c894e0]]}
  dc.input_tensor.sigmoid_129.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40063960]]}
  dc.input_tensor.sigmoid_133.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22057c0]]}
  dc.input_tensor.sigmoid_133.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40001080]]}
  dc.input_tensor.sigmoid_136.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3250940]]}
  dc.input_tensor.sigmoid_136.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40000840]]}
  lc.input_tensor.resize2d_138.dc.sparse_matmul.3.0:                                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 24], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x40001d00], [4, 0x6c20940]]}
  lc.input_tensor.resize2d_138.dc.sparse_matmul.3.1:                                         {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x40001040], [3, 0x6c21e00]]}
  dc.input_tensor.sigmoid_141.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21a0100]]}
  dc.input_tensor.sigmoid_141.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21a0940]]}
  dc.input_tensor.sigmoid_144.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40000000]]}
  dc.input_tensor.sigmoid_144.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c20100]]}
  lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x6c20100], [3, 0x40000000]]}
  lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x21a0100], [2, 0x40000000]]}
  dc.input_tensor.sigmoid_147.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40000000]]}
  dc.input_tensor.sigmoid_147.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40000840]]}
  dc.input_tensor.sigmoid_150.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c71200]]}
  dc.input_tensor.sigmoid_150.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40050440]]}
  dc.input_tensor.sigmoid_154.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x328a020]]}
  dc.input_tensor.sigmoid_154.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21da020], [0, 0x400504a0]]}
  dc.input_tensor.sigmoid_157.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [8, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3251180]]}
  dc.input_tensor.sigmoid_157.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40059320], [2, 0x21f5b20], [2, 0x4004f3e0], [3, 0x6c701a0]]}
  input_1_multiply_158:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400355c0], [0, 0x21d8fc0], [0, 0x4004f440], [1, 0x3288fc0]]}
  input_2_concatenate_160:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4003fcc0], [2, 0x21dc4c0], [2, 0x40035d80], [3, 0x6c56b40], [3, 0x40037b20], [4, 0x6c55cc0], [4, 0x40040e00], [5, 0x3290f00]]}
  input_1_multiply_164:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40034560], [0, 0x21d7f60], [0, 0x4004e3e0], [1, 0x3287f60]]}
  input_1_concatenate_165:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40026660], [2, 0x21c2e60], [2, 0x4001c720], [3, 0x6c3d4e0], [3, 0x4001e4c0], [4, 0x6c3c660], [4, 0x400277a0], [5, 0x32778a0]]}
  input_1_multiply_168:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40004e60], [4, 0x6c23000], [4, 0x4000e140], [5, 0x325e240], [5, 0x4001af00], [0, 0x21be900], [0, 0x40034d80], [1, 0x326e900]]}
  input_1_multiply_171:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400018a0], [0, 0x21a52a0], [0, 0x4001b720], [1, 0x32552a0], [1, 0x4000d000], [2, 0x21a9800], [2, 0x400030c0], [3, 0x6c23e80]]}
  lc.input_tensor.reshape_174.dc.sparse_matmul.3.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 4], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x6c22a60], [4, 0x4000dba0], [5, 0x325dca0]]}
  lc.input_tensor.reshape_174.dc.sparse_matmul.3.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x40002080], [3, 0x6c22e40], [3, 0x40003e20]]}
  lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 86], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x400059a0], [2, 0x21a21a0]]}
  lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x400af040], [4, 0x6cf8a20]]}
  dc.input_tensor.sigmoid_178.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2245ae0]]}
  dc.input_tensor.sigmoid_178.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40099200]]}
  dc.input_tensor.sigmoid_182.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2292c40]]}
  dc.input_tensor.sigmoid_182.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400728a0]]}
  dc.input_tensor.sigmoid_185.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6cb3860]]}
  dc.input_tensor.sigmoid_185.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4008f820]]}
  dc.input_tensor.conv2d_187.dc.pad.8.0:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6cc0bc0]]}
  lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 33], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2242d60], [2, 0x4008cee0]]}
  lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x32c1740], [1, 0x400981c0]]}
  dc.input_tensor.sigmoid_188.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3338e20]]}
  dc.input_tensor.sigmoid_188.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4009c3a0]]}
  dc.input_tensor.sigmoid_191.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cd0a60]]}
  dc.input_tensor.sigmoid_191.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cf9a60]]}
  dc.input_tensor.sigmoid_195.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400ac3c0]]}
  dc.input_tensor.sigmoid_195.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x226dc00]]}
  dc.input_tensor.sigmoid_198.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400d4740]]}
  dc.input_tensor.sigmoid_198.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400c53c0], [5, 0x3362e80], [5, 0x400a7620], [0, 0x22c0800]]}
  input_1_multiply_199:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cdddc0], [4, 0x400aa760], [5, 0x3348220], [5, 0x4007fc00]]}
  input_2_concatenate_201:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400b3fc0], [2, 0x22608a0], [2, 0x4009f060], [3, 0x6cd6160]]}
  input_1_multiply_205:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4009a2c0], [0, 0x22b34a0], [0, 0x400c73e0], [1, 0x32d4c40]]}
  input_1_concatenate_206:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400a1ce0], [4, 0x6ceb6c0], [4, 0x400b8060], [5, 0x3355b20]]}
  input_1_multiply_209:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400a6c60], [2, 0x2253540], [2, 0x40091d00], [3, 0x6cc8e00]]}
  input_1_multiply_212:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4008cf60], [0, 0x22a6140], [0, 0x400ba080], [1, 0x32c78e0]]}
  lc.input_tensor.reshape_215.dc.sparse_matmul.3.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 4], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x6ceb120], [4, 0x400b7ac0], [5, 0x3355580]]}
  lc.input_tensor.reshape_215.dc.sparse_matmul.3.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x40090cc0], [3, 0x6cc7dc0], [3, 0x400a0ca0]]}
  lc.input_tensor.reshape_217.dc.sparse_matmul.4.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x400a6560], [2, 0x2252e40]]}
  lc.input_tensor.reshape_217.dc.sparse_matmul.4.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x400b9040], [1, 0x32c68a0]]}
  dc.input_tensor.conv2d_218.dc.pad.8.0:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x229ffa0]]}
  lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 137], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x3324f60]]}
  lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x40094680]]}
  dc.input_tensor.sigmoid_219.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3317be0]]}
  dc.input_tensor.sigmoid_219.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40083a20]]}
  dc.input_tensor.sigmoid_223.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c9a180]]}
  dc.input_tensor.sigmoid_223.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4006c080]]}
  dc.input_tensor.sigmoid_226.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x329bd40]]}
  dc.input_tensor.sigmoid_226.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4008c460]]}
  lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 43], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x22276c0]]}
  lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x4005d660]]}
  dc.input_tensor.sigmoid_229.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6ca3ba0]]}
  dc.input_tensor.sigmoid_229.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40073da0]]}
  dc.input_tensor.sigmoid_232.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40073260]]}
  dc.input_tensor.sigmoid_232.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40084cc0]]}
  dc.input_tensor.sigmoid_236.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cc8820], [4, 0x40098280], [5, 0x3334d00], [5, 0x4006d720]]}
  dc.input_tensor.sigmoid_236.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2236a20], [2, 0x40080ba0], [3, 0x6caf740], [3, 0x4008a6a0]]}
  dc.input_tensor.sigmoid_239.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40086580], [4, 0x6cc4700], [4, 0x40094160], [5, 0x3330be0]]}
  dc.input_tensor.sigmoid_239.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40083c60], [2, 0x2232900], [2, 0x4007ca80], [3, 0x6cab620]]}
  input_1_multiply_240:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400654e0], [0, 0x2279580], [0, 0x4009a820], [1, 0x32ad1e0]]}
  input_2_concatenate_242:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32a3f60], [1, 0x4007b480], [2, 0x222a120], [2, 0x400742a0]]}
  input_1_multiply_246:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6ca7500], [3, 0x40082460], [4, 0x6cc05e0], [4, 0x40090040]]}
  input_1_concatenate_247:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32a90c0], [1, 0x4007fb40], [2, 0x222e7e0], [2, 0x40078960]]}
  input_1_multiply_250:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3320e40], [5, 0x400613c0], [0, 0x2275460], [0, 0x40096700]]}
  input_1_multiply_253:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6ca33e0], [3, 0x4007e340], [4, 0x6cbc4c0], [4, 0x4008bf20]]}
  lc.input_tensor.reshape_256.dc.sparse_matmul.3.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 4], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x4007f5a0], [2, 0x222e240], [2, 0x400783c0]]}
  lc.input_tensor.reshape_256.dc.sparse_matmul.3.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x2274420], [0, 0x400956c0], [1, 0x32a8080]]}
  lc.input_tensor.reshape_258.dc.sparse_matmul.4.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x40060740]]}
  lc.input_tensor.reshape_258.dc.sparse_matmul.4.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x331fe00]]}
  lc.input_tensor.concatenate_259.dc.sparse_matmul.4.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 2], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x4007e060], [4, 0x6cbc1e0], [4, 0x4008bc40]]}
  lc.input_tensor.concatenate_259.dc.sparse_matmul.4.1:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x6ca23a0]]}

  # epoch_to_epoch
  e2e_conv2d_6.dc.matmul.8_0:                                                                {input: conv2d_6.dc.matmul.8, type: queue, entries: 1, grid_size: [4, 1], t: 2, mblock: [25, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x333e940], [1, 0x40134240], [2, 0x22eaa00], [2, 0x4010d5c0]]}
  e2e_conv2d_16.dc.matmul.8_0:                                                               {input: conv2d_16.dc.matmul.8, type: queue, entries: 1, grid_size: [4, 1], t: 2, mblock: [25, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33adea0], [5, 0x40108ac0], [0, 0x230c6a0], [0, 0x40158f60]]}
  e2e_conv2d_20.dc.matmul.8_transpose_nop_11161_0:                                           {input: conv2d_20.dc.matmul.8_transpose_nop_11161, type: queue, entries: 1, grid_size: [4, 1], t: 10, mblock: [5, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6d1f8c0], [3, 0x401335a0], [4, 0x6db0900], [4, 0x4011ae60]]}
  e2e_conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0:                                {input: conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [16, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x230c6a0]]}
  e2e__fused_op_32_0:                                                                        {input: _fused_op_32, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40108ac0]]}
  e2e__fused_op_27_0:                                                                        {input: _fused_op_27, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33c7500]]}
  e2e__fused_op_55_0:                                                                        {input: _fused_op_55, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22eaa00], [2, 0x4010d5c0]]}
  e2e__fused_op_42_0:                                                                        {input: _fused_op_42, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40134240]]}
  e2e__fused_op_26_0:                                                                        {input: _fused_op_26, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [25, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40158f60], [1, 0x333e940]]}
  e2e__fused_op_74_0:                                                                        {input: _fused_op_74, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [25, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4011ae60], [5, 0x33adea0]]}
  e2e_concatenate_139.dc.concatenate.0_0:                                                    {input: concatenate_139.dc.concatenate.0, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [25, 2], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6d1f8c0], [3, 0x401335a0]]}
  e2e__fused_op_81_0:                                                                        {input: _fused_op_81, type: queue, entries: 1, grid_size: [1, 5], t: 8, mblock: [1, 5], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40134240], [2, 0x22eaa00], [2, 0x4010d5c0], [3, 0x6d52560], [3, 0x40166240]]}
  e2e__fused_op_70_0:                                                                        {input: _fused_op_70, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6db0900]]}
  e2e__fused_op_93_0:                                                                        {input: _fused_op_93, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x333e940]]}
  e2e__fused_op_59_0:                                                                        {input: _fused_op_59, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40108ac0], [0, 0x230c6a0]]}
  e2e_concatenate_234.dc.concatenate.0_0:                                                    {input: concatenate_234.dc.concatenate.0, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401725c0]]}
  e2e_reshape_256.dc.sparse_matmul.3.lc2_0:                                                  {input: reshape_256.dc.sparse_matmul.3.lc2, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 2], ublock: [3, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6dbdc60], [4, 0x401279a0], [5, 0x33ba9e0]]}
  e2e_concatenate_259.dc.concatenate.2_transpose_nop_2_11336_0:                              {input: concatenate_259.dc.concatenate.2_transpose_nop_2_11336, type: queue, entries: 1, grid_size: [5, 1], t: 3, mblock: [5, 3], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40108ac0], [0, 0x230c6a0], [0, 0x401829e0], [1, 0x3373660], [1, 0x4015cc60]]}
  e2e_reshape_217.dc.sparse_matmul.4.lc2_0:                                                  {input: reshape_217.dc.sparse_matmul.4.lc2, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [19, 1], ublock: [1, 3], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2313420], [2, 0x40135fe0]]}

graphs:
  fwd_0_0_temporal_epoch_0:
    target_device: 0
    input_count: 1
    conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0, ims_1, lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 25, mblock: [3, 1], ublock: [8, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 3, sparse_ublock_idx_bits: 3, u_kt: 200}}
    conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.matmul.11: {type: matmul, grid_loc: [0, 1], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.0.conv.weight_0_fork_clone1818],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 25}, hslice: 25], input_0_tms: [vslice: 96, hstack: 3, vstack: 32],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0, ims_1, lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 25, mblock: [3, 1], ublock: [8, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 3, sparse_ublock_idx_bits: 3, u_kt: 200}}
    conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.matmul.11: {type: matmul, grid_loc: [0, 3], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.0.conv.weight_0, model.model.model.0.conv.bias_0],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 800}, vslice: 25], input_1_tms: [broadcast: {c: 25}, hslice: 25], input_0_tms: [vslice: 96, hstack: 3, vstack: 32],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 3}}
    conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 4], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0, ims_1, lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 25, mblock: [3, 1], ublock: [8, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 3, sparse_ublock_idx_bits: 3, u_kt: 200}}
    conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.matmul.11: {type: matmul, grid_loc: [0, 5], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.0.conv.weight_0_fork_clone1816],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 25}, hslice: 25], input_0_tms: [vslice: 96, hstack: 3, vstack: 32],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_0: {type: fused_op, grid_loc: [0, 6], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.matmul.11, conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.matmul.11, conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.matmul.11, dc.input_tensor.sigmoid_1.0, dc.input_tensor.sigmoid_1.1],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_4_tms: [broadcast: {r: 800}, vslice: 25], input_3_tms: [broadcast: {r: 800}, vslice: 25],
         attributes: {approximate_mode: false, fused_op_id: 0, kernel_broadcast: {input_4: 1, input_3: 1}}}
    conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 2, mblock: [15, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 25],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 25, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 32}}
    conv2d_3.dc.conv2d.5.dc.matmul.11: {type: matmul, grid_loc: [4, 1], grid_size: [4, 1], inputs: [conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.1.conv.weight_0_fork_clone430],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 300, hstack: 3, vstack: 100],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 2, mblock: [15, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 25],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 25, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 32}}
    conv2d_3.dc.conv2d.1.dc.matmul.11: {type: matmul, grid_loc: [4, 3], grid_size: [4, 1], inputs: [conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.1.conv.weight_0, model.model.model.1.conv.bias_0],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 300, hstack: 3, vstack: 100],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 4], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 2, mblock: [15, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 25],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 25, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 32}}
    conv2d_3.dc.conv2d.3.dc.matmul.11: {type: matmul, grid_loc: [4, 5], grid_size: [4, 1], inputs: [conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.1.conv.weight_0_fork_clone428],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 300, hstack: 3, vstack: 100],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_1: {type: fused_op, grid_loc: [0, 7], grid_size: [4, 1], inputs: [conv2d_3.dc.conv2d.1.dc.matmul.11, conv2d_3.dc.conv2d.3.dc.matmul.11, conv2d_3.dc.conv2d.5.dc.matmul.11, dc.input_tensor.sigmoid_4.0, dc.input_tensor.sigmoid_4.1],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_4_tms: [broadcast: {r: 200}, vslice: 2], input_3_tms: [broadcast: {r: 200}, vslice: 2],
         attributes: {approximate_mode: false, fused_op_id: 1, kernel_broadcast: {input_4: 1, input_3: 1}}}
    conv2d_6.dc.matmul.8: {type: matmul, grid_loc: [4, 6], grid_size: [4, 1], inputs: [_fused_op_1, model.model.model.2.cv1.conv.weight_0, model.model.model.2.cv1.conv.bias_0],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 1, input_1: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    conv2d_16.dc.matmul.8: {type: matmul, grid_loc: [4, 7], grid_size: [4, 1], inputs: [_fused_op_1, model.model.model.2.cv2.conv.weight_0, model.model.model.2.cv2.conv.bias_0],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 1, input_1: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}

  fwd_0_1_temporal_epoch_1:
    target_device: 0
    input_count: 1
    _fused_op_2: {type: fused_op, grid_loc: [0, 0], grid_size: [4, 1], inputs: [e2e_conv2d_6.dc.matmul.8_0, dc.input_tensor.sigmoid_7.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}], input_0_tms: [vstack: 2],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    _fused_op_3: {type: fused_op, grid_loc: [0, 1], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_7.1, _fused_op_2, e2e_conv2d_6.dc.matmul.8_0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 48], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vstack: 2], input_0_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 3, kernel_broadcast: {input_0: 1}}}
    conv2d_9.dc.matmul.8: {type: matmul, grid_loc: [0, 4], grid_size: [4, 1], inputs: [_fused_op_3, model.model.model.2.m.0.cv1.conv.weight_0, model.model.model.2.m.0.cv1.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    _fused_op_4: {type: fused_op, grid_loc: [0, 5], grid_size: [4, 1], inputs: [conv2d_9.dc.matmul.8, dc.input_tensor.sigmoid_10.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    _fused_op_5: {type: fused_op, grid_loc: [0, 6], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_10.1, _fused_op_4, conv2d_9.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 390], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 3, kernel_broadcast: {input_0: 1}}}
    conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 4], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_5, lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 11, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 200}}
    conv2d_12.dc.conv2d.5.dc.matmul.11: {type: matmul, grid_loc: [4, 5], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.2.m.0.cv2.conv.weight_0_fork_clone488],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 60, hstack: 3, vstack: 20],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_5, lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 11, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 200}}
    conv2d_12.dc.conv2d.1.dc.matmul.11: {type: matmul, grid_loc: [4, 1], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.2.m.0.cv2.conv.weight_0, model.model.model.2.m.0.cv2.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 60, hstack: 3, vstack: 20],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_5, lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 8, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 200}}
    conv2d_12.dc.conv2d.3.dc.matmul.11: {type: matmul, grid_loc: [4, 3], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.2.m.0.cv2.conv.weight_0_fork_clone486],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 60, hstack: 3, vstack: 20],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_6: {type: fused_op, grid_loc: [0, 7], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.1.dc.matmul.11, conv2d_12.dc.conv2d.3.dc.matmul.11, conv2d_12.dc.conv2d.5.dc.matmul.11, dc.input_tensor.sigmoid_13.0, dc.input_tensor.sigmoid_13.1, _fused_op_3],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 0, 0, 0, 477], input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_5_tms: [vslice: 10], input_4_tms: [broadcast: {r: 200}, vslice: 10], input_3_tms: [broadcast: {r: 200}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 6, kernel_broadcast: {input_4: 1, input_3: 1}}}
    _fused_op_7: {type: fused_op, grid_loc: [0, 2], grid_size: [4, 1], inputs: [e2e_conv2d_16.dc.matmul.8_0, dc.input_tensor.sigmoid_17.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}], input_0_tms: [vstack: 2],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    _fused_op_8: {type: fused_op, grid_loc: [0, 3], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_17.1, _fused_op_7, e2e_conv2d_16.dc.matmul.8_0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 48], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vstack: 2], input_0_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 3, kernel_broadcast: {input_0: 1}}}
    concatenate_19.dc.concatenate.2: {type: splice, grid_loc: [4, 6], grid_size: [4, 1], inputs: [_fused_op_6, _fused_op_8],
         t: 10, mblock: [5, 2], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [vslice: 10],
         attributes: {input0: [0, 5, 5], input1: [0, 5, 5]}}
    concatenate_19.dc.sparse_matmul.5.lc2: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.concatenate_19.dc.sparse_matmul.5.0, concatenate_19.dc.concatenate.2, lc.input_tensor.concatenate_19.dc.sparse_matmul.5.1],
         t: 10, mblock: [1, 4], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 10, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 3, sparse_tile_ptr_bits: 2, sparse_ublock_idx_bits: 2, u_kt: 1}}
    conv2d_20.dc.matmul.8_transpose_nop_11161: {type: nop, grid_loc: [5, 7], grid_size: [4, 1], inputs: [concatenate_19.dc.sparse_matmul.5.lc2],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}

  fwd_0_2_temporal_epoch_2:
    target_device: 0
    input_count: 1
    conv2d_20.dc.matmul.8: {type: matmul, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e_conv2d_20.dc.matmul.8_transpose_nop_11161_0, model.model.model.2.cv3.conv.weight_0, model.model.model.2.cv3.conv.bias_0],
         t: 1, mblock: [100, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}], input_0_tms: [vstack: 10],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    _fused_op_9: {type: fused_op, grid_loc: [0, 1], grid_size: [1, 1], inputs: [conv2d_20.dc.matmul.8, dc.input_tensor.sigmoid_21.0],
         t: 1, mblock: [100, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 9, kernel_broadcast: {input_1: 1}}}
    buffer_1_4647_5598: {type: nop, grid_loc: [0, 2], grid_size: [1, 1], inputs: [conv2d_20.dc.matmul.8],
         t: 1, mblock: [100, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_4647_5598: {type: nop, grid_loc: [0, 3], grid_size: [1, 1], inputs: [buffer_1_4647_5598],
         t: 1, mblock: [100, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_10: {type: fused_op, grid_loc: [0, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_21.1, _fused_op_9, buffer_0_4647_5598],
         t: 1, mblock: [100, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 10, kernel_broadcast: {input_0: 1}}}
    conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 5], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_10, lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 50, mblock: [3, 1], ublock: [3, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 39, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 200}}
    conv2d_23.dc.matmul.11: {type: matmul, grid_loc: [0, 6], grid_size: [1, 2], inputs: [conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.3.conv.weight_0, model.model.model.3.conv.bias_0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 100, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 50], input_1_tms: [broadcast: {c: 50}, hslice: 50], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 9}}
    _fused_op_11: {type: fused_op, grid_loc: [1, 0], grid_size: [1, 1], inputs: [conv2d_23.dc.matmul.11, dc.input_tensor.sigmoid_24.0],
         t: 50, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 11}}
    _fused_op_12: {type: fused_op, grid_loc: [1, 1], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_24.1, _fused_op_11, conv2d_23.dc.matmul.11],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 489], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 12}}
    conv2d_26.dc.matmul.8: {type: matmul, grid_loc: [1, 3], grid_size: [1, 1], inputs: [_fused_op_12, model.model.model.4.cv1.conv.weight_0, model.model.model.4.cv1.conv.bias_0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 100, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 50], input_1_tms: [broadcast: {c: 50}, hslice: 50],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_13: {type: fused_op, grid_loc: [1, 5], grid_size: [1, 1], inputs: [conv2d_26.dc.matmul.8, dc.input_tensor.sigmoid_27.0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 13, kernel_broadcast: {input_1: 1}}}
    _fused_op_14: {type: fused_op, grid_loc: [1, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_27.1, _fused_op_13, conv2d_26.dc.matmul.8],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 491], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 12, kernel_broadcast: {input_0: 1}}}
    conv2d_29.dc.matmul.8: {type: matmul, grid_loc: [2, 0], grid_size: [1, 1], inputs: [_fused_op_14, model.model.model.4.m.0.cv1.conv.weight_0, model.model.model.4.m.0.cv1.conv.bias_0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 100, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 50], input_1_tms: [broadcast: {c: 50}, hslice: 50],
         attributes: {bias: true, kernel_broadcast: {input_2: 1, input_1: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    _fused_op_15: {type: fused_op, grid_loc: [2, 4], grid_size: [1, 1], inputs: [conv2d_29.dc.matmul.8, dc.input_tensor.sigmoid_30.0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 13, kernel_broadcast: {input_1: 1}}}
    _fused_op_16: {type: fused_op, grid_loc: [2, 5], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_30.1, _fused_op_15, conv2d_29.dc.matmul.8],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 491], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 12, kernel_broadcast: {input_0: 1}}}
    conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 6], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_16, lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [45, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 50],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 50, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_32.dc.matmul.11: {type: matmul, grid_loc: [2, 7], grid_size: [2, 1], inputs: [conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.4.m.0.cv2.conv.weight_0, model.model.model.4.m.0.cv2.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 9}}
    _fused_op_17: {type: fused_op, grid_loc: [3, 0], grid_size: [1, 1], inputs: [conv2d_32.dc.matmul.11, dc.input_tensor.sigmoid_33.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    buffer_0_5602_5606: {type: nop, grid_loc: [2, 1], grid_size: [1, 1], inputs: [_fused_op_14],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [494], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_18: {type: fused_op, grid_loc: [3, 1], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_33.1, _fused_op_17, conv2d_32.dc.matmul.11, buffer_0_5602_5606],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 489, 0], input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vslice: 50], input_1_tms: [vslice: 50], input_0_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 18, kernel_broadcast: {input_0: 1}}}
    conv2d_36.dc.matmul.8: {type: matmul, grid_loc: [3, 2], grid_size: [1, 1], inputs: [_fused_op_18, model.model.model.4.m.1.cv1.conv.weight_0, model.model.model.4.m.1.cv1.conv.bias_0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 100, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 50], input_1_tms: [broadcast: {c: 50}, hslice: 50],
         attributes: {bias: true, kernel_broadcast: {input_2: 1, input_1: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    _fused_op_19: {type: fused_op, grid_loc: [3, 3], grid_size: [1, 1], inputs: [conv2d_36.dc.matmul.8, dc.input_tensor.sigmoid_37.0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 13, kernel_broadcast: {input_1: 1}}}
    _fused_op_20: {type: fused_op, grid_loc: [3, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_37.1, _fused_op_19, conv2d_36.dc.matmul.8],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 491], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 12, kernel_broadcast: {input_0: 1}}}
    conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_20, lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [45, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 50],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 50, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_39.dc.matmul.11: {type: matmul, grid_loc: [4, 1], grid_size: [2, 1], inputs: [conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.4.m.1.cv2.conv.weight_0, model.model.model.4.m.1.cv2.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 9}}
    buffer_0_5600_4748: {type: nop, grid_loc: [1, 4], grid_size: [1, 1], inputs: [_fused_op_12],
         t: 50, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [492], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    conv2d_43.dc.matmul.8: {type: matmul, grid_loc: [1, 7], grid_size: [1, 1], inputs: [buffer_0_5600_4748, model.model.model.4.cv2.conv.weight_0, model.model.model.4.cv2.conv.bias_0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 100, input_buf_min_size_tiles: [391, 0, 0], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 50], input_1_tms: [broadcast: {c: 50}, hslice: 50],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_21: {type: fused_op, grid_loc: [3, 5], grid_size: [1, 1], inputs: [conv2d_39.dc.matmul.11, dc.input_tensor.sigmoid_40.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    buffer_0_5606_5610: {type: nop, grid_loc: [4, 2], grid_size: [1, 1], inputs: [_fused_op_18],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [494], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_22: {type: fused_op, grid_loc: [4, 3], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_40.1, _fused_op_21, conv2d_39.dc.matmul.11, buffer_0_5606_5610],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 489, 0], input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vslice: 50], input_1_tms: [vslice: 50], input_0_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 18, kernel_broadcast: {input_0: 1}}}
    _fused_op_23: {type: fused_op, grid_loc: [2, 2], grid_size: [1, 1], inputs: [conv2d_43.dc.matmul.8, dc.input_tensor.sigmoid_44.0],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 13, kernel_broadcast: {input_1: 1}}}
    _fused_op_24: {type: fused_op, grid_loc: [2, 3], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_44.1, _fused_op_23, conv2d_43.dc.matmul.8],
         t: 50, mblock: [1, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 491], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 12, kernel_broadcast: {input_0: 1}}}
    concatenate_46.dc.concatenate.0: {type: splice, grid_loc: [4, 4], grid_size: [1, 1], inputs: [_fused_op_22, _fused_op_24],
         t: 50, mblock: [1, 2], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 490], input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 1, 1], input1: [0, 1, 1]}}
    conv2d_47.dc.matmul.8: {type: matmul, grid_loc: [4, 5], grid_size: [1, 1], inputs: [concatenate_46.dc.concatenate.0, model.model.model.4.cv3.conv.weight_0, model.model.model.4.cv3.conv.bias_0],
         t: 50, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 100, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 50], input_1_tms: [broadcast: {c: 50}, hslice: 50],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_25: {type: fused_op, grid_loc: [4, 6], grid_size: [1, 1], inputs: [conv2d_47.dc.matmul.8, dc.input_tensor.sigmoid_48.0],
         t: 50, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 50],
         attributes: {approximate_mode: false, fused_op_id: 11, kernel_broadcast: {input_1: 2}}}
    _fused_op_26: {type: fused_op, grid_loc: [4, 7], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_48.1, _fused_op_25, conv2d_47.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 390], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vstack: 50], input_1_tms: [vstack: 50], input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 26, kernel_broadcast: {input_0: 2}}}
    conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 2], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_26, lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [4, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 86, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 50}}
    conv2d_50.dc.matmul.11: {type: matmul, grid_loc: [5, 3], grid_size: [2, 1], inputs: [conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.5.conv.weight_0],
         t: 1, mblock: [4, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 18}}
    conv2d_50.dc.select.12: {type: splice, grid_loc: [5, 4], grid_size: [1, 1], inputs: [conv2d_50.dc.matmul.11],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    _fused_op_27: {type: fused_op, grid_loc: [5, 5], grid_size: [1, 1], inputs: [conv2d_50.dc.select.12, model.model.model.5.conv.bias_0, dc.input_tensor.sigmoid_51.0, dc.input_tensor.sigmoid_51.1],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 27}}
    conv2d_53.dc.matmul.8: {type: matmul, grid_loc: [5, 6], grid_size: [1, 1], inputs: [_fused_op_27, model.model.model.6.cv1.conv.weight_0, model.model.model.6.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_28: {type: fused_op, grid_loc: [6, 0], grid_size: [1, 1], inputs: [conv2d_53.dc.matmul.8, dc.input_tensor.sigmoid_54.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_29: {type: fused_op, grid_loc: [6, 1], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_54.1, _fused_op_28, conv2d_53.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_56.dc.matmul.8: {type: matmul, grid_loc: [6, 4], grid_size: [1, 1], inputs: [_fused_op_29, model.model.model.6.m.0.cv1.conv.weight_0, model.model.model.6.m.0.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 2}}
    _fused_op_30: {type: fused_op, grid_loc: [6, 5], grid_size: [1, 1], inputs: [conv2d_56.dc.matmul.8, dc.input_tensor.sigmoid_57.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_31: {type: fused_op, grid_loc: [6, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_57.1, _fused_op_30, conv2d_56.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_59.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [6, 7], grid_size: [1, 1], inputs: [_fused_op_31, dc.input_tensor.conv2d_59.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [7, 0], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_59.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [4, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 33, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_59.dc.matmul.12: {type: matmul, grid_loc: [7, 1], grid_size: [2, 1], inputs: [conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.6.m.0.cv2.conv.weight_0],
         t: 1, mblock: [4, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_59.dc.select.13: {type: splice, grid_loc: [7, 2], grid_size: [1, 1], inputs: [conv2d_59.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    _fused_op_32: {type: fused_op, grid_loc: [7, 3], grid_size: [1, 1], inputs: [conv2d_59.dc.select.13, model.model.model.6.m.0.cv2.conv.bias_0, dc.input_tensor.sigmoid_60.0, dc.input_tensor.sigmoid_60.1, _fused_op_29],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 0, 0, 372], input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 32}}
    conv2d_63.dc.matmul.8: {type: matmul, grid_loc: [7, 4], grid_size: [1, 1], inputs: [_fused_op_32, model.model.model.6.m.1.cv1.conv.weight_0, model.model.model.6.m.1.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 2}}
    _fused_op_33: {type: fused_op, grid_loc: [7, 5], grid_size: [1, 1], inputs: [conv2d_63.dc.matmul.8, dc.input_tensor.sigmoid_64.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_34: {type: fused_op, grid_loc: [7, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_64.1, _fused_op_33, conv2d_63.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [7, 7], grid_size: [1, 1], inputs: [_fused_op_34, dc.input_tensor.conv2d_66.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}

  fwd_0_3_temporal_epoch_3:
    target_device: 0
    input_count: 1
    conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.0, e2e_conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0, lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [4, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 32, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 33, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_66.dc.matmul.12: {type: matmul, grid_loc: [0, 1], grid_size: [2, 1], inputs: [conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.6.m.1.cv2.conv.weight_0],
         t: 1, mblock: [4, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_66.dc.select.13: {type: splice, grid_loc: [0, 2], grid_size: [1, 1], inputs: [conv2d_66.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    _fused_op_35: {type: fused_op, grid_loc: [0, 3], grid_size: [1, 1], inputs: [conv2d_66.dc.select.13, model.model.model.6.m.1.cv2.conv.bias_0, dc.input_tensor.sigmoid_67.0, dc.input_tensor.sigmoid_67.1, e2e__fused_op_32_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 48], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 32}}
    conv2d_70.dc.matmul.8: {type: matmul, grid_loc: [0, 4], grid_size: [1, 1], inputs: [_fused_op_35, model.model.model.6.m.2.cv1.conv.weight_0, model.model.model.6.m.2.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 2}}
    _fused_op_36: {type: fused_op, grid_loc: [0, 5], grid_size: [1, 1], inputs: [conv2d_70.dc.matmul.8, dc.input_tensor.sigmoid_71.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_37: {type: fused_op, grid_loc: [0, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_71.1, _fused_op_36, conv2d_70.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_73.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [0, 7], grid_size: [1, 1], inputs: [_fused_op_37, dc.input_tensor.conv2d_73.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 2], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_73.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [4, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 33, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_73.dc.matmul.12: {type: matmul, grid_loc: [1, 3], grid_size: [2, 1], inputs: [conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.6.m.2.cv2.conv.weight_0],
         t: 1, mblock: [4, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_73.dc.select.13: {type: splice, grid_loc: [1, 4], grid_size: [1, 1], inputs: [conv2d_73.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    conv2d_77.dc.matmul.8: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [e2e__fused_op_27_0, model.model.model.6.cv2.conv.weight_0, model.model.model.6.cv2.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_38: {type: fused_op, grid_loc: [1, 5], grid_size: [1, 1], inputs: [conv2d_73.dc.select.13, model.model.model.6.m.2.cv2.conv.bias_0, dc.input_tensor.sigmoid_74.0, dc.input_tensor.sigmoid_74.1, _fused_op_35],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 0, 0, 372], input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 32}}
    _fused_op_39: {type: fused_op, grid_loc: [1, 7], grid_size: [1, 1], inputs: [conv2d_77.dc.matmul.8, dc.input_tensor.sigmoid_78.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_40: {type: fused_op, grid_loc: [2, 0], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_78.1, _fused_op_39, conv2d_77.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    concatenate_80.dc.concatenate.0: {type: splice, grid_loc: [2, 1], grid_size: [1, 1], inputs: [_fused_op_38, _fused_op_40],
         t: 1, mblock: [13, 2], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_81.dc.matmul.8: {type: matmul, grid_loc: [2, 4], grid_size: [1, 1], inputs: [concatenate_80.dc.concatenate.0, model.model.model.6.cv3.conv.weight_0, model.model.model.6.cv3.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_41: {type: fused_op, grid_loc: [2, 5], grid_size: [1, 1], inputs: [conv2d_81.dc.matmul.8, dc.input_tensor.sigmoid_82.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 41}}
    _fused_op_42: {type: fused_op, grid_loc: [2, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_82.1, _fused_op_41, conv2d_81.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 42}}
    conv2d_84.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [2, 7], grid_size: [1, 1], inputs: [_fused_op_42, dc.input_tensor.conv2d_84.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 0], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_84.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [9, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 70, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 16}}
    conv2d_84.dc.matmul.12: {type: matmul, grid_loc: [3, 1], grid_size: [2, 1], inputs: [conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.7.conv.weight_0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 9, min_buffer_input: 0, u_kt: 4}}
    _fused_op_43: {type: fused_op, grid_loc: [3, 2], grid_size: [2, 1], inputs: [conv2d_84.dc.matmul.12, model.model.model.7.conv.bias_0, dc.input_tensor.sigmoid_85.0, dc.input_tensor.sigmoid_85.1],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}],
         attributes: {approximate_mode: false, fused_op_id: 43}}
    conv2d_87.dc.matmul.8: {type: matmul, grid_loc: [3, 3], grid_size: [2, 1], inputs: [_fused_op_43, model.model.model.8.cv1.conv.weight_0, model.model.model.8.cv1.conv.bias_0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_44: {type: fused_op, grid_loc: [3, 4], grid_size: [2, 1], inputs: [conv2d_87.dc.matmul.8, dc.input_tensor.sigmoid_88.0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_45: {type: fused_op, grid_loc: [3, 5], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_88.1, _fused_op_44, conv2d_87.dc.matmul.8],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 440], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    conv2d_90.dc.matmul.8: {type: matmul, grid_loc: [3, 6], grid_size: [2, 1], inputs: [_fused_op_45, model.model.model.8.m.0.cv1.conv.weight_0, model.model.model.8.m.0.cv1.conv.bias_0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_46: {type: fused_op, grid_loc: [3, 7], grid_size: [2, 1], inputs: [conv2d_90.dc.matmul.8, dc.input_tensor.sigmoid_91.0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_47: {type: fused_op, grid_loc: [5, 0], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_91.1, _fused_op_46, conv2d_90.dc.matmul.8],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 440], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 1], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_47, lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [9, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 23, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 4}}
    conv2d_93.dc.matmul.11: {type: matmul, grid_loc: [5, 2], grid_size: [2, 1], inputs: [conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.8.m.0.cv2.conv.weight_0, model.model.model.8.m.0.cv2.conv.bias_0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 6, min_buffer_input: 0, u_kt: 6}}
    conv2d_97.dc.matmul.8: {type: matmul, grid_loc: [5, 6], grid_size: [2, 1], inputs: [_fused_op_43, model.model.model.8.cv2.conv.weight_0, model.model.model.8.cv2.conv.bias_0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [424, 0, 0], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_48: {type: fused_op, grid_loc: [5, 3], grid_size: [2, 1], inputs: [conv2d_93.dc.matmul.11, dc.input_tensor.sigmoid_94.0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    buffer_0_5633_5637: {type: nop, grid_loc: [5, 4], grid_size: [2, 1], inputs: [_fused_op_45],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [480], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_49: {type: fused_op, grid_loc: [5, 5], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_94.1, _fused_op_48, conv2d_93.dc.matmul.11, buffer_0_5633_5637],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 424, 0], input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 49}}
    _fused_op_50: {type: fused_op, grid_loc: [5, 7], grid_size: [2, 1], inputs: [conv2d_97.dc.matmul.8, dc.input_tensor.sigmoid_98.0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_51: {type: fused_op, grid_loc: [7, 0], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_98.1, _fused_op_50, conv2d_97.dc.matmul.8],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 440], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    concatenate_100.dc.concatenate.0: {type: splice, grid_loc: [7, 1], grid_size: [2, 1], inputs: [_fused_op_49, _fused_op_51],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 448], input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 1, 1], input1: [0, 1, 1]}}
    conv2d_101.dc.matmul.8: {type: matmul, grid_loc: [7, 2], grid_size: [2, 1], inputs: [concatenate_100.dc.concatenate.0, model.model.model.8.cv3.conv.weight_0, model.model.model.8.cv3.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 16}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_52: {type: fused_op, grid_loc: [7, 3], grid_size: [2, 1], inputs: [conv2d_101.dc.matmul.8, dc.input_tensor.sigmoid_102.0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 52}}
    _fused_op_53: {type: fused_op, grid_loc: [7, 4], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_102.1, _fused_op_52, conv2d_101.dc.matmul.8],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 53}}
    conv2d_104.dc.matmul.8: {type: matmul, grid_loc: [7, 5], grid_size: [2, 1], inputs: [_fused_op_53, model.model.model.9.cv1.conv.weight_0, model.model.model.9.cv1.conv.bias_0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_54: {type: fused_op, grid_loc: [7, 6], grid_size: [2, 1], inputs: [conv2d_104.dc.matmul.8, dc.input_tensor.sigmoid_105.0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_55: {type: fused_op, grid_loc: [7, 7], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_105.1, _fused_op_54, conv2d_104.dc.matmul.8],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 440], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}

  fwd_0_4_temporal_epoch_4:
    target_device: 0
    input_count: 1
    max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.0, e2e__fused_op_55_0, lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.1],
         t: 1, mblock: [25, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 67, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 4}}
    max_pool2d_107.dc.reduce_max.6: {type: reduce, grid_loc: [0, 1], grid_size: [2, 1], inputs: [max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 25],
         attributes: {dim: z, type: max, z: 25}}
    max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 2], grid_size: [2, 1], inputs: [lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.0, max_pool2d_107.dc.reduce_max.6, lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.1],
         t: 1, mblock: [25, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 67, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 4}}
    max_pool2d_108.dc.reduce_max.6: {type: reduce, grid_loc: [0, 3], grid_size: [2, 1], inputs: [max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 25],
         attributes: {dim: z, type: max, z: 25}}
    max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 4], grid_size: [2, 1], inputs: [lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.0, max_pool2d_108.dc.reduce_max.6, lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.1],
         t: 1, mblock: [25, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 67, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 4}}
    max_pool2d_109.dc.reduce_max.6: {type: reduce, grid_loc: [0, 5], grid_size: [2, 1], inputs: [max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 25],
         attributes: {dim: z, type: max, z: 25}}
    concatenate_110.dc.concatenate.0: {type: splice, grid_loc: [0, 6], grid_size: [2, 1], inputs: [e2e__fused_op_55_0, max_pool2d_107.dc.reduce_max.6, max_pool2d_108.dc.reduce_max.6, max_pool2d_109.dc.reduce_max.6],
         t: 1, mblock: [1, 4], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 384, 0], input_dram_io_buf_size_tiles: [48, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 1, 1], input1: [0, 1, 1], input2: [0, 1, 1], input3: [0, 1, 1]}}
    conv2d_111.dc.matmul.8: {type: matmul, grid_loc: [0, 7], grid_size: [2, 1], inputs: [concatenate_110.dc.concatenate.0, model.model.model.9.cv2.conv.weight_0, model.model.model.9.cv2.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 16}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_56: {type: fused_op, grid_loc: [2, 0], grid_size: [2, 1], inputs: [conv2d_111.dc.matmul.8, dc.input_tensor.sigmoid_112.0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 52}}
    _fused_op_57: {type: fused_op, grid_loc: [2, 1], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_112.1, _fused_op_56, conv2d_111.dc.matmul.8],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 53}}
    conv2d_114.dc.matmul.8: {type: matmul, grid_loc: [2, 2], grid_size: [2, 1], inputs: [_fused_op_57, model.model.model.10.conv.weight_0, model.model.model.10.conv.bias_0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_58: {type: fused_op, grid_loc: [2, 3], grid_size: [2, 1], inputs: [conv2d_114.dc.matmul.8, dc.input_tensor.sigmoid_115.0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_59: {type: fused_op, grid_loc: [2, 4], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_115.1, _fused_op_58, conv2d_114.dc.matmul.8],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 440], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    resize2d_117.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [2, 5], grid_size: [1, 1], inputs: [lc.input_tensor.resize2d_117.dc.sparse_matmul.3.0, _fused_op_59, lc.input_tensor.resize2d_117.dc.sparse_matmul.3.1],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 20, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 4}}
    concatenate_118.dc.concatenate.0: {type: splice, grid_loc: [2, 6], grid_size: [1, 1], inputs: [resize2d_117.dc.sparse_matmul.3.lc2, e2e__fused_op_42_0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_119.dc.matmul.8: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [concatenate_118.dc.concatenate.0, model.model.model.13.cv1.conv.weight_0, model.model.model.13.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_60: {type: fused_op, grid_loc: [3, 5], grid_size: [1, 1], inputs: [conv2d_119.dc.matmul.8, dc.input_tensor.sigmoid_120.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_61: {type: fused_op, grid_loc: [3, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_120.1, _fused_op_60, conv2d_119.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_122.dc.matmul.8: {type: matmul, grid_loc: [3, 7], grid_size: [1, 1], inputs: [_fused_op_61, model.model.model.13.m.0.cv1.conv.weight_0, model.model.model.13.m.0.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 2}}
    _fused_op_62: {type: fused_op, grid_loc: [4, 0], grid_size: [1, 1], inputs: [conv2d_122.dc.matmul.8, dc.input_tensor.sigmoid_123.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_63: {type: fused_op, grid_loc: [4, 1], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_123.1, _fused_op_62, conv2d_122.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [4, 2], grid_size: [1, 1], inputs: [_fused_op_63, dc.input_tensor.conv2d_125.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 3], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [4, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 33, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_125.dc.matmul.12: {type: matmul, grid_loc: [4, 4], grid_size: [2, 1], inputs: [conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.13.m.0.cv2.conv.weight_0],
         t: 1, mblock: [4, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_125.dc.select.13: {type: splice, grid_loc: [4, 5], grid_size: [1, 1], inputs: [conv2d_125.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    conv2d_128.dc.matmul.8: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [concatenate_118.dc.concatenate.0, model.model.model.13.cv2.conv.weight_0, model.model.model.13.cv2.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [408, 0, 0], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_64: {type: fused_op, grid_loc: [4, 6], grid_size: [1, 1], inputs: [conv2d_125.dc.select.13, model.model.model.13.m.0.cv2.conv.bias_0, dc.input_tensor.sigmoid_126.0, dc.input_tensor.sigmoid_126.1],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 64}}
    _fused_op_65: {type: fused_op, grid_loc: [5, 0], grid_size: [1, 1], inputs: [conv2d_128.dc.matmul.8, dc.input_tensor.sigmoid_129.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_66: {type: fused_op, grid_loc: [5, 1], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_129.1, _fused_op_65, conv2d_128.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    concatenate_131.dc.concatenate.0: {type: splice, grid_loc: [5, 2], grid_size: [1, 1], inputs: [_fused_op_64, _fused_op_66],
         t: 1, mblock: [13, 2], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 388], input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_132.dc.matmul.8: {type: matmul, grid_loc: [5, 5], grid_size: [1, 1], inputs: [concatenate_131.dc.concatenate.0, model.model.model.13.cv3.conv.weight_0, model.model.model.13.cv3.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_67: {type: fused_op, grid_loc: [5, 6], grid_size: [1, 1], inputs: [conv2d_132.dc.matmul.8, dc.input_tensor.sigmoid_133.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 41}}
    _fused_op_68: {type: fused_op, grid_loc: [5, 7], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_133.1, _fused_op_67, conv2d_132.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 42}}
    conv2d_135.dc.matmul.8: {type: matmul, grid_loc: [6, 0], grid_size: [1, 1], inputs: [_fused_op_68, model.model.model.14.conv.weight_0, model.model.model.14.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_69: {type: fused_op, grid_loc: [6, 1], grid_size: [1, 1], inputs: [conv2d_135.dc.matmul.8, dc.input_tensor.sigmoid_136.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_70: {type: fused_op, grid_loc: [6, 2], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_136.1, _fused_op_69, conv2d_135.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    resize2d_138.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [6, 3], grid_size: [2, 1], inputs: [lc.input_tensor.resize2d_138.dc.sparse_matmul.3.0, _fused_op_70, lc.input_tensor.resize2d_138.dc.sparse_matmul.3.1],
         t: 1, mblock: [5, 2], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 24, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 13}}
    concatenate_139.dc.concatenate.0: {type: splice, grid_loc: [6, 4], grid_size: [2, 1], inputs: [resize2d_138.dc.sparse_matmul.3.lc2, e2e__fused_op_26_0],
         t: 1, mblock: [25, 2], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 25, 25], input1: [0, 25, 25]}}
    conv2d_140.dc.matmul.8: {type: matmul, grid_loc: [6, 5], grid_size: [2, 1], inputs: [concatenate_139.dc.concatenate.0, model.model.model.17.cv1.conv.weight_0, model.model.model.17.cv1.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_71: {type: fused_op, grid_loc: [6, 6], grid_size: [2, 1], inputs: [conv2d_140.dc.matmul.8, dc.input_tensor.sigmoid_141.0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 71, kernel_broadcast: {input_1: 1}}}
    _fused_op_72: {type: fused_op, grid_loc: [6, 7], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_141.1, _fused_op_71, conv2d_140.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 443], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 72, kernel_broadcast: {input_0: 1}}}
    conv2d_143.dc.matmul.8: {type: matmul, grid_loc: [7, 0], grid_size: [2, 1], inputs: [_fused_op_72, model.model.model.17.m.0.cv1.conv.weight_0, model.model.model.17.m.0.cv1.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    _fused_op_73: {type: fused_op, grid_loc: [7, 1], grid_size: [2, 1], inputs: [conv2d_143.dc.matmul.8, dc.input_tensor.sigmoid_144.0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 71, kernel_broadcast: {input_1: 1}}}
    _fused_op_74: {type: fused_op, grid_loc: [7, 2], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_144.1, _fused_op_73, conv2d_143.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 443], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 72, kernel_broadcast: {input_0: 1}}}

  fwd_0_5_temporal_epoch_5:
    target_device: 0
    input_count: 1
    conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.0, e2e__fused_op_74_0, lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [45, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 25, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 25}}
    conv2d_146.dc.matmul.11: {type: matmul, grid_loc: [0, 1], grid_size: [2, 1], inputs: [conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.17.m.0.cv2.conv.weight_0, model.model.model.17.m.0.cv2.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 9}}
    conv2d_149.dc.matmul.8: {type: matmul, grid_loc: [0, 4], grid_size: [1, 1], inputs: [e2e_concatenate_139.dc.concatenate.0_0, model.model.model.17.cv2.conv.weight_0, model.model.model.17.cv2.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_75: {type: fused_op, grid_loc: [0, 2], grid_size: [1, 1], inputs: [conv2d_146.dc.matmul.11, dc.input_tensor.sigmoid_147.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    _fused_op_76: {type: fused_op, grid_loc: [0, 3], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_147.1, _fused_op_75, conv2d_146.dc.matmul.11],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 390], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 3, kernel_broadcast: {input_0: 1}}}
    _fused_op_77: {type: fused_op, grid_loc: [0, 5], grid_size: [1, 1], inputs: [conv2d_149.dc.matmul.8, dc.input_tensor.sigmoid_150.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    _fused_op_78: {type: fused_op, grid_loc: [0, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_150.1, _fused_op_77, conv2d_149.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 390], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 3, kernel_broadcast: {input_0: 1}}}
    concatenate_152.dc.concatenate.0: {type: splice, grid_loc: [0, 7], grid_size: [1, 1], inputs: [_fused_op_76, _fused_op_78],
         t: 1, mblock: [25, 2], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 25, 25], input1: [0, 25, 25]}}
    conv2d_153.dc.matmul.8: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [concatenate_152.dc.concatenate.0, model.model.model.17.cv3.conv.weight_0, model.model.model.17.cv3.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_79: {type: fused_op, grid_loc: [1, 3], grid_size: [1, 1], inputs: [conv2d_153.dc.matmul.8, dc.input_tensor.sigmoid_154.0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 79}}
    _fused_op_80: {type: fused_op, grid_loc: [1, 4], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_154.1, _fused_op_79, conv2d_153.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 386], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 3}}
    conv2d_156.dc.matmul.8: {type: matmul, grid_loc: [5, 6], grid_size: [1, 2], inputs: [_fused_op_80, model.model.model.24.m.0.weight_0, model.model.model.24.m.0.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_81_transpose_nop_11757: {type: nop, grid_loc: [6, 3], grid_size: [1, 1], inputs: [conv2d_156.dc.matmul.8],
         t: 8, mblock: [1, 25], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, vslice: 8]}
    _fused_op_81: {type: fused_op, grid_loc: [7, 1], grid_size: [1, 5], inputs: [_fused_op_81_transpose_nop_11757, dc.input_tensor.sigmoid_157.0],
         t: 8, mblock: [1, 5], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 50}, vslice: 8],
         attributes: {approximate_mode: false, fused_op_id: 81}}
    conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 6], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_80, lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [4, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 86, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 50}}
    conv2d_177.dc.matmul.11: {type: matmul, grid_loc: [1, 7], grid_size: [2, 1], inputs: [conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.18.conv.weight_0],
         t: 1, mblock: [4, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_177.dc.select.12: {type: splice, grid_loc: [2, 0], grid_size: [1, 1], inputs: [conv2d_177.dc.matmul.11],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    _fused_op_83: {type: fused_op, grid_loc: [2, 1], grid_size: [1, 1], inputs: [conv2d_177.dc.select.12, model.model.model.18.conv.bias_0, dc.input_tensor.sigmoid_178.0, dc.input_tensor.sigmoid_178.1],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 64}}
    concatenate_180.dc.concatenate.0: {type: splice, grid_loc: [2, 2], grid_size: [1, 1], inputs: [_fused_op_83, e2e__fused_op_70_0],
         t: 1, mblock: [13, 2], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_181.dc.matmul.8: {type: matmul, grid_loc: [2, 3], grid_size: [1, 1], inputs: [concatenate_180.dc.concatenate.0, model.model.model.20.cv1.conv.weight_0, model.model.model.20.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_84: {type: fused_op, grid_loc: [2, 4], grid_size: [1, 1], inputs: [conv2d_181.dc.matmul.8, dc.input_tensor.sigmoid_182.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_85: {type: fused_op, grid_loc: [2, 5], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_182.1, _fused_op_84, conv2d_181.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_184.dc.matmul.8: {type: matmul, grid_loc: [3, 0], grid_size: [1, 1], inputs: [_fused_op_85, model.model.model.20.m.0.cv1.conv.weight_0, model.model.model.20.m.0.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 2}}
    _fused_op_86: {type: fused_op, grid_loc: [3, 1], grid_size: [1, 1], inputs: [conv2d_184.dc.matmul.8, dc.input_tensor.sigmoid_185.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_87: {type: fused_op, grid_loc: [3, 2], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_185.1, _fused_op_86, conv2d_184.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_187.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [3, 3], grid_size: [1, 1], inputs: [_fused_op_87, dc.input_tensor.conv2d_187.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 4], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_187.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [4, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 33, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_187.dc.matmul.12: {type: matmul, grid_loc: [3, 5], grid_size: [2, 1], inputs: [conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.20.m.0.cv2.conv.weight_0],
         t: 1, mblock: [4, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_187.dc.select.13: {type: splice, grid_loc: [3, 6], grid_size: [1, 1], inputs: [conv2d_187.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    conv2d_190.dc.matmul.8: {type: matmul, grid_loc: [4, 0], grid_size: [1, 1], inputs: [concatenate_180.dc.concatenate.0, model.model.model.20.cv2.conv.weight_0, model.model.model.20.cv2.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [416, 0, 0], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_88: {type: fused_op, grid_loc: [3, 7], grid_size: [1, 1], inputs: [conv2d_187.dc.select.13, model.model.model.20.m.0.cv2.conv.bias_0, dc.input_tensor.sigmoid_188.0, dc.input_tensor.sigmoid_188.1],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 64}}
    _fused_op_89: {type: fused_op, grid_loc: [4, 1], grid_size: [1, 1], inputs: [conv2d_190.dc.matmul.8, dc.input_tensor.sigmoid_191.0],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_90: {type: fused_op, grid_loc: [4, 2], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_191.1, _fused_op_89, conv2d_190.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 410], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    concatenate_193.dc.concatenate.0: {type: splice, grid_loc: [4, 3], grid_size: [1, 1], inputs: [_fused_op_88, _fused_op_90],
         t: 1, mblock: [13, 2], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 388], input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_194.dc.matmul.8: {type: matmul, grid_loc: [4, 6], grid_size: [1, 1], inputs: [concatenate_193.dc.concatenate.0, model.model.model.20.cv3.conv.weight_0, model.model.model.20.cv3.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_91: {type: fused_op, grid_loc: [4, 7], grid_size: [1, 1], inputs: [conv2d_194.dc.matmul.8, dc.input_tensor.sigmoid_195.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 41}}
    _fused_op_92: {type: fused_op, grid_loc: [5, 0], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_195.1, _fused_op_91, conv2d_194.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 42}}
    conv2d_197.dc.matmul.8: {type: matmul, grid_loc: [6, 0], grid_size: [1, 1], inputs: [_fused_op_92, model.model.model.24.m.1.weight_0, model.model.model.24.m.1.bias_0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_93_transpose_nop_11808: {type: nop, grid_loc: [6, 4], grid_size: [1, 1], inputs: [conv2d_197.dc.matmul.8],
         t: 1, mblock: [4, 13], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    _fused_op_93: {type: fused_op, grid_loc: [7, 6], grid_size: [1, 1], inputs: [_fused_op_93_transpose_nop_11808, dc.input_tensor.sigmoid_198.0],
         t: 1, mblock: [4, 13], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 93}}
    conv2d_218.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [5, 1], grid_size: [1, 1], inputs: [_fused_op_92, dc.input_tensor.conv2d_218.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_218.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 137, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 16}}
    conv2d_218.dc.matmul.12: {type: matmul, grid_loc: [5, 3], grid_size: [1, 1], inputs: [conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.21.conv.weight_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 18}}
    _fused_op_95: {type: fused_op, grid_loc: [5, 4], grid_size: [1, 1], inputs: [conv2d_218.dc.matmul.12, model.model.model.21.conv.bias_0, dc.input_tensor.sigmoid_219.0, dc.input_tensor.sigmoid_219.1],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}],
         attributes: {approximate_mode: false, fused_op_id: 95}}
    concatenate_221.dc.concatenate.0: {type: splice, grid_loc: [5, 5], grid_size: [1, 1], inputs: [_fused_op_95, e2e__fused_op_59_0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 2, 2], input1: [0, 2, 2]}}
    conv2d_222.dc.matmul.8: {type: matmul, grid_loc: [6, 1], grid_size: [1, 1], inputs: [concatenate_221.dc.concatenate.0, model.model.model.23.cv1.conv.weight_0, model.model.model.23.cv1.conv.bias_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_96: {type: fused_op, grid_loc: [6, 5], grid_size: [1, 1], inputs: [conv2d_222.dc.matmul.8, dc.input_tensor.sigmoid_223.0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 96}}
    _fused_op_97: {type: fused_op, grid_loc: [6, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_223.1, _fused_op_96, conv2d_222.dc.matmul.8],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 97}}
    conv2d_225.dc.matmul.8: {type: matmul, grid_loc: [7, 7], grid_size: [1, 1], inputs: [_fused_op_97, model.model.model.23.m.0.cv1.conv.weight_0, model.model.model.23.m.0.cv1.conv.bias_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_98: {type: fused_op, grid_loc: [8, 0], grid_size: [1, 1], inputs: [conv2d_225.dc.matmul.8, dc.input_tensor.sigmoid_226.0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 96}}
    _fused_op_99: {type: fused_op, grid_loc: [8, 1], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_226.1, _fused_op_98, conv2d_225.dc.matmul.8],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 97}}
    conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [8, 2], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_99, lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 43, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 4}}
    conv2d_228.dc.matmul.11: {type: matmul, grid_loc: [8, 3], grid_size: [1, 1], inputs: [conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.23.m.0.cv2.conv.weight_0, model.model.model.23.m.0.cv2.conv.bias_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 18}}
    conv2d_231.dc.matmul.8: {type: matmul, grid_loc: [6, 2], grid_size: [1, 1], inputs: [concatenate_221.dc.concatenate.0, model.model.model.23.cv2.conv.weight_0, model.model.model.23.cv2.conv.bias_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [352, 0, 0], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_100: {type: fused_op, grid_loc: [8, 4], grid_size: [1, 1], inputs: [conv2d_228.dc.matmul.11, dc.input_tensor.sigmoid_229.0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 96}}
    _fused_op_101: {type: fused_op, grid_loc: [8, 5], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_229.1, _fused_op_100, conv2d_228.dc.matmul.11],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 97}}
    _fused_op_102: {type: fused_op, grid_loc: [6, 7], grid_size: [1, 1], inputs: [conv2d_231.dc.matmul.8, dc.input_tensor.sigmoid_232.0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 96}}
    _fused_op_103: {type: fused_op, grid_loc: [7, 0], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_232.1, _fused_op_102, conv2d_231.dc.matmul.8],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 97}}
    concatenate_234.dc.concatenate.0: {type: splice, grid_loc: [8, 6], grid_size: [1, 1], inputs: [_fused_op_101, _fused_op_103],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 416], input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 2, 2], input1: [0, 2, 2]}}

  fwd_0_6_temporal_epoch_6:
    target_device: 0
    input_count: 1
    _fused_op_82: {type: fused_op, grid_loc: [0, 0], grid_size: [4, 2], inputs: [dc.input_tensor.sigmoid_157.1, e2e__fused_op_81_0, input_1_multiply_158, input_2_concatenate_160, input_1_multiply_164, input_1_concatenate_165, input_1_multiply_168, input_1_multiply_171],
         t: 1, mblock: [1, 25], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0, 0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_4_tms: [broadcast: {c: 50}], input_2_tms: [broadcast: {c: 50}], input_1_tms: [vstack: 8], input_0_tms: [broadcast: {c: 50}],
         attributes: {approximate_mode: false, fused_op_id: 82}}
    reshape_174.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [0, 4], grid_size: [3, 1], inputs: [lc.input_tensor.reshape_174.dc.sparse_matmul.3.0, _fused_op_82, lc.input_tensor.reshape_174.dc.sparse_matmul.3.1],
         t: 1, mblock: [1, 25], ublock: [3, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 8, num_index_tiles: 1, num_sparse_tiles: 4, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 1}}
    _fused_op_94: {type: fused_op, grid_loc: [0, 2], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_198.1, e2e__fused_op_93_0, input_1_multiply_199, input_2_concatenate_201, input_1_multiply_205, input_1_concatenate_206, input_1_multiply_209, input_1_multiply_212],
         t: 1, mblock: [1, 13], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0, 0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 94}}
    reshape_215.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [0, 5], grid_size: [3, 1], inputs: [lc.input_tensor.reshape_215.dc.sparse_matmul.3.0, _fused_op_94, lc.input_tensor.reshape_215.dc.sparse_matmul.3.1],
         t: 1, mblock: [1, 13], ublock: [3, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 4, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 8}}
    reshape_217.dc.sparse_matmul.4.lc2: {type: matmul, grid_loc: [3, 5], grid_size: [2, 1], inputs: [lc.input_tensor.reshape_217.dc.sparse_matmul.4.0, reshape_215.dc.sparse_matmul.3.lc2, lc.input_tensor.reshape_217.dc.sparse_matmul.4.1],
         t: 1, mblock: [19, 1], ublock: [1, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose, hslice: 3, vstack: 3],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 3, num_index_tiles: 1, num_sparse_tiles: 5, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 13}}
    conv2d_235.dc.matmul.8: {type: matmul, grid_loc: [0, 3], grid_size: [4, 1], inputs: [e2e_concatenate_234.dc.concatenate.0_0, model.model.model.23.cv3.conv.weight_0, model.model.model.23.cv3.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_104: {type: fused_op, grid_loc: [0, 6], grid_size: [4, 1], inputs: [conv2d_235.dc.matmul.8, dc.input_tensor.sigmoid_236.0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 104}}
    _fused_op_105: {type: fused_op, grid_loc: [0, 7], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_236.1, _fused_op_104, conv2d_235.dc.matmul.8],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 456], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 105}}
    conv2d_238.dc.matmul.8: {type: matmul, grid_loc: [4, 0], grid_size: [4, 1], inputs: [_fused_op_105, model.model.model.24.m.2.weight_0, model.model.model.24.m.2.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_106_transpose_nop_11860: {type: nop, grid_loc: [4, 2], grid_size: [4, 1], inputs: [conv2d_238.dc.matmul.8],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    _fused_op_106: {type: fused_op, grid_loc: [4, 3], grid_size: [4, 1], inputs: [_fused_op_106_transpose_nop_11860, dc.input_tensor.sigmoid_239.0],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_107: {type: fused_op, grid_loc: [4, 6], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_239.1, _fused_op_106, input_1_multiply_240, input_2_concatenate_242, input_1_multiply_246, input_1_concatenate_247, input_1_multiply_250, input_1_multiply_253],
         t: 1, mblock: [1, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 107}}
    reshape_256.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [4, 7], grid_size: [3, 1], inputs: [lc.input_tensor.reshape_256.dc.sparse_matmul.3.0, _fused_op_107, lc.input_tensor.reshape_256.dc.sparse_matmul.3.1],
         t: 1, mblock: [1, 2], ublock: [3, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 4, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 4}}
    concatenate_259.dc.concatenate.2_transpose_nop_11336: {type: nop, grid_loc: [3, 4], grid_size: [3, 1], inputs: [reshape_174.dc.sparse_matmul.3.lc2],
         t: 3, mblock: [1, 25], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 3]}
    concatenate_259.dc.concatenate.2_transpose_nop_2_11336: {type: nop, grid_loc: [4, 1], grid_size: [5, 1], inputs: [concatenate_259.dc.concatenate.2_transpose_nop_11336],
         t: 3, mblock: [5, 3], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}

  fwd_0_7_temporal_epoch_7:
    target_device: 0
    input_count: 1
    reshape_258.dc.sparse_matmul.4.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [1, 1], inputs: [lc.input_tensor.reshape_258.dc.sparse_matmul.4.0, e2e_reshape_256.dc.sparse_matmul.3.lc2_0, lc.input_tensor.reshape_258.dc.sparse_matmul.4.1],
         t: 1, mblock: [5, 1], ublock: [2, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose, hslice: 3, vstack: 3],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 3, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 4}}
    concatenate_259.dc.concatenate.2: {type: splice, grid_loc: [0, 1], grid_size: [1, 3], inputs: [e2e_concatenate_259.dc.concatenate.2_transpose_nop_2_11336_0, e2e_reshape_217.dc.sparse_matmul.4.lc2_0, reshape_258.dc.sparse_matmul.4.lc2],
         t: 1, mblock: [99, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [24, 24, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 3],
         attributes: {input0: [0, 75, 75], input1: [0, 19, 19], input2: [0, 5, 5]}}
    concatenate_259.dc.sparse_matmul.4.lc2: {type: matmul, grid_loc: [0, 4], grid_size: [1, 3], inputs: [lc.input_tensor.concatenate_259.dc.sparse_matmul.4.0, concatenate_259.dc.concatenate.2, lc.input_tensor.concatenate_259.dc.sparse_matmul.4.1],
         t: 1, mblock: [197, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 3}], input_0_tms: [broadcast: {c: 3}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 6, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 33}}
    concatenate_259.dc.sparse_matmul.4.lc2_output_nop_0: {type: nop, grid_loc: [1, 0], grid_size: [1, 3], inputs: [concatenate_259.dc.sparse_matmul.4.lc2], untilize_output: true,
         t: 1, mblock: [197, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}


programs:
  - run_fwd_0:
    - param: [$p_loop_count]
    - var: {$gptr_q1: 0, $lptr_q2: 0, $lptr_q1: 0, $c_zero: 0, $c_one: 1, $lptr_q7: 0, $c_microbatch_size: 1, $gptr_q6: 0, $lptr_q6: 0, $lptr_q5: 0, $gptr_q5: 0, $gptr_q2: 0, $gptr_q3: 0, $lptr_q4: 0, $lptr_q3: 0, $gptr_q7: 0, $gptr_q4: 0}
    - staticvar: {$gptr_q0: 0, $lptr_q0: 0}
    - loop: $p_loop_count
    -   allocate_queue: [e2e_conv2d_6.dc.matmul.8_0, e2e_conv2d_16.dc.matmul.8_0]
    -   execute: {graph_name: fwd_0_0_temporal_epoch_0, queue_settings: {
               ims_1: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.0.conv.weight_0_fork_clone1818: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.0.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.0.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.0.conv.weight_0_fork_clone1816: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.1.conv.weight_0_fork_clone430: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.1.conv.weight_0_fork_clone428: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q0, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q0, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_conv2d_20.dc.matmul.8_transpose_nop_11161_0]
    -   execute: {graph_name: fwd_0_1_temporal_epoch_1, queue_settings: {
               e2e_conv2d_6.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               e2e_conv2d_16.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               dc.input_tensor.sigmoid_7.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_7.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_10.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_10.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.weight_0_fork_clone488: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.weight_0_fork_clone486: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_13.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_13.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_17.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_17.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.concatenate_19.dc.sparse_matmul.5.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.concatenate_19.dc.sparse_matmul.5.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_6.dc.matmul.8_0, e2e_conv2d_16.dc.matmul.8_0]
    -   varinst: [$gptr_q1, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q1, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_27_0, e2e__fused_op_32_0, e2e_conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0, e2e__fused_op_26_0]
    -   execute: {graph_name: fwd_0_2_temporal_epoch_2, queue_settings: {
               e2e_conv2d_20.dc.matmul.8_transpose_nop_11161_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               model.model.model.2.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_21.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_21.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_24.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_24.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_27.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_27.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_30.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_30.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_33.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_33.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.1.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.1.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_37.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_37.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.1.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.1.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_40.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_40.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_44.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_44.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_48.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_48.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.5.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.5.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_51.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_51.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_54.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_54.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_57.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_57.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_59.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_60.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_60.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.1.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.1.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_64.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_64.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_66.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_20.dc.matmul.8_transpose_nop_11161_0]
    -   varinst: [$gptr_q2, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q2, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_42_0, e2e__fused_op_55_0]
    -   execute: {graph_name: fwd_0_3_temporal_epoch_3, queue_settings: {
               e2e__fused_op_27_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e__fused_op_32_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.1.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.1.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_67.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_67.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.2.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.2.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_71.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_71.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_73.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.2.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.2.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_74.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_74.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_78.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_78.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_82.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_82.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_84.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.7.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.7.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_85.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_85.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_88.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_88.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_91.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_91.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_94.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_94.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_98.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_98.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_102.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_102.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.9.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.9.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_105.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_105.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_27_0, e2e__fused_op_32_0, e2e_conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0]
    -   varinst: [$gptr_q3, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q3, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_59_0, e2e__fused_op_70_0, e2e_concatenate_139.dc.concatenate.0_0, e2e__fused_op_74_0]
    -   execute: {graph_name: fwd_0_4_temporal_epoch_4, queue_settings: {
               e2e__fused_op_26_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               e2e__fused_op_42_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               e2e__fused_op_55_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.9.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.9.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_112.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_112.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.10.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.10.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_115.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_115.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_117.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_117.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_120.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_120.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_123.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_123.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_125.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_126.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_126.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_129.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_129.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_133.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_133.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.14.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.14.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_136.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_136.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_138.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_138.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_141.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_141.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_144.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_144.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_26_0, e2e__fused_op_42_0, e2e__fused_op_55_0]
    -   varinst: [$gptr_q4, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q4, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_81_0, e2e__fused_op_93_0, e2e_concatenate_234.dc.concatenate.0_0]
    -   execute: {graph_name: fwd_0_5_temporal_epoch_5, queue_settings: {
               e2e__fused_op_59_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e__fused_op_70_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_concatenate_139.dc.concatenate.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e__fused_op_74_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_147.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_147.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_150.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_150.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_154.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_154.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.24.m.0.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.24.m.0.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_157.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.18.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.18.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_178.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_178.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_182.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_182.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_185.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_185.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_187.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_188.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_188.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_191.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_191.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_195.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_195.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.24.m.1.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.24.m.1.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_198.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_218.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.21.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.21.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_219.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_219.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_223.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_223.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_226.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_226.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_229.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_229.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_232.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_232.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_59_0, e2e__fused_op_70_0, e2e_concatenate_139.dc.concatenate.0_0, e2e__fused_op_74_0]
    -   varinst: [$gptr_q5, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q5, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e_reshape_217.dc.sparse_matmul.4.lc2_0, e2e_reshape_256.dc.sparse_matmul.3.lc2_0, e2e_concatenate_259.dc.concatenate.2_transpose_nop_2_11336_0]
    -   execute: {graph_name: fwd_0_6_temporal_epoch_6, queue_settings: {
               e2e__fused_op_81_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e__fused_op_93_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e_concatenate_234.dc.concatenate.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               dc.input_tensor.sigmoid_157.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_158: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_2_concatenate_160: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_164: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_concatenate_165: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_168: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_171: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_174.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_174.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_198.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_199: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_2_concatenate_201: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_205: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_concatenate_206: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_209: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_212: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_215.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_215.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_217.dc.sparse_matmul.4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_217.dc.sparse_matmul.4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_236.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_236.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.24.m.2.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.24.m.2.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_239.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_239.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_240: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_2_concatenate_242: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_246: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_concatenate_247: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_250: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_253: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_256.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_256.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_81_0, e2e__fused_op_93_0, e2e_concatenate_234.dc.concatenate.0_0]
    -   varinst: [$gptr_q6, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q6, incwrap, $c_microbatch_size, 2]
    -   execute: {graph_name: fwd_0_7_temporal_epoch_7, queue_settings: {
               e2e_reshape_217.dc.sparse_matmul.4.lc2_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_reshape_256.dc.sparse_matmul.3.lc2_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_concatenate_259.dc.concatenate.2_transpose_nop_2_11336_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               lc.input_tensor.reshape_258.dc.sparse_matmul.4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_258.dc.sparse_matmul.4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.concatenate_259.dc.sparse_matmul.4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.concatenate_259.dc.sparse_matmul.4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_reshape_217.dc.sparse_matmul.4.lc2_0, e2e_reshape_256.dc.sparse_matmul.3.lc2_0, e2e_concatenate_259.dc.concatenate.2_transpose_nop_2_11336_0]
    -   varinst: [$gptr_q7, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q7, incwrap, $c_microbatch_size, 2]
    - endloop


fused_ops:
  0: 
    inputs: 5
    intermediates: 1
    schedules: 
      -
        - conv2d_0.dc.conv2d.3.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [4, 1], ublock: [2, 1], output: dest}
        - conv2d_0.dc.conv2d.3.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [4, 1], ublock: [2, 1], output: intermed0}
        - sigmoid_1.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input3], mblock: [4, 1], ublock: [2, 1], output: dest}
        - sigmoid_1.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [4, 1], ublock: [2, 1], output: dest}
        - sigmoid_1.dc.add.4.0: { type: add, inputs: [input4, dest], mblock: [4, 1], ublock: [2, 1], output: dest}
        - sigmoid_1.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [4, 1], ublock: [2, 1], output: dest}
        - multiply_2.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [4, 1], ublock: [2, 1], output: output}
  1: 
    inputs: 5
    intermediates: 1
    schedules: 
      -
        - conv2d_3.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 1], output: dest}
        - conv2d_3.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [25, 1], ublock: [1, 1], output: intermed0}
        - sigmoid_4.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input3], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_4.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_4.dc.add.4.0: { type: add, inputs: [input4, dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_4.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - multiply_5.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [25, 1], ublock: [1, 1], output: output}
  2: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_7.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [25, 1], ublock: [2, 1], output: dest}
        - sigmoid_7.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [2, 1], output: output}
  3: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_7.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [2, 1], output: dest}
        - sigmoid_7.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [2, 1], output: dest}
        - multiply_8.0: { type: multiply, inputs: [input2, dest], mblock: [25, 1], ublock: [2, 1], output: output}
  6: 
    inputs: 6
    intermediates: 1
    schedules: 
      -
        - conv2d_12.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [5, 1], ublock: [1, 1], output: dest}
        - conv2d_12.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [5, 1], ublock: [1, 1], output: intermed0}
        - sigmoid_13.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input3], mblock: [5, 1], ublock: [1, 1], output: dest}
        - sigmoid_13.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [5, 1], ublock: [1, 1], output: dest}
        - sigmoid_13.dc.add.4.0: { type: add, inputs: [input4, dest], mblock: [5, 1], ublock: [1, 1], output: dest}
        - sigmoid_13.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [5, 1], ublock: [1, 1], output: dest}
        - multiply_14.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [5, 1], ublock: [1, 1], output: dest}
        - add_15.0: { type: add, inputs: [input5, dest], mblock: [5, 1], ublock: [1, 1], output: output}
  9: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_21.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [100, 1], ublock: [2, 1], output: dest}
        - sigmoid_21.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [100, 1], ublock: [2, 1], output: output}
  10: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_21.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [100, 1], ublock: [2, 1], output: dest}
        - sigmoid_21.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [100, 1], ublock: [2, 1], output: dest}
        - multiply_22.0: { type: multiply, inputs: [input2, dest], mblock: [100, 1], ublock: [2, 1], output: output}
  11: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_24.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 1], ublock: [1, 2], output: dest}
        - sigmoid_24.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 1], ublock: [1, 2], output: output}
  12: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_24.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 1], ublock: [1, 1], output: dest}
        - sigmoid_24.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 1], ublock: [1, 1], output: dest}
        - multiply_25.0: { type: multiply, inputs: [input2, dest], mblock: [1, 1], ublock: [1, 1], output: output}
  13: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_27.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 1], ublock: [1, 1], output: dest}
        - sigmoid_27.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 1], ublock: [1, 1], output: output}
  18: 
    inputs: 4
    intermediates: 0
    schedules: 
      -
        - sigmoid_33.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 1], ublock: [1, 1], output: dest}
        - sigmoid_33.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 1], ublock: [1, 1], output: dest}
        - multiply_34.0: { type: multiply, inputs: [input2, dest], mblock: [1, 1], ublock: [1, 1], output: dest}
        - add_35.0: { type: add, inputs: [input3, dest], mblock: [1, 1], ublock: [1, 1], output: output}
  26: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_48.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 2], output: dest}
        - sigmoid_48.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [1, 2], output: dest}
        - multiply_49.0: { type: multiply, inputs: [input2, dest], mblock: [25, 1], ublock: [1, 2], output: output}
  27: 
    inputs: 4
    intermediates: 1
    schedules: 
      -
        - conv2d_50.dc.add.17.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 4], output: intermed0}
        - sigmoid_51.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_51.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_51.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_51.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - multiply_52.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [13, 1], ublock: [1, 4], output: output}
  28: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_54.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_54.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 2], output: output}
  29: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_54.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_54.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 2], output: dest}
        - multiply_55.0: { type: multiply, inputs: [input2, dest], mblock: [13, 1], ublock: [1, 2], output: output}
  32: 
    inputs: 5
    intermediates: 1
    schedules: 
      -
        - conv2d_59.dc.add.18.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 2], output: intermed0}
        - sigmoid_60.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_60.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_60.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_60.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 2], output: dest}
        - multiply_61.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [13, 1], ublock: [1, 2], output: dest}
        - add_62.0: { type: add, inputs: [input4, dest], mblock: [13, 1], ublock: [1, 2], output: output}
  41: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_82.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_82.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: output}
  42: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_82.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_82.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - multiply_83.0: { type: multiply, inputs: [input2, dest], mblock: [13, 1], ublock: [1, 4], output: output}
  43: 
    inputs: 4
    intermediates: 1
    schedules: 
      -
        - conv2d_84.dc.add.18.0: { type: add, inputs: [input0, input1], mblock: [1, 2], ublock: [2, 4], output: intermed0}
        - sigmoid_85.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 2], ublock: [2, 4], output: dest}
        - sigmoid_85.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 2], ublock: [2, 4], output: dest}
        - sigmoid_85.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [1, 2], ublock: [2, 4], output: dest}
        - sigmoid_85.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 2], ublock: [2, 4], output: dest}
        - multiply_86.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [1, 2], ublock: [2, 4], output: output}
  44: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_88.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 1], ublock: [2, 4], output: dest}
        - sigmoid_88.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 1], ublock: [2, 4], output: output}
  45: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_88.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 1], ublock: [2, 4], output: dest}
        - sigmoid_88.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 1], ublock: [2, 4], output: dest}
        - multiply_89.0: { type: multiply, inputs: [input2, dest], mblock: [1, 1], ublock: [2, 4], output: output}
  49: 
    inputs: 4
    intermediates: 0
    schedules: 
      -
        - sigmoid_94.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 1], ublock: [2, 4], output: dest}
        - sigmoid_94.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 1], ublock: [2, 4], output: dest}
        - multiply_95.0: { type: multiply, inputs: [input2, dest], mblock: [1, 1], ublock: [2, 4], output: dest}
        - add_96.0: { type: add, inputs: [input3, dest], mblock: [1, 1], ublock: [2, 4], output: output}
  52: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_102.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 2], ublock: [2, 4], output: dest}
        - sigmoid_102.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 2], ublock: [2, 4], output: output}
  53: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_102.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 2], ublock: [2, 4], output: dest}
        - sigmoid_102.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 2], ublock: [2, 4], output: dest}
        - multiply_103.0: { type: multiply, inputs: [input2, dest], mblock: [1, 2], ublock: [2, 4], output: output}
  64: 
    inputs: 4
    intermediates: 1
    schedules: 
      -
        - conv2d_125.dc.add.18.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 2], output: intermed0}
        - sigmoid_126.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_126.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_126.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [13, 1], ublock: [1, 2], output: dest}
        - sigmoid_126.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 2], output: dest}
        - multiply_127.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [13, 1], ublock: [1, 2], output: output}
  71: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_141.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_141.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: output}
  72: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_141.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_141.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - multiply_142.0: { type: multiply, inputs: [input2, dest], mblock: [25, 1], ublock: [1, 1], output: output}
  79: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_154.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [25, 1], ublock: [2, 2], output: dest}
        - sigmoid_154.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [2, 2], output: output}
  81: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_157.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 5], ublock: [1, 2], output: dest}
        - sigmoid_157.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 5], ublock: [1, 2], output: output}
  82: 
    inputs: 8
    intermediates: 2
    schedules: 
      -
        - sigmoid_157.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 25], ublock: [2, 1], output: dest}
        - sigmoid_157.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 25], ublock: [2, 1], output: intermed0}
        - multiply_158.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 25], ublock: [2, 1], output: intermed1}
        - multiply_159.0: { type: multiply, inputs: [intermed1, intermed1], pop: [intermed1], mblock: [1, 25], ublock: [2, 1], output: dest}
        - multiply_162.0: { type: multiply, inputs: [dest, input3], mblock: [1, 25], ublock: [2, 1], output: intermed1}
        - multiply_164.0: { type: multiply, inputs: [intermed0, input4], mblock: [1, 25], ublock: [2, 1], output: dest}
        - add_167.0: { type: add, inputs: [dest, input5], mblock: [1, 25], ublock: [2, 1], output: dest}
        - multiply_168.0: { type: multiply, inputs: [dest, input6], mblock: [1, 25], ublock: [2, 1], output: dest}
        - add_170.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 25], ublock: [2, 1], output: intermed1}
        - multiply_171.0: { type: multiply, inputs: [intermed0, input7], pop: [intermed0], mblock: [1, 25], ublock: [2, 1], output: dest}
        - add_172.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 25], ublock: [2, 1], output: output}
  93: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_198.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [4, 13], ublock: [2, 1], output: dest}
        - sigmoid_198.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [4, 13], ublock: [2, 1], output: output}
  94: 
    inputs: 8
    intermediates: 2
    schedules: 
      -
        - sigmoid_198.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 13], ublock: [2, 1], output: dest}
        - sigmoid_198.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 13], ublock: [2, 1], output: intermed0}
        - multiply_199.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 13], ublock: [2, 1], output: intermed1}
        - multiply_200.0: { type: multiply, inputs: [intermed1, intermed1], pop: [intermed1], mblock: [1, 13], ublock: [2, 1], output: dest}
        - multiply_203.0: { type: multiply, inputs: [dest, input3], mblock: [1, 13], ublock: [2, 1], output: intermed1}
        - multiply_205.0: { type: multiply, inputs: [intermed0, input4], mblock: [1, 13], ublock: [2, 1], output: dest}
        - add_208.0: { type: add, inputs: [dest, input5], mblock: [1, 13], ublock: [2, 1], output: dest}
        - multiply_209.0: { type: multiply, inputs: [dest, input6], mblock: [1, 13], ublock: [2, 1], output: dest}
        - add_211.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 13], ublock: [2, 1], output: intermed1}
        - multiply_212.0: { type: multiply, inputs: [intermed0, input7], pop: [intermed0], mblock: [1, 13], ublock: [2, 1], output: dest}
        - add_213.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 13], ublock: [2, 1], output: output}
  95: 
    inputs: 4
    intermediates: 1
    schedules: 
      -
        - conv2d_218.dc.add.18.0: { type: add, inputs: [input0, input1], mblock: [2, 1], ublock: [2, 4], output: intermed0}
        - sigmoid_219.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [2, 1], ublock: [2, 4], output: dest}
        - sigmoid_219.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [2, 1], ublock: [2, 4], output: dest}
        - sigmoid_219.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [2, 1], ublock: [2, 4], output: dest}
        - sigmoid_219.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [2, 1], ublock: [2, 4], output: dest}
        - multiply_220.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [2, 1], ublock: [2, 4], output: output}
  96: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_223.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [2, 1], ublock: [2, 4], output: dest}
        - sigmoid_223.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [2, 1], ublock: [2, 4], output: output}
  97: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_223.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [2, 1], ublock: [2, 4], output: dest}
        - sigmoid_223.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [2, 1], ublock: [2, 4], output: dest}
        - multiply_224.0: { type: multiply, inputs: [input2, dest], mblock: [2, 1], ublock: [2, 4], output: output}
  104: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_236.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 2], ublock: [1, 4], output: dest}
        - sigmoid_236.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 2], ublock: [1, 4], output: output}
  105: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_236.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 2], ublock: [1, 4], output: dest}
        - sigmoid_236.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 2], ublock: [1, 4], output: dest}
        - multiply_237.0: { type: multiply, inputs: [input2, dest], mblock: [1, 2], ublock: [1, 4], output: output}
  107: 
    inputs: 8
    intermediates: 2
    schedules: 
      -
        - sigmoid_239.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 1], ublock: [2, 4], output: dest}
        - sigmoid_239.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 1], ublock: [2, 4], output: intermed0}
        - multiply_240.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 1], ublock: [2, 4], output: intermed1}
        - multiply_241.0: { type: multiply, inputs: [intermed1, intermed1], pop: [intermed1], mblock: [1, 1], ublock: [2, 4], output: dest}
        - multiply_244.0: { type: multiply, inputs: [dest, input3], mblock: [1, 1], ublock: [2, 4], output: intermed1}
        - multiply_246.0: { type: multiply, inputs: [intermed0, input4], mblock: [1, 1], ublock: [2, 4], output: dest}
        - add_249.0: { type: add, inputs: [dest, input5], mblock: [1, 1], ublock: [2, 4], output: dest}
        - multiply_250.0: { type: multiply, inputs: [dest, input6], mblock: [1, 1], ublock: [2, 4], output: dest}
        - add_252.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 1], ublock: [2, 4], output: intermed1}
        - multiply_253.0: { type: multiply, inputs: [intermed0, input7], pop: [intermed0], mblock: [1, 1], ublock: [2, 4], output: dest}
        - add_254.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 1], ublock: [2, 4], output: output}
