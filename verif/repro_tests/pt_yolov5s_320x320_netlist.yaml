# git checkout 4d373f6ae
# pytest pybuda/test/model_demos/high_prio/cnn/pytorch/test_yolo_v5.py::test_yolov5_320x320[Wormhole_B0-yolov5s]

devices:
  arch: wormhole_b0

queues:

  # input
  ims_1:                                                                                     {input: HOST, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 800], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x20]]}

  # output
  pt_yolov5s_320x320.output_concatenate_259:                                                 {input: concatenate_259.dc.sparse_matmul.4.lc2_output_nop_0, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [197, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x32c860]]}

  # parameter
  model.model.model.0.conv.weight_0_fork_clone1818:                                          {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33c4aa0], [5, 0x401a91a0], [0, 0x234c0e0]]}
  model.model.model.0.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x34b99c0], [1, 0x40296040], [2, 0x23e3100]]}
  model.model.model.0.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4033e300]]}
  model.model.model.0.conv.weight_0_fork_clone1816:                                          {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x33e4c40], [1, 0x401da920], [2, 0x2328800]]}
  model.model.model.1.conv.weight_0_fork_clone430:                                           {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40133b20], [4, 0x6d57e20], [4, 0x40166880]]}
  model.model.model.1.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2326b20], [2, 0x4028b1a0], [3, 0x6e43c00]]}
  model.model.model.1.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x401d8c40]]}
  model.model.model.1.conv.weight_0_fork_clone428:                                           {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x233e080], [0, 0x4018aae0], [1, 0x33e22e0]]}
  model.model.model.2.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x401322a0], [4, 0x6d565a0]]}
  model.model.model.2.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6e42380]]}
  model.model.model.2.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33b6e60]]}
  model.model.model.2.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x401647c0]]}
  model.model.model.2.m.0.cv2.conv.weight_0_fork_clone488:                                   {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x401699a0], [5, 0x33bc040], [5, 0x401a0740]]}
  model.model.model.2.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33bb800], [5, 0x4019ff00], [0, 0x2342640]]}
  model.model.model.2.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d5a700]]}
  model.model.model.2.m.0.cv2.conv.weight_0_fork_clone486:                                   {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4019f6c0], [0, 0x2341e00], [0, 0x4018e040]]}
  model.model.model.2.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40135bc0], [4, 0x6d59ec0]]}
  model.model.model.2.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6e45ca0]]}
  model.model.model.2.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4019e660], [0, 0x2340da0]]}
  model.model.model.2.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33b9f60]]}
  model.model.model.3.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [18, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4026f3a0], [3, 0x6e25560]]}
  model.model.model.3.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x401c94e0], [2, 0x2317000]]}
  model.model.model.4.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33a71a0]]}
  model.model.model.4.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4015e5c0]]}
  model.model.model.4.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6e234c0]]}
  model.model.model.4.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4026e340]]}
  model.model.model.4.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [6, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x33cf860], [1, 0x401c22e0], [2, 0x230fe00]]}
  model.model.model.4.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40182300]]}
  model.model.model.4.m.1.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4012b880]]}
  model.model.model.4.m.1.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x402888c0]]}
  model.model.model.4.m.1.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [6, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x33d9be0], [1, 0x401cfd80], [2, 0x231e0a0]]}
  model.model.model.4.m.1.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40162720]]}
  model.model.model.4.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6e3c9e0]]}
  model.model.model.4.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40286820]]}
  model.model.model.4.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33ac320]]}
  model.model.model.4.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40160680]]}
  model.model.model.5.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x23e3940], [2, 0x4033eb40], [3, 0x6f0e720], [3, 0x401cc520]]}
  model.model.model.5.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x34ba200], [1, 0x40296880]]}
  model.model.model.6.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40218960]]}
  model.model.model.6.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6df9040]]}
  model.model.model.6.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401cb860]]}
  model.model.model.6.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x23b7460]]}
  model.model.model.6.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40200320], [5, 0x3418360], [5, 0x40219660], [0, 0x23a4fc0]]}
  model.model.model.6.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6df52a0]]}
  model.model.model.6.m.1.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401d4ac0]]}
  model.model.model.6.m.1.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x402749e0]]}
  model.model.model.6.m.1.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4022aa80], [5, 0x3461240], [5, 0x40262540], [0, 0x23d58a0]]}
  model.model.model.6.m.1.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6e15780]]}
  model.model.model.6.m.2.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40363460]]}
  model.model.model.6.m.2.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2408260]]}
  model.model.model.6.m.2.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6dc9420], [4, 0x401c81a0], [5, 0x33e01e0], [5, 0x401de720]]}
  model.model.model.6.m.2.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40185b20]]}
  model.model.model.6.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4019dc80]]}
  model.model.model.6.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2381640]]}
  model.model.model.6.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d5be80]]}
  model.model.model.6.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40199b60]]}
  model.model.model.7.conv.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [4, 2], t: 1, mblock: [3, 2], ublock: [6, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x33e8560], [1, 0x401de240], [2, 0x232bae0], [2, 0x40290060], [3, 0x6e48e80], [3, 0x40138da0], [4, 0x6d7c6a0], [4, 0x40172400]]}
  model.model.model.7.conv.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40190900]]}
  model.model.model.8.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x401eff00], [5, 0x3407f40], [5, 0x40209240], [0, 0x2394ba0]]}
  model.model.model.8.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6df1180]]}
  model.model.model.8.m.0.cv1.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6de8f60], [4, 0x401e7ce0], [5, 0x33ffd20], [5, 0x40201020]]}
  model.model.model.8.m.0.cv1.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4018d8a0]]}
  model.model.model.8.m.0.cv2.conv.weight_0:                                                 {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [3, 2], ublock: [6, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x34664e0], [1, 0x40242b60], [2, 0x238fc20], [2, 0x402ea160]]}
  model.model.model.8.m.0.cv2.conv.bias_0:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401bf500]]}
  model.model.model.8.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401af0e0], [1, 0x34560c0], [1, 0x40232740], [2, 0x237f800]]}
  model.model.model.8.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2384720]]}
  model.model.model.8.cv3.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [2, 4], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40094b60], [2, 0x221d680]]}
  model.model.model.8.cv3.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x330eda0]]}
  model.model.model.9.cv1.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [2, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c9d900], [4, 0x40048e40]]}
  model.model.model.9.cv1.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40063180]]}
  model.model.model.9.cv2.conv.weight_0:                                                     {input: HOST, type: ram, entries: 1, grid_size: [2, 2], t: 1, mblock: [4, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400669a0], [0, 0x2200cc0], [0, 0x40067e20], [1, 0x32c6f60]]}
  model.model.model.9.cv2.conv.bias_0:                                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4003cb00], [5, 0x32af8e0]]}
  model.model.model.10.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [2, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4006b0e0], [2, 0x21f3c00]]}
  model.model.model.10.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32c2e40]]}
  model.model.model.13.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [16, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2256ee0]]}
  model.model.model.13.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400d51c0]]}
  model.model.model.13.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cc1200]]}
  model.model.model.13.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40082980]]}
  model.model.model.13.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400c0080], [1, 0x3316fc0], [1, 0x400d5b80], [2, 0x225e6a0]]}
  model.model.model.13.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2253140]]}
  model.model.model.13.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [16, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40069660]]}
  model.model.model.13.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cbe120]]}
  model.model.model.13.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4005ed80]]}
  model.model.model.13.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400023c0]]}
  model.model.model.14.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400020a0]]}
  model.model.model.14.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x21a21a0]]}
  model.model.model.17.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40001360]]}
  model.model.model.17.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3251460]]}
  model.model.model.17.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c21140]]}
  model.model.model.17.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40001040]]}
  model.model.model.17.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [6, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21a0100], [0, 0x40000000], [1, 0x3250100]]}
  model.model.model.17.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40000000]]}
  model.model.model.17.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c72e40]]}
  model.model.model.17.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4007f5a0]]}
  model.model.model.17.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400579e0]]}
  model.model.model.17.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21f6a00]]}
  model.model.model.24.m.0.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32524c0], [5, 0x40009580]]}
  model.model.model.24.m.0.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40068800], [2, 0x21f0b00]]}
  model.model.model.18.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400fcd00], [5, 0x3369960], [5, 0x401586c0], [0, 0x22d3920]]}
  model.model.model.18.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cfc140]]}
  model.model.model.20.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40208580]]}
  model.model.model.20.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22df300]]}
  model.model.model.20.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4015a1c0]]}
  model.model.model.20.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22dc220]]}
  model.model.model.20.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400e46c0], [5, 0x333ce20], [5, 0x4012bb80], [0, 0x22bf3e0]]}
  model.model.model.20.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cf83a0]]}
  model.model.model.20.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x401f6460]]}
  model.model.model.20.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22d1880]]}
  model.model.model.20.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4010a020]]}
  model.model.model.20.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6e1e360]]}
  model.model.model.24.m.1.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x33af040]]}
  model.model.model.24.m.1.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4017e1e0]]}
  model.model.model.21.conv.weight_0:                                                        {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [4, 2], ublock: [9, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4014f640], [3, 0x6d216a0]]}
  model.model.model.21.conv.bias_0:                                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22c2fe0]]}
  model.model.model.23.cv1.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400d9a20]]}
  model.model.model.23.cv1.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x227cb80]]}
  model.model.model.23.m.0.cv1.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400ab380]]}
  model.model.model.23.m.0.cv1.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400e9060]]}
  model.model.model.23.m.0.cv2.conv.weight_0:                                                {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [3, 2], ublock: [6, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400ed180], [2, 0x2275ca0], [2, 0x40102300], [3, 0x6cd4360]]}
  model.model.model.23.m.0.cv2.conv.bias_0:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x332c040]]}
  model.model.model.23.cv2.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [8, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400c12e0]]}
  model.model.model.23.cv2.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2271b80]]}
  model.model.model.23.cv3.conv.weight_0:                                                    {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 4], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4010b360], [0, 0x229ebc0], [0, 0x40138960], [1, 0x3356a00]]}
  model.model.model.23.cv3.conv.bias_0:                                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3334c00]]}
  model.model.model.24.m.2.weight_0:                                                         {input: HOST, type: ram, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [4, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33247e0], [5, 0x400faf40], [0, 0x228e7a0], [0, 0x40128540]]}
  model.model.model.24.m.2.bias_0:                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400d8380]]}

  # constant
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 6], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x237efa0], [2, 0x402e57e0], [3, 0x6eb0a80], [3, 0x40187bc0]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x401623e0], [1, 0x3392900], [1, 0x4018b500], [2, 0x22e13a0]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 6], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x401852c0], [4, 0x6dc8bc0], [4, 0x401c7940], [5, 0x33df980]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x402306c0], [2, 0x237df60], [2, 0x402e47a0], [3, 0x6eafa40]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 6], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x233a280], [0, 0x40186ce0], [1, 0x33d9380], [1, 0x401cf520]]}
  lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x33b4540], [5, 0x40199000], [0, 0x233aae0], [0, 0x40187540]]}
  dc.input_tensor.sigmoid_1.0:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40169160]]}
  dc.input_tensor.sigmoid_1.1:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4019b920]]}
  lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x233d400], [0, 0x40189e60], [1, 0x33e1660], [1, 0x401d6f80]]}
  lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x401d7c00], [2, 0x2325ae0], [2, 0x4028a160], [3, 0x6e42bc0]]}
  lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x33e3fc0], [1, 0x401d9ca0], [2, 0x2327b80], [2, 0x4028c200]]}
  lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x33b8f20], [5, 0x4019d620], [0, 0x233fd60], [0, 0x4018c7c0]]}
  lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x4019c9a0], [0, 0x233f0e0], [0, 0x4018bb40], [1, 0x33e3340]]}
  lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1:              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x40132ae0], [4, 0x6d56de0], [4, 0x40165840], [5, 0x33b7ee0]]}
  dc.input_tensor.sigmoid_4.0:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6e41b40], [3, 0x40131a60]]}
  dc.input_tensor.sigmoid_4.1:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40165000], [5, 0x33b76a0]]}
  dc.input_tensor.sigmoid_7.0:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40289920]]}
  dc.input_tensor.sigmoid_7.1:                                                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x23252a0]]}
  dc.input_tensor.sigmoid_10.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d55d60]]}
  dc.input_tensor.sigmoid_10.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4019c160]]}
  lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 11], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x232aba0], [2, 0x4028f120], [3, 0x6e47f40], [3, 0x40137e60]]}
  lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x2342e80], [0, 0x4018f8c0], [1, 0x33e7520], [1, 0x401dd200]]}
  lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 11], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x4028e1e0], [3, 0x6e47000], [3, 0x40136f20], [4, 0x6d5af40]]}
  lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x4018e880], [1, 0x33e64e0], [1, 0x401dc1c0], [2, 0x2329b60]]}
  lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 8], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2329040], [2, 0x4028d6c0], [3, 0x6e464e0], [3, 0x40136400]]}
  lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x6e44c60], [3, 0x40134b80], [4, 0x6d58e80], [4, 0x401678e0]]}
  dc.input_tensor.sigmoid_13.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33bafc0]]}
  dc.input_tensor.sigmoid_13.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40168920]]}
  dc.input_tensor.sigmoid_17.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4028ce80]]}
  dc.input_tensor.sigmoid_17.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4018d800]]}
  dc.input_tensor.sigmoid_21.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4012f9c0]]}
  dc.input_tensor.sigmoid_21.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4015f620]]}
  lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 39], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x6d4f6a0]]}
  lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x4012d920]]}
  dc.input_tensor.sigmoid_24.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40184c40], [1, 0x33d72e0]]}
  dc.input_tensor.sigmoid_24.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40195f00], [0, 0x23381e0]]}
  dc.input_tensor.sigmoid_27.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d4e640]]}
  dc.input_tensor.sigmoid_27.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33a4860]]}
  dc.input_tensor.sigmoid_30.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2315fa0]]}
  dc.input_tensor.sigmoid_30.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x401c8480]]}
  lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 18], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x33a58c0], [5, 0x40194620], [0, 0x2336900], [0, 0x40183360], [1, 0x33d5a00]]}
  lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x4026d300], [3, 0x6e22480], [3, 0x4012a840], [4, 0x6d4d600], [4, 0x4015d580]]}
  dc.input_tensor.sigmoid_33.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x23358a0]]}
  dc.input_tensor.sigmoid_33.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401935c0]]}
  dc.input_tensor.sigmoid_37.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2324240]]}
  dc.input_tensor.sigmoid_37.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x401d5f20]]}
  lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 18], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x33b5580], [5, 0x4019a040], [0, 0x233bb20], [0, 0x40188580], [1, 0x33dfd80]]}
  lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x40287880], [3, 0x6e40b00], [3, 0x40130a20], [4, 0x6d54d20], [4, 0x40163780]]}
  dc.input_tensor.sigmoid_40.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d53cc0]]}
  dc.input_tensor.sigmoid_40.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33ab2c0]]}
  dc.input_tensor.sigmoid_44.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x231d040]]}
  dc.input_tensor.sigmoid_44.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40197fa0]]}
  dc.input_tensor.sigmoid_48.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4012e960], [4, 0x6d52c60]]}
  dc.input_tensor.sigmoid_48.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x33e5480], [1, 0x401db160]]}
  lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 58], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x401ca540], [2, 0x2318060], [2, 0x40281840], [3, 0x6e37a00]]}
  lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x40196f60], [0, 0x2339240], [0, 0x40185ca0], [1, 0x33d8340]]}
  dc.input_tensor.sigmoid_51.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x23b9500], [0, 0x401dcce0]]}
  dc.input_tensor.sigmoid_51.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3444ea0], [5, 0x402461a0]]}
  dc.input_tensor.sigmoid_54.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x401b1e80]]}
  dc.input_tensor.sigmoid_54.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6ef4080]]}
  dc.input_tensor.sigmoid_57.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4022bb00]]}
  dc.input_tensor.sigmoid_57.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x342a800]]}
  dc.input_tensor.conv2d_59.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x402127c0]]}
  lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x4033c600], [3, 0x6ef2380], [3, 0x401b0180], [4, 0x6df7340]]}
  lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x401d3a80], [1, 0x34b8980], [1, 0x40295000], [2, 0x23e20c0]]}
  dc.input_tensor.sigmoid_60.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40195ae0]]}
  dc.input_tensor.sigmoid_60.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6ed7ce0]]}
  dc.input_tensor.sigmoid_64.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6dfb0e0]]}
  dc.input_tensor.sigmoid_64.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x34736e0]]}
  dc.input_tensor.conv2d_66.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4023cf20]]}
  lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x4036b680], [3, 0x6f4d6e0], [3, 0x4020b4e0], [4, 0x6e17820]]}
  lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x401fd520], [1, 0x34d6940], [1, 0x402b2fc0], [2, 0x240a300]]}
  dc.input_tensor.sigmoid_67.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x401f0e40]]}
  dc.input_tensor.sigmoid_67.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6f33040]]}
  dc.input_tensor.sigmoid_71.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40298920]]}
  dc.input_tensor.sigmoid_71.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x34bc2a0]]}
  dc.input_tensor.conv2d_73.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401f7380]]}
  lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x40228d80], [5, 0x345f540], [5, 0x40260840], [0, 0x23d3ba0]]}
  lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x34b7940], [1, 0x40293fc0], [2, 0x23e1080], [2, 0x4033b5c0]]}
  dc.input_tensor.sigmoid_74.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6eb5400]]}
  dc.input_tensor.sigmoid_74.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x343a9e0]]}
  dc.input_tensor.sigmoid_78.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401c4080]]}
  dc.input_tensor.sigmoid_78.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6e953a0]]}
  dc.input_tensor.sigmoid_82.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x234c920]]}
  dc.input_tensor.sigmoid_82.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33c52e0], [5, 0x401a99e0]]}
  dc.input_tensor.conv2d_84.dc.pad.8.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x401bb620]]}
  lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 37], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x402d9280], [3, 0x6e920a0], [3, 0x40181fc0], [4, 0x6dc58c0]]}
  lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x40198b20], [1, 0x3431780], [1, 0x40227460], [2, 0x2374d00]]}
  dc.input_tensor.sigmoid_85.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4016a1e0], [5, 0x33bc880], [5, 0x401a0f80], [0, 0x2343ec0]]}
  dc.input_tensor.sigmoid_85.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x34327c0], [1, 0x402284a0], [2, 0x2375d40], [2, 0x402dc580]]}
  dc.input_tensor.sigmoid_88.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x23dcf60], [2, 0x403374a0], [3, 0x6ed3bc0], [3, 0x401919c0]]}
  dc.input_tensor.sigmoid_88.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2390a80], [0, 0x401c7740], [1, 0x34b3820], [1, 0x4028fea0]]}
  dc.input_tensor.sigmoid_91.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4028bd80], [2, 0x23d8e40], [2, 0x40333380], [3, 0x6ecfaa0]]}
  dc.input_tensor.sigmoid_91.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401fcf00], [0, 0x238c960], [0, 0x401c3620], [1, 0x34af700]]}
  lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                         {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 14], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x4018c540], [4, 0x6de7c00], [4, 0x401e6980], [5, 0x33fe9c0]]}
  lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                         {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x23836e0], [0, 0x401ae0a0], [1, 0x3455080], [1, 0x40231700]]}
  dc.input_tensor.sigmoid_94.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x401e2860], [5, 0x33fa8a0], [5, 0x401f8de0], [0, 0x2388840]]}
  dc.input_tensor.sigmoid_94.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x402e6040], [3, 0x6eb12e0], [3, 0x40188420], [4, 0x6de3ae0]]}
  dc.input_tensor.sigmoid_98.0:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x33f2680], [5, 0x401f0bc0]]}
  dc.input_tensor.sigmoid_98.1:                                                              {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6ddb8c0], [4, 0x401da640]]}
  dc.input_tensor.sigmoid_102.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 4], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2242d20], [0, 0x400afc60]]}
  dc.input_tensor.sigmoid_102.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 4], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32bbc20], [5, 0x400a8a00]]}
  dc.input_tensor.sigmoid_105.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40097840], [3, 0x6c922a0]]}
  dc.input_tensor.sigmoid_105.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4008c940], [2, 0x2215460]]}
  lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.0:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 80], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x400a8e40], [1, 0x3307f80]]}
  lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.1:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x400a79c0], [0, 0x2241ce0]]}
  lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.0:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 80], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x32a8ac0], [5, 0x4005fb80]]}
  lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.1:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x40062140], [4, 0x6c9c8c0]]}
  lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.0:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 80], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x40090a20], [3, 0x6c8b480]]}
  lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.1:                    {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x4008b900], [2, 0x2214420]]}
  dc.input_tensor.sigmoid_112.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [2, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40051d20], [4, 0x6c8c4a0]]}
  dc.input_tensor.sigmoid_112.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [2, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40080600], [3, 0x6c7b060]]}
  dc.input_tensor.sigmoid_115.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x21f8aa0], [0, 0x4005fc00]]}
  dc.input_tensor.sigmoid_115.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40040c20], [5, 0x32b3a00]]}
  lc.input_tensor.resize2d_117.dc.sparse_matmul.3.0:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 20], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x332a4a0]]}
  lc.input_tensor.resize2d_117.dc.sparse_matmul.3.1:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x400d3560]]}
  dc.input_tensor.sigmoid_120.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32e83e0]]}
  dc.input_tensor.sigmoid_120.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4008bb80]]}
  dc.input_tensor.sigmoid_123.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6cb5ba0]]}
  dc.input_tensor.sigmoid_123.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x400a6c40]]}
  dc.input_tensor.conv2d_125.dc.pad.8.0:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4009fa60]]}
  lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                       {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x40089e80], [5, 0x32e66e0], [5, 0x400d34c0], [0, 0x22551e0]]}
  lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                       {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400a5c00], [3, 0x6cb4b60], [3, 0x40081940], [4, 0x6cc01c0]]}
  dc.input_tensor.sigmoid_126.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400b8e20]]}
  dc.input_tensor.sigmoid_126.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32cc040]]}
  dc.input_tensor.sigmoid_129.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400672a0]]}
  dc.input_tensor.sigmoid_129.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c9a4c0]]}
  dc.input_tensor.sigmoid_133.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6c21980]]}
  dc.input_tensor.sigmoid_133.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c231e0], [3, 0x40001880]]}
  dc.input_tensor.sigmoid_136.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400018a0]]}
  dc.input_tensor.sigmoid_136.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3256ae0]]}
  lc.input_tensor.resize2d_138.dc.sparse_matmul.3.0:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x40007500]]}
  lc.input_tensor.resize2d_138.dc.sparse_matmul.3.1:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x21a7600]]}
  dc.input_tensor.sigmoid_141.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40001360]]}
  dc.input_tensor.sigmoid_141.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40001040], [4, 0x6c21140]]}
  dc.input_tensor.sigmoid_144.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x21a1140]]}
  dc.input_tensor.sigmoid_144.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32562a0], [1, 0x40001060]]}
  lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 14], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x40000000], [5, 0x3250100], [5, 0x40000000], [0, 0x21a62a0], [0, 0x400061a0]]}
  lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x21a0100], [2, 0x40000000], [3, 0x6c20100], [3, 0x40000000], [4, 0x6c20100]]}
  dc.input_tensor.sigmoid_147.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4003baa0]]}
  dc.input_tensor.sigmoid_147.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400514e0], [4, 0x6c8bc60]]}
  dc.input_tensor.sigmoid_150.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x21f2ba0]]}
  dc.input_tensor.sigmoid_150.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32c2600], [1, 0x4006a8a0]]}
  dc.input_tensor.sigmoid_154.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32a7a60], [5, 0x4005eb20]]}
  dc.input_tensor.sigmoid_154.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 4], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c72600], [3, 0x40050ca0], [4, 0x6c8b420], [4, 0x4003b260]]}
  dc.input_tensor.sigmoid_157.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [8, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32be4e0]]}
  dc.input_tensor.sigmoid_157.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x32a6a00], [5, 0x4005dac0], [0, 0x21f59a0], [0, 0x40056980]]}
  input_1_multiply_158:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c715a0], [3, 0x4004fc40], [4, 0x6c8a3c0], [4, 0x4003a200]]}
  input_2_concatenate_160:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x328d3a0], [5, 0x40044460], [0, 0x21dc340], [0, 0x4003d320], [1, 0x32a4e80], [1, 0x4004f1a0], [2, 0x21d74a0], [2, 0x40045720]]}
  input_1_multiply_164:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c70540], [3, 0x4004ebe0], [4, 0x6c89360], [4, 0x400391a0]]}
  input_1_concatenate_165:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3273d40], [5, 0x4002ae00], [0, 0x21c2ce0], [0, 0x40023cc0], [1, 0x328b820], [1, 0x40035b40], [2, 0x21bde40], [2, 0x4002c0c0]]}
  input_1_multiply_168:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x32721c0], [1, 0x4001c4e0], [2, 0x21a47e0], [2, 0x40012a60], [3, 0x6c56ee0], [3, 0x40035580], [4, 0x6c6fd00], [4, 0x4001fb40]]}
  input_1_multiply_171:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 2], t: 1, mblock: [1, 25], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6c3d880], [3, 0x4001bf20], [4, 0x6c566a0], [4, 0x400064e0], [5, 0x325a6e0], [5, 0x400117a0], [0, 0x21a9680], [0, 0x4000a660]]}
  lc.input_tensor.reshape_174.dc.sparse_matmul.3.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 4], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x4001bf40], [2, 0x21a4240], [2, 0x400124c0]]}
  lc.input_tensor.reshape_174.dc.sparse_matmul.3.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x21a8640], [0, 0x40009620], [1, 0x3271180]]}
  lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 58], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x22f0780], [2, 0x40233600], [3, 0x6e19380], [3, 0x40105040]]}
  lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x400d2520], [1, 0x3329460], [1, 0x400e8020], [2, 0x2270b40]]}
  dc.input_tensor.sigmoid_178.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400cfd40]]}
  dc.input_tensor.sigmoid_178.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6de4080]]}
  dc.input_tensor.sigmoid_182.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40170e60]]}
  dc.input_tensor.sigmoid_182.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3378260]]}
  dc.input_tensor.sigmoid_185.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4013e020]]}
  dc.input_tensor.sigmoid_185.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x334f2c0]]}
  dc.input_tensor.conv2d_187.dc.pad.8.0:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400f6b60]]}
  lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                       {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 21], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x40206880], [3, 0x6de2380], [3, 0x400ce040], [4, 0x6cfa440]]}
  lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                       {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x40159180], [1, 0x3377220], [1, 0x4016fe20], [2, 0x22de2c0]]}
  dc.input_tensor.sigmoid_188.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400b39a0]]}
  dc.input_tensor.sigmoid_188.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6dc7ce0]]}
  dc.input_tensor.sigmoid_191.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40142ee0]]}
  dc.input_tensor.sigmoid_191.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d32f60]]}
  dc.input_tensor.sigmoid_195.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x402385e0]]}
  dc.input_tensor.sigmoid_195.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x401a7c40], [2, 0x22f5760]]}
  dc.input_tensor.sigmoid_198.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2300b80]]}
  dc.input_tensor.sigmoid_198.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d25c00], [4, 0x40135b80], [5, 0x3397500], [5, 0x40186260]]}
  input_1_multiply_199:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x402189a0], [3, 0x6dfe720], [3, 0x400ea3e0], [4, 0x6cfe1e0]]}
  input_2_concatenate_201:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22f3820], [0, 0x40170e80], [1, 0x33a1ce0], [1, 0x4019a8e0]]}
  input_1_multiply_205:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d188a0], [4, 0x40128820], [5, 0x338a1a0], [5, 0x40178f00]]}
  input_1_concatenate_206:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x22e3420], [2, 0x402262a0], [3, 0x6e0c020], [3, 0x400f7ce0]]}
  input_1_multiply_209:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x22e64c0], [0, 0x40163b20], [1, 0x3394980], [1, 0x4018d580]]}
  input_1_multiply_212:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6d0b540], [4, 0x4011b4c0], [5, 0x337ce40], [5, 0x4016bba0]]}
  lc.input_tensor.reshape_215.dc.sparse_matmul.3.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 4], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x40225d00], [3, 0x6e0ba80], [3, 0x400f7740]]}
  lc.input_tensor.reshape_215.dc.sparse_matmul.3.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x3393940], [1, 0x4018c540], [2, 0x22e23e0]]}
  lc.input_tensor.reshape_217.dc.sparse_matmul.4.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x22e5dc0], [0, 0x40163420]]}
  lc.input_tensor.reshape_217.dc.sparse_matmul.4.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x337be00], [5, 0x4016ab60]]}
  dc.input_tensor.conv2d_218.dc.pad.8.0:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4010f1a0]]}
  lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.0:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 70], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x400a15e0], [4, 0x6ce5fe0]]}
  lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.1:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x40099fa0], [4, 0x6cde9a0]]}
  dc.input_tensor.sigmoid_219.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4013a4c0]]}
  dc.input_tensor.sigmoid_219.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x33314c0]]}
  dc.input_tensor.sigmoid_223.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400dc6e0]]}
  dc.input_tensor.sigmoid_223.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3307be0]]}
  dc.input_tensor.sigmoid_226.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40089b80]]}
  dc.input_tensor.sigmoid_226.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x401363a0], [2, 0x22beec0], [2, 0x4014b520], [3, 0x6d1d580]]}
  lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.0:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 14], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x400db380], [0, 0x227b820], [0, 0x400d86c0], [1, 0x3330160]]}
  lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.1:                        {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x40088b40], [4, 0x6ccd540], [4, 0x400aa340], [5, 0x3306ba0]]}
  dc.input_tensor.sigmoid_229.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3302a80], [5, 0x400d7260], [0, 0x2277700], [0, 0x400d45a0]]}
  dc.input_tensor.sigmoid_229.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6cd0240], [3, 0x40084a20], [4, 0x6cc9420], [4, 0x400a6220]]}
  dc.input_tensor.sigmoid_232.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6cce580]]}
  dc.input_tensor.sigmoid_232.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4015fa00]]}
  dc.input_tensor.sigmoid_236.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6dbfac0], [3, 0x400ab780], [4, 0x6cf0180], [4, 0x400dc4a0]]}
  dc.input_tensor.sigmoid_236.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x334e7e0], [1, 0x401577e0], [2, 0x22d4000], [2, 0x401ee240]]}
  dc.input_tensor.sigmoid_239.0:                                                             {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x401264a0], [1, 0x334c740], [1, 0x40155740], [2, 0x22d1f60], [2, 0x401ec1a0], [3, 0x6dbda20], [3, 0x400a96e0], [4, 0x6cee0e0]]}
  dc.input_tensor.sigmoid_239.1:                                                             {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x401ea100], [3, 0x6dbb980], [3, 0x400a7640], [4, 0x6cec040], [4, 0x400d62e0], [5, 0x3322740], [5, 0x400f8ea0], [0, 0x228c700]]}
  input_1_multiply_240:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400d4240], [5, 0x33206a0], [5, 0x400f6e00], [0, 0x228a660], [0, 0x40124400], [1, 0x334a6a0], [1, 0x401536a0], [2, 0x22cfec0]]}
  input_2_concatenate_242:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400cbba0], [5, 0x3318000], [5, 0x400ecb00], [0, 0x2280ca0], [0, 0x4011aa40], [1, 0x33418e0], [1, 0x4014a8e0], [2, 0x22c7100]]}
  input_1_multiply_246:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400f4d60], [0, 0x22885c0], [0, 0x40122360], [1, 0x3348600], [1, 0x40151600], [2, 0x22cde20], [2, 0x401e8060], [3, 0x6db98e0]]}
  input_1_concatenate_247:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4014f560], [2, 0x22cbd80], [2, 0x401e5fc0], [3, 0x6db7840], [3, 0x4009f540], [4, 0x6ce3f40], [4, 0x400d21a0], [5, 0x331e600]]}
  input_1_multiply_250:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4009d4a0], [4, 0x6ce1ea0], [4, 0x400d0100], [5, 0x331c560], [5, 0x400f2cc0], [0, 0x2286520], [0, 0x401202c0], [1, 0x3346560]]}
  input_1_multiply_253:                                                                      {input: HOST, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [1, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x400f0c20], [0, 0x2284480], [0, 0x4011e220], [1, 0x33444c0], [1, 0x4014d4c0], [2, 0x22c9ce0], [2, 0x401e3f20], [3, 0x6db57a0]]}
  lc.input_tensor.reshape_256.dc.sparse_matmul.3.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [9, 1], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x3344080], [1, 0x4014d080], [2, 0x22c98a0], [2, 0x401e3ae0], [3, 0x6db5360], [3, 0x4009d060], [4, 0x6ce1a60], [4, 0x400cfcc0], [5, 0x331c120]]}
  lc.input_tensor.reshape_256.dc.sparse_matmul.3.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [9, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x401e2aa0], [3, 0x6db4320], [3, 0x4009c020], [4, 0x6ce0a20], [4, 0x400cec80], [5, 0x331b0e0], [5, 0x400efbe0], [0, 0x2283440], [0, 0x4011d1e0]]}
  lc.input_tensor.reshape_258.dc.sparse_matmul.4.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x2282d40], [0, 0x4011cae0], [1, 0x3343980], [1, 0x4014c980], [2, 0x22c91a0]]}
  lc.input_tensor.reshape_258.dc.sparse_matmul.4.1:                                          {input: HOST, type: queue, entries: 1, grid_size: [5, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x4009afe0], [4, 0x6cdf9e0], [4, 0x400cdc40], [5, 0x331a0a0], [5, 0x400eeba0]]}
  lc.input_tensor.concatenate_259.dc.sparse_matmul.4.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 6], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x6db3ac0]]}
  lc.input_tensor.concatenate_259.dc.sparse_matmul.4.1:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x401e1a60]]}

  # epoch_to_epoch
  e2e_conv2d_6.dc.matmul.8_0:                                                                {input: conv2d_6.dc.matmul.8, type: queue, entries: 1, grid_size: [4, 1], t: 2, mblock: [25, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6e19520], [4, 0x402430c0], [5, 0x348dd80], [5, 0x40276a80]]}
  e2e__fused_op_3_0:                                                                         {input: _fused_op_3, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [25, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x24013a0], [0, 0x40217bc0], [1, 0x34f0fe0], [1, 0x402cd660], [2, 0x24249a0], [2, 0x403869e0], [3, 0x6f68a40], [3, 0x40226840]]}
  e2e__fused_op_1_0:                                                                         {input: _fused_op_1, type: queue, entries: 1, grid_size: [4, 2], t: 2, mblock: [25, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x23e7d40], [0, 0x401fe560], [1, 0x34d7980], [1, 0x402b4000], [2, 0x240b340], [2, 0x4036d380], [3, 0x6f4f3e0], [3, 0x4020d1e0]]}
  e2e__fused_op_7_0:                                                                         {input: _fused_op_7, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [25, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6e32b80], [4, 0x4025c720], [5, 0x34a73e0], [5, 0x402900e0], [0, 0x240dee0], [0, 0x40224700], [1, 0x34fdb20], [1, 0x402da1a0]]}
  e2e_conv2d_16.dc.matmul.8_0:                                                               {input: conv2d_16.dc.matmul.8, type: queue, entries: 1, grid_size: [8, 1], t: 1, mblock: [25, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x24314e0], [2, 0x40393520], [3, 0x6f75580], [3, 0x40233380], [4, 0x6e3f6c0], [4, 0x40269260], [5, 0x34b3f20], [5, 0x4029cc20]]}
  e2e__fused_op_10_0:                                                                        {input: _fused_op_10, type: queue, entries: 1, grid_size: [4, 1], t: 10, mblock: [5, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x241aa20], [0, 0x40231240], [1, 0x350a660], [1, 0x402e6ce0]]}
  e2e__fused_op_26_0:                                                                        {input: _fused_op_26, type: queue, entries: 1, grid_size: [2, 2], t: 1, mblock: [25, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x240b340], [2, 0x4036d380], [3, 0x6f4f3e0], [3, 0x4020d1e0]]}
  e2e__fused_op_38_0:                                                                        {input: _fused_op_38, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x402430c0]]}
  e2e__fused_op_39_0:                                                                        {input: _fused_op_39, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6e19520]]}
  e2e_conv2d_77.dc.matmul.8_0:                                                               {input: conv2d_77.dc.matmul.8, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x348dd80]]}
  e2e__fused_op_49_0:                                                                        {input: _fused_op_49, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40276a80], [0, 0x23e7d40], [0, 0x401fe560], [1, 0x34d7980]]}
  e2e_conv2d_97.dc.matmul.8_0:                                                               {input: conv2d_97.dc.matmul.8, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 2], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x402b4000], [2, 0x24249a0], [2, 0x403869e0], [3, 0x6f68a40]]}
  e2e__fused_op_42_0:                                                                        {input: _fused_op_42, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40226840], [4, 0x6e33bc0]]}
  e2e_conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0:                               {input: conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [16, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x4025d760]]}
  e2e_concatenate_118.dc.concatenate.0_0:                                                    {input: concatenate_118.dc.concatenate.0, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x348dd80]]}
  e2e__fused_op_76_0:                                                                        {input: _fused_op_76, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [25, 1], ublock: [2, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x34d7980], [1, 0x402b4000]]}
  e2e__fused_op_78_0:                                                                        {input: _fused_op_78, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [25, 1], ublock: [2, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x24249a0], [2, 0x403869e0]]}
  e2e__fused_op_81_0:                                                                        {input: _fused_op_81, type: queue, entries: 1, grid_size: [1, 5], t: 8, mblock: [1, 5], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4020d1e0], [4, 0x6e19520], [4, 0x402430c0], [5, 0x348dd80], [5, 0x40282dc0]]}
  e2e__fused_op_70_0:                                                                        {input: _fused_op_70, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [13, 1], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40202680]]}
  e2e__fused_op_93_0:                                                                        {input: _fused_op_93, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 13], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x23f4080]]}
  e2e__fused_op_59_0:                                                                        {input: _fused_op_59, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4027aba0], [0, 0x23ebe60]]}
  e2e__fused_op_98_0:                                                                        {input: _fused_op_98, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4021cd20]]}
  e2e_conv2d_225.dc.matmul.8_0:                                                              {input: conv2d_225.dc.matmul.8, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x34f0fe0]]}
  e2e__fused_op_103_0:                                                                       {input: _fused_op_103, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6f68a40]]}
  e2e__fused_op_105_0:                                                                       {input: _fused_op_105, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x6e41f40], [4, 0x4026bae0], [5, 0x34b67a0], [5, 0x40276a80]]}
  e2e_concatenate_259.dc.concatenate.2_transpose_nop_11316_0:                                {input: concatenate_259.dc.concatenate.2_transpose_nop_11316, type: queue, entries: 1, grid_size: [3, 1], t: 3, mblock: [1, 25], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x402cd660], [2, 0x243e000], [2, 0x403a0040]]}
  e2e_reshape_217.dc.sparse_matmul.4.lc2_0:                                                  {input: reshape_217.dc.sparse_matmul.4.lc2, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [19, 1], ublock: [1, 3], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6f78e60], [3, 0x40235c00]]}
  e2e_concatenate_259.dc.concatenate.2_0:                                                    {input: concatenate_259.dc.concatenate.2, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [99, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2428da0], [0, 0x4022d140], [1, 0x3501400]]}

graphs:
  fwd_0_0_temporal_epoch_0:
    target_device: 0
    input_count: 1
    conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0, ims_1, lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 25, mblock: [3, 1], ublock: [8, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 3, sparse_ublock_idx_bits: 3, u_kt: 200}}
    conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.matmul.11: {type: matmul, grid_loc: [0, 1], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.0.conv.weight_0_fork_clone1818],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 25}, hslice: 25], input_0_tms: [vslice: 96, hstack: 3, vstack: 32],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0, ims_1, lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 25, mblock: [3, 1], ublock: [8, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 3, sparse_ublock_idx_bits: 3, u_kt: 200}}
    conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.matmul.11: {type: matmul, grid_loc: [0, 3], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.0.conv.weight_0, model.model.model.0.conv.bias_0],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 800}, vslice: 25], input_1_tms: [broadcast: {c: 25}, hslice: 25], input_0_tms: [vslice: 96, hstack: 3, vstack: 32],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 3}}
    conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 4], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0, ims_1, lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 25, mblock: [3, 1], ublock: [8, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 3, sparse_ublock_idx_bits: 3, u_kt: 200}}
    conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.matmul.11: {type: matmul, grid_loc: [0, 5], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.0.conv.weight_0_fork_clone1816],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 25}, hslice: 25], input_0_tms: [vslice: 96, hstack: 3, vstack: 32],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_0: {type: fused_op, grid_loc: [0, 6], grid_size: [4, 1], inputs: [conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.matmul.11, conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.matmul.11, conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.matmul.11, dc.input_tensor.sigmoid_1.0, dc.input_tensor.sigmoid_1.1],
         t: 25, mblock: [4, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_4_tms: [broadcast: {r: 800}, vslice: 25], input_3_tms: [broadcast: {r: 800}, vslice: 25],
         attributes: {approximate_mode: false, fused_op_id: 0, kernel_broadcast: {input_4: 1, input_3: 1}}}
    conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 2, mblock: [15, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 25],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 25, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 32}}
    conv2d_3.dc.conv2d.5.dc.matmul.11: {type: matmul, grid_loc: [4, 1], grid_size: [4, 1], inputs: [conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.1.conv.weight_0_fork_clone430],
         t: 2, mblock: [25, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 300, hstack: 3, vstack: 100],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 3}}
    conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 2, mblock: [15, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 25],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 25, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 32}}
    conv2d_3.dc.conv2d.1.dc.matmul.11: {type: matmul, grid_loc: [4, 3], grid_size: [4, 1], inputs: [conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.1.conv.weight_0, model.model.model.1.conv.bias_0],
         t: 2, mblock: [25, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 300, hstack: 3, vstack: 100],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 4], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 2, mblock: [15, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 25],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 25, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 32}}
    conv2d_3.dc.conv2d.3.dc.matmul.11: {type: matmul, grid_loc: [4, 5], grid_size: [4, 1], inputs: [conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.1.conv.weight_0_fork_clone428],
         t: 2, mblock: [25, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 300, hstack: 3, vstack: 100],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 3}}
    _fused_op_1: {type: fused_op, grid_loc: [4, 6], grid_size: [4, 2], inputs: [conv2d_3.dc.conv2d.1.dc.matmul.11, conv2d_3.dc.conv2d.3.dc.matmul.11, conv2d_3.dc.conv2d.5.dc.matmul.11, dc.input_tensor.sigmoid_4.0, dc.input_tensor.sigmoid_4.1],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_4_tms: [broadcast: {r: 200}, vslice: 2], input_3_tms: [broadcast: {r: 200}, vslice: 2],
         attributes: {approximate_mode: false, fused_op_id: 1}}
    conv2d_6.dc.matmul.8: {type: matmul, grid_loc: [0, 7], grid_size: [4, 1], inputs: [_fused_op_1, model.model.model.2.cv1.conv.weight_0, model.model.model.2.cv1.conv.bias_0],
         t: 2, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}

  fwd_0_1_temporal_epoch_1:
    target_device: 0
    input_count: 1
    _fused_op_2: {type: fused_op, grid_loc: [0, 1], grid_size: [8, 1], inputs: [e2e_conv2d_6.dc.matmul.8_0, dc.input_tensor.sigmoid_7.0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [49, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}], input_0_tms: [vstack: 2],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}
    _fused_op_3: {type: fused_op, grid_loc: [0, 2], grid_size: [8, 1], inputs: [dc.input_tensor.sigmoid_7.1, _fused_op_2, e2e_conv2d_6.dc.matmul.8_0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 49], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vstack: 2], input_0_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 3, kernel_broadcast: {input_0: 1}}}
    conv2d_16.dc.matmul.8: {type: matmul, grid_loc: [0, 0], grid_size: [8, 1], inputs: [e2e__fused_op_1_0, model.model.model.2.cv2.conv.weight_0, model.model.model.2.cv2.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [49, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}], input_0_tms: [vstack: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_7: {type: fused_op, grid_loc: [0, 3], grid_size: [8, 1], inputs: [conv2d_16.dc.matmul.8, dc.input_tensor.sigmoid_17.0],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 2, kernel_broadcast: {input_1: 1}}}

  fwd_0_2_temporal_epoch_2:
    target_device: 0
    input_count: 1
    conv2d_9.dc.matmul.8: {type: matmul, grid_loc: [0, 1], grid_size: [4, 1], inputs: [e2e__fused_op_3_0, model.model.model.2.m.0.cv1.conv.weight_0, model.model.model.2.m.0.cv1.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    _fused_op_4: {type: fused_op, grid_loc: [0, 2], grid_size: [4, 1], inputs: [conv2d_9.dc.matmul.8, dc.input_tensor.sigmoid_10.0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 4, kernel_broadcast: {input_1: 1}}}
    _fused_op_5: {type: fused_op, grid_loc: [0, 3], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_10.1, _fused_op_4, conv2d_9.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 390], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 5, kernel_broadcast: {input_0: 1}}}
    conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_5, lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 11, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 200}}
    conv2d_12.dc.conv2d.5.dc.matmul.11: {type: matmul, grid_loc: [4, 1], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.2.m.0.cv2.conv.weight_0_fork_clone488],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 60, hstack: 3, vstack: 20],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 4], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_5, lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 11, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 200}}
    conv2d_12.dc.conv2d.1.dc.matmul.11: {type: matmul, grid_loc: [0, 5], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.2.m.0.cv2.conv.weight_0, model.model.model.2.m.0.cv2.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 60, hstack: 3, vstack: 20],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 6], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_5, lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [5, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 8, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 200}}
    conv2d_12.dc.conv2d.3.dc.matmul.11: {type: matmul, grid_loc: [0, 7], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.2.m.0.cv2.conv.weight_0_fork_clone486],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 60, hstack: 3, vstack: 20],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_6: {type: fused_op, grid_loc: [4, 2], grid_size: [4, 1], inputs: [conv2d_12.dc.conv2d.1.dc.matmul.11, conv2d_12.dc.conv2d.3.dc.matmul.11, conv2d_12.dc.conv2d.5.dc.matmul.11, dc.input_tensor.sigmoid_13.0, dc.input_tensor.sigmoid_13.1, e2e__fused_op_3_0],
         t: 10, mblock: [5, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0, 49], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_5_tms: [vslice: 10], input_4_tms: [broadcast: {r: 200}, vslice: 10], input_3_tms: [broadcast: {r: 200}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 6, kernel_broadcast: {input_4: 1, input_3: 1}}}
    _fused_op_8: {type: fused_op, grid_loc: [0, 0], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_17.1, e2e__fused_op_7_0, e2e_conv2d_16.dc.matmul.8_0],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 24, 24], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 200}],
         attributes: {approximate_mode: false, fused_op_id: 5, kernel_broadcast: {input_0: 1}}}
    concatenate_19.dc.concatenate.0: {type: splice, grid_loc: [4, 3], grid_size: [4, 1], inputs: [_fused_op_6, _fused_op_8],
         t: 10, mblock: [5, 2], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [vslice: 10],
         attributes: {input0: [0, 5, 5], input1: [0, 5, 5]}}
    conv2d_20.dc.matmul.8: {type: matmul, grid_loc: [4, 4], grid_size: [4, 1], inputs: [concatenate_19.dc.concatenate.0, model.model.model.2.cv3.conv.weight_0, model.model.model.2.cv3.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 200}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_9: {type: fused_op, grid_loc: [4, 5], grid_size: [4, 1], inputs: [conv2d_20.dc.matmul.8, dc.input_tensor.sigmoid_21.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 200}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9, kernel_broadcast: {input_1: 2}}}
    _fused_op_10: {type: fused_op, grid_loc: [4, 6], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_21.1, _fused_op_9, conv2d_20.dc.matmul.8],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 470], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 200}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 10, kernel_broadcast: {input_0: 2}}}

  fwd_0_3_temporal_epoch_3:
    target_device: 0
    input_count: 1
    conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.0, e2e__fused_op_10_0, lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [15, 1], ublock: [3, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 10],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 39, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 50}}
    conv2d_23.dc.matmul.11: {type: matmul, grid_loc: [0, 1], grid_size: [1, 2], inputs: [conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.3.conv.weight_0, model.model.model.3.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 45, hstack: 9, vstack: 5],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 18}}
    _fused_op_11: {type: fused_op, grid_loc: [0, 3], grid_size: [1, 2], inputs: [conv2d_23.dc.matmul.11, dc.input_tensor.sigmoid_24.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9}}
    _fused_op_12: {type: fused_op, grid_loc: [0, 5], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_24.1, _fused_op_11, conv2d_23.dc.matmul.11],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 466], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 10}}
    conv2d_26.dc.matmul.8: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [_fused_op_12, model.model.model.4.cv1.conv.weight_0, model.model.model.4.cv1.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_13: {type: fused_op, grid_loc: [1, 1], grid_size: [1, 1], inputs: [conv2d_26.dc.matmul.8, dc.input_tensor.sigmoid_27.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9}}
    _fused_op_14: {type: fused_op, grid_loc: [1, 2], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_27.1, _fused_op_13, conv2d_26.dc.matmul.8],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 466], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 10}}
    conv2d_29.dc.matmul.8: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [_fused_op_14, model.model.model.4.m.0.cv1.conv.weight_0, model.model.model.4.m.0.cv1.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 2}}
    _fused_op_15: {type: fused_op, grid_loc: [1, 7], grid_size: [1, 1], inputs: [conv2d_29.dc.matmul.8, dc.input_tensor.sigmoid_30.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9, kernel_broadcast: {input_1: 2}}}
    _fused_op_16: {type: fused_op, grid_loc: [2, 0], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_30.1, _fused_op_15, conv2d_29.dc.matmul.8],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 470], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 10, kernel_broadcast: {input_0: 2}}}
    conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 1], grid_size: [5, 1], inputs: [lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_16, lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [3, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 10],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 10, num_index_tiles: 1, num_sparse_tiles: 18, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_32.dc.matmul.11: {type: matmul, grid_loc: [2, 2], grid_size: [5, 1], inputs: [conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.4.m.0.cv2.conv.weight_0, model.model.model.4.m.0.cv2.conv.bias_0],
         t: 10, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 45, hstack: 9, vstack: 5],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    _fused_op_17: {type: fused_op, grid_loc: [2, 3], grid_size: [1, 1], inputs: [conv2d_32.dc.matmul.11, dc.input_tensor.sigmoid_33.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9}}
    buffer_0_5587_5591: {type: nop, grid_loc: [1, 6], grid_size: [1, 1], inputs: [_fused_op_14],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [476], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_18: {type: fused_op, grid_loc: [2, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_33.1, _fused_op_17, conv2d_32.dc.matmul.11, buffer_0_5587_5591],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 462, 0], input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 18}}
    conv2d_36.dc.matmul.8: {type: matmul, grid_loc: [2, 5], grid_size: [1, 1], inputs: [_fused_op_18, model.model.model.4.m.1.cv1.conv.weight_0, model.model.model.4.m.1.cv1.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 2}}
    _fused_op_19: {type: fused_op, grid_loc: [2, 6], grid_size: [1, 1], inputs: [conv2d_36.dc.matmul.8, dc.input_tensor.sigmoid_37.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9, kernel_broadcast: {input_1: 2}}}
    _fused_op_20: {type: fused_op, grid_loc: [2, 7], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_37.1, _fused_op_19, conv2d_36.dc.matmul.8],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 470], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 10, kernel_broadcast: {input_0: 2}}}
    conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 3], grid_size: [5, 1], inputs: [lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_20, lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 10, mblock: [3, 1], ublock: [3, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 10],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 10, num_index_tiles: 1, num_sparse_tiles: 18, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_39.dc.matmul.11: {type: matmul, grid_loc: [3, 4], grid_size: [5, 1], inputs: [conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.4.m.1.cv2.conv.weight_0, model.model.model.4.m.1.cv2.conv.bias_0],
         t: 10, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10], input_0_tms: [vslice: 45, hstack: 9, vstack: 5],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_43.dc.matmul.8: {type: matmul, grid_loc: [1, 0], grid_size: [1, 1], inputs: [_fused_op_12, model.model.model.4.cv2.conv.weight_0, model.model.model.4.cv2.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 20, input_buf_min_size_tiles: [268, 0, 0], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_21: {type: fused_op, grid_loc: [3, 0], grid_size: [1, 1], inputs: [conv2d_39.dc.matmul.11, dc.input_tensor.sigmoid_40.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9}}
    buffer_0_5591_5595: {type: nop, grid_loc: [3, 5], grid_size: [1, 1], inputs: [_fused_op_18],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [476], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_22: {type: fused_op, grid_loc: [3, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_40.1, _fused_op_21, conv2d_39.dc.matmul.11, buffer_0_5591_5595],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 462, 0], input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 18}}
    _fused_op_23: {type: fused_op, grid_loc: [1, 3], grid_size: [1, 1], inputs: [conv2d_43.dc.matmul.8, dc.input_tensor.sigmoid_44.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9}}
    _fused_op_24: {type: fused_op, grid_loc: [1, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_44.1, _fused_op_23, conv2d_43.dc.matmul.8],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 466], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 10}}
    concatenate_46.dc.concatenate.0: {type: splice, grid_loc: [3, 7], grid_size: [1, 1], inputs: [_fused_op_22, _fused_op_24],
         t: 10, mblock: [5, 2], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 452], input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 5, 5], input1: [0, 5, 5]}}
    conv2d_47.dc.matmul.8: {type: matmul, grid_loc: [4, 0], grid_size: [1, 1], inputs: [concatenate_46.dc.concatenate.0, model.model.model.4.cv3.conv.weight_0, model.model.model.4.cv3.conv.bias_0],
         t: 10, mblock: [5, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 20, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}, vslice: 10], input_1_tms: [broadcast: {c: 10}, hslice: 10],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_25: {type: fused_op, grid_loc: [4, 5], grid_size: [1, 2], inputs: [conv2d_47.dc.matmul.8, dc.input_tensor.sigmoid_48.0],
         t: 10, mblock: [5, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}, vslice: 10],
         attributes: {approximate_mode: false, fused_op_id: 9, kernel_broadcast: {input_1: 2}}}
    _fused_op_26: {type: fused_op, grid_loc: [5, 5], grid_size: [2, 2], inputs: [dc.input_tensor.sigmoid_48.1, _fused_op_25, conv2d_47.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 390], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vstack: 10], input_1_tms: [vstack: 10], input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 26, kernel_broadcast: {input_0: 2}}}

  fwd_0_4_temporal_epoch_4:
    target_device: 0
    input_count: 1
    conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.0, e2e__fused_op_26_0, lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 58, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 25}}
    conv2d_50.dc.matmul.11: {type: matmul, grid_loc: [0, 1], grid_size: [4, 1], inputs: [conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.5.conv.weight_0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 18}}
    conv2d_50.dc.select.12: {type: splice, grid_loc: [0, 2], grid_size: [1, 1], inputs: [conv2d_50.dc.matmul.11],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    _fused_op_27: {type: fused_op, grid_loc: [0, 3], grid_size: [1, 2], inputs: [conv2d_50.dc.select.12, model.model.model.5.conv.bias_0, dc.input_tensor.sigmoid_51.0, dc.input_tensor.sigmoid_51.1],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 27}}
    conv2d_53.dc.matmul.8: {type: matmul, grid_loc: [0, 5], grid_size: [1, 1], inputs: [_fused_op_27, model.model.model.6.cv1.conv.weight_0, model.model.model.6.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_28: {type: fused_op, grid_loc: [0, 6], grid_size: [1, 1], inputs: [conv2d_53.dc.matmul.8, dc.input_tensor.sigmoid_54.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_29: {type: fused_op, grid_loc: [0, 7], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_54.1, _fused_op_28, conv2d_53.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_56.dc.matmul.8: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [_fused_op_29, model.model.model.6.m.0.cv1.conv.weight_0, model.model.model.6.m.0.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_30: {type: fused_op, grid_loc: [1, 3], grid_size: [1, 1], inputs: [conv2d_56.dc.matmul.8, dc.input_tensor.sigmoid_57.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_31: {type: fused_op, grid_loc: [1, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_57.1, _fused_op_30, conv2d_56.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_59.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [1, 5], grid_size: [1, 1], inputs: [_fused_op_31, dc.input_tensor.conv2d_59.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 6], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_59.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_59.dc.matmul.12: {type: matmul, grid_loc: [1, 7], grid_size: [4, 1], inputs: [conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.6.m.0.cv2.conv.weight_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 36}}
    conv2d_59.dc.select.13: {type: splice, grid_loc: [2, 2], grid_size: [1, 1], inputs: [conv2d_59.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    buffer_1_5602_5605: {type: nop, grid_loc: [2, 3], grid_size: [1, 1], inputs: [_fused_op_29],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [392], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_5602_5605: {type: nop, grid_loc: [2, 4], grid_size: [1, 1], inputs: [buffer_1_5602_5605],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [392], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_32: {type: fused_op, grid_loc: [2, 5], grid_size: [1, 1], inputs: [conv2d_59.dc.select.13, model.model.model.6.m.0.cv2.conv.bias_0, dc.input_tensor.sigmoid_60.0, dc.input_tensor.sigmoid_60.1, buffer_0_5602_5605],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 0, 0, 248], input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 32}}
    conv2d_63.dc.matmul.8: {type: matmul, grid_loc: [3, 2], grid_size: [1, 1], inputs: [_fused_op_32, model.model.model.6.m.1.cv1.conv.weight_0, model.model.model.6.m.1.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_33: {type: fused_op, grid_loc: [3, 3], grid_size: [1, 1], inputs: [conv2d_63.dc.matmul.8, dc.input_tensor.sigmoid_64.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_34: {type: fused_op, grid_loc: [3, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_64.1, _fused_op_33, conv2d_63.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [3, 5], grid_size: [1, 1], inputs: [_fused_op_34, dc.input_tensor.conv2d_66.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_66.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_66.dc.matmul.12: {type: matmul, grid_loc: [4, 1], grid_size: [4, 1], inputs: [conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.6.m.1.cv2.conv.weight_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 36}}
    conv2d_66.dc.select.13: {type: splice, grid_loc: [4, 2], grid_size: [1, 1], inputs: [conv2d_66.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    buffer_1_5605_5608: {type: nop, grid_loc: [4, 3], grid_size: [1, 1], inputs: [_fused_op_32],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [392], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_5605_5608: {type: nop, grid_loc: [4, 4], grid_size: [1, 1], inputs: [buffer_1_5605_5608],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [392], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_35: {type: fused_op, grid_loc: [4, 5], grid_size: [1, 1], inputs: [conv2d_66.dc.select.13, model.model.model.6.m.1.cv2.conv.bias_0, dc.input_tensor.sigmoid_67.0, dc.input_tensor.sigmoid_67.1, buffer_0_5605_5608],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 0, 0, 248], input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 32}}
    conv2d_70.dc.matmul.8: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [_fused_op_35, model.model.model.6.m.2.cv1.conv.weight_0, model.model.model.6.m.2.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_36: {type: fused_op, grid_loc: [5, 3], grid_size: [1, 1], inputs: [conv2d_70.dc.matmul.8, dc.input_tensor.sigmoid_71.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_37: {type: fused_op, grid_loc: [5, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_71.1, _fused_op_36, conv2d_70.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_73.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [5, 5], grid_size: [1, 1], inputs: [_fused_op_37, dc.input_tensor.conv2d_73.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 6], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_73.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_73.dc.matmul.12: {type: matmul, grid_loc: [5, 7], grid_size: [4, 1], inputs: [conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.6.m.2.cv2.conv.weight_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 36}}
    conv2d_73.dc.select.13: {type: splice, grid_loc: [6, 2], grid_size: [1, 1], inputs: [conv2d_73.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    conv2d_77.dc.matmul.8: {type: matmul, grid_loc: [7, 2], grid_size: [1, 1], inputs: [_fused_op_27, model.model.model.6.cv2.conv.weight_0, model.model.model.6.cv2.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    buffer_1_5608_5611: {type: nop, grid_loc: [6, 3], grid_size: [1, 1], inputs: [_fused_op_35],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [392], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_5608_5611: {type: nop, grid_loc: [6, 4], grid_size: [1, 1], inputs: [buffer_1_5608_5611],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [392], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_38: {type: fused_op, grid_loc: [6, 5], grid_size: [1, 1], inputs: [conv2d_73.dc.select.13, model.model.model.6.m.2.cv2.conv.bias_0, dc.input_tensor.sigmoid_74.0, dc.input_tensor.sigmoid_74.1, buffer_0_5608_5611],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 0, 0, 248], input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 32}}
    _fused_op_39: {type: fused_op, grid_loc: [7, 3], grid_size: [1, 1], inputs: [conv2d_77.dc.matmul.8, dc.input_tensor.sigmoid_78.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}

  fwd_0_5_temporal_epoch_5:
    target_device: 0
    input_count: 1
    _fused_op_40: {type: fused_op, grid_loc: [0, 0], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_78.1, e2e__fused_op_39_0, e2e_conv2d_77.dc.matmul.8_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 24, 24], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    concatenate_80.dc.concatenate.0: {type: splice, grid_loc: [0, 1], grid_size: [1, 1], inputs: [e2e__fused_op_38_0, _fused_op_40],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_81.dc.matmul.8: {type: matmul, grid_loc: [0, 2], grid_size: [1, 1], inputs: [concatenate_80.dc.concatenate.0, model.model.model.6.cv3.conv.weight_0, model.model.model.6.cv3.conv.bias_0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_41: {type: fused_op, grid_loc: [0, 3], grid_size: [1, 1], inputs: [conv2d_81.dc.matmul.8, dc.input_tensor.sigmoid_82.0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 41}}
    _fused_op_42: {type: fused_op, grid_loc: [0, 4], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_82.1, _fused_op_41, conv2d_81.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_84.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [0, 6], grid_size: [1, 1], inputs: [_fused_op_42, dc.input_tensor.conv2d_84.dc.pad.8.0],
         t: 1, mblock: [16, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 26, 26], input1: [0, 6, 6]}}
    conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_84.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [9, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 37, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 16}}
    conv2d_84.dc.matmul.12: {type: matmul, grid_loc: [1, 1], grid_size: [4, 2], inputs: [conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.7.conv.weight_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 12, min_buffer_input: 0, u_kt: 6}}
    _fused_op_43: {type: fused_op, grid_loc: [0, 7], grid_size: [4, 1], inputs: [conv2d_84.dc.matmul.12, model.model.model.7.conv.bias_0, dc.input_tensor.sigmoid_85.0, dc.input_tensor.sigmoid_85.1],
         t: 1, mblock: [1, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}],
         attributes: {approximate_mode: false, fused_op_id: 43}}
    conv2d_87.dc.matmul.8: {type: matmul, grid_loc: [1, 3], grid_size: [4, 1], inputs: [_fused_op_43, model.model.model.8.cv1.conv.weight_0, model.model.model.8.cv1.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_44: {type: fused_op, grid_loc: [1, 4], grid_size: [4, 1], inputs: [conv2d_87.dc.matmul.8, dc.input_tensor.sigmoid_88.0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_45: {type: fused_op, grid_loc: [1, 5], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_88.1, _fused_op_44, conv2d_87.dc.matmul.8],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 456], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    conv2d_90.dc.matmul.8: {type: matmul, grid_loc: [1, 6], grid_size: [4, 1], inputs: [_fused_op_45, model.model.model.8.m.0.cv1.conv.weight_0, model.model.model.8.m.0.cv1.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_46: {type: fused_op, grid_loc: [4, 7], grid_size: [4, 1], inputs: [conv2d_90.dc.matmul.8, dc.input_tensor.sigmoid_91.0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_47: {type: fused_op, grid_loc: [5, 0], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_91.1, _fused_op_46, conv2d_90.dc.matmul.8],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 456], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 1], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_47, lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [9, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 14, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 4}}
    conv2d_93.dc.matmul.11: {type: matmul, grid_loc: [5, 2], grid_size: [4, 1], inputs: [conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.8.m.0.cv2.conv.weight_0, model.model.model.8.m.0.cv2.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 12, min_buffer_input: 0, u_kt: 6}}
    conv2d_97.dc.matmul.8: {type: matmul, grid_loc: [5, 6], grid_size: [4, 1], inputs: [_fused_op_43, model.model.model.8.cv2.conv.weight_0, model.model.model.8.cv2.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_48: {type: fused_op, grid_loc: [5, 3], grid_size: [4, 1], inputs: [conv2d_93.dc.matmul.11, dc.input_tensor.sigmoid_94.0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    buffer_0_5618_5622: {type: nop, grid_loc: [5, 4], grid_size: [4, 1], inputs: [_fused_op_45],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [480], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    _fused_op_49: {type: fused_op, grid_loc: [5, 5], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_94.1, _fused_op_48, conv2d_93.dc.matmul.11, buffer_0_5618_5622],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 448, 0], input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 49}}

  fwd_0_6_temporal_epoch_6:
    target_device: 0
    input_count: 1
    _fused_op_50: {type: fused_op, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_conv2d_97.dc.matmul.8_0, dc.input_tensor.sigmoid_98.0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 50}}
    _fused_op_51: {type: fused_op, grid_loc: [0, 1], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_98.1, _fused_op_50, e2e_conv2d_97.dc.matmul.8_0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 48], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 51}}
    concatenate_100.dc.concatenate.0: {type: splice, grid_loc: [0, 2], grid_size: [2, 1], inputs: [e2e__fused_op_49_0, _fused_op_51],
         t: 1, mblock: [1, 4], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 2, 2], input1: [0, 2, 2]}}
    conv2d_101.dc.matmul.8: {type: matmul, grid_loc: [0, 3], grid_size: [2, 1], inputs: [concatenate_100.dc.concatenate.0, model.model.model.8.cv3.conv.weight_0, model.model.model.8.cv3.conv.bias_0],
         t: 1, mblock: [1, 4], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 32}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_52: {type: fused_op, grid_loc: [0, 4], grid_size: [2, 1], inputs: [conv2d_101.dc.matmul.8, dc.input_tensor.sigmoid_102.0],
         t: 1, mblock: [1, 4], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 52}}
    _fused_op_53: {type: fused_op, grid_loc: [0, 5], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_102.1, _fused_op_52, conv2d_101.dc.matmul.8],
         t: 1, mblock: [1, 4], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 368], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 53}}
    conv2d_104.dc.matmul.8: {type: matmul, grid_loc: [0, 6], grid_size: [2, 1], inputs: [_fused_op_53, model.model.model.9.cv1.conv.weight_0, model.model.model.9.cv1.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 16}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_54: {type: fused_op, grid_loc: [0, 7], grid_size: [2, 1], inputs: [conv2d_104.dc.matmul.8, dc.input_tensor.sigmoid_105.0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 50}}
    _fused_op_55: {type: fused_op, grid_loc: [2, 0], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_105.1, _fused_op_54, conv2d_104.dc.matmul.8],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 51}}
    max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 1], grid_size: [2, 1], inputs: [lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.0, _fused_op_55, lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.1],
         t: 2, mblock: [25, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 80, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 4}}
    max_pool2d_107.dc.reduce_max.6: {type: reduce, grid_loc: [2, 2], grid_size: [2, 1], inputs: [max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2],
         t: 2, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 4, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 50, hstack: 25, vstack: 2, hslice: 25],
         attributes: {dim: z, type: max, z: 25}}
    max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 3], grid_size: [2, 1], inputs: [lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.0, max_pool2d_107.dc.reduce_max.6, lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.1],
         t: 2, mblock: [25, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 80, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 1}}
    max_pool2d_108.dc.reduce_max.6: {type: reduce, grid_loc: [2, 4], grid_size: [2, 1], inputs: [max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2],
         t: 2, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 4, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 50, hstack: 25, vstack: 2, hslice: 25],
         attributes: {dim: z, type: max, z: 25}}
    max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 5], grid_size: [2, 1], inputs: [lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.0, max_pool2d_108.dc.reduce_max.6, lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.1],
         t: 2, mblock: [25, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 80, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 1}}
    max_pool2d_109.dc.reduce_max.6: {type: reduce, grid_loc: [2, 6], grid_size: [2, 1], inputs: [max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.lc2],
         t: 2, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 50, hstack: 25, vstack: 2, hslice: 25],
         attributes: {dim: z, type: max, z: 25}}
    concatenate_110.dc.concatenate.0: {type: splice, grid_loc: [2, 7], grid_size: [2, 1], inputs: [_fused_op_55, max_pool2d_107.dc.reduce_max.6, max_pool2d_108.dc.reduce_max.6, max_pool2d_109.dc.reduce_max.6],
         t: 2, mblock: [1, 8], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 408, 0], input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 2],
         attributes: {input0: [0, 2, 2], input1: [0, 2, 2], input2: [0, 2, 2], input3: [0, 2, 2]}}
    conv2d_111.dc.matmul.8: {type: matmul, grid_loc: [4, 0], grid_size: [2, 2], inputs: [concatenate_110.dc.concatenate.0, model.model.model.9.cv2.conv.weight_0, model.model.model.9.cv2.conv.bias_0],
         t: 2, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 4, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 8, min_buffer_input: 0, u_kt: 4}}
    _fused_op_56: {type: fused_op, grid_loc: [4, 2], grid_size: [2, 1], inputs: [conv2d_111.dc.matmul.8, dc.input_tensor.sigmoid_112.0],
         t: 2, mblock: [1, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [vslice: 2],
         attributes: {approximate_mode: false, fused_op_id: 56}}
    _fused_op_57: {type: fused_op, grid_loc: [4, 3], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_112.1, _fused_op_56, conv2d_111.dc.matmul.8],
         t: 2, mblock: [1, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 2],
         attributes: {approximate_mode: false, fused_op_id: 57}}
    conv2d_114.dc.matmul.8: {type: matmul, grid_loc: [4, 4], grid_size: [2, 1], inputs: [_fused_op_57, model.model.model.10.conv.weight_0, model.model.model.10.conv.bias_0],
         t: 2, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 4, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_58: {type: fused_op, grid_loc: [4, 5], grid_size: [2, 1], inputs: [conv2d_114.dc.matmul.8, dc.input_tensor.sigmoid_115.0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 2],
         attributes: {approximate_mode: false, fused_op_id: 50}}
    _fused_op_59: {type: fused_op, grid_loc: [4, 6], grid_size: [2, 1], inputs: [dc.input_tensor.sigmoid_115.1, _fused_op_58, conv2d_114.dc.matmul.8],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 416], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [vstack: 2],
         attributes: {approximate_mode: false, fused_op_id: 51}}
    resize2d_117.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.resize2d_117.dc.sparse_matmul.3.0, _fused_op_59, lc.input_tensor.resize2d_117.dc.sparse_matmul.3.1],
         t: 1, mblock: [13, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 20, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 4}}
    concatenate_118.dc.concatenate.0: {type: splice, grid_loc: [5, 7], grid_size: [1, 1], inputs: [resize2d_117.dc.sparse_matmul.3.lc2, e2e__fused_op_42_0],
         t: 1, mblock: [13, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 26, 26], input1: [0, 26, 26]}}
    conv2d_119.dc.matmul.8: {type: matmul, grid_loc: [6, 0], grid_size: [1, 1], inputs: [concatenate_118.dc.concatenate.0, model.model.model.13.cv1.conv.weight_0, model.model.model.13.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 16}}
    _fused_op_60: {type: fused_op, grid_loc: [6, 1], grid_size: [1, 1], inputs: [conv2d_119.dc.matmul.8, dc.input_tensor.sigmoid_120.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_61: {type: fused_op, grid_loc: [6, 2], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_120.1, _fused_op_60, conv2d_119.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_122.dc.matmul.8: {type: matmul, grid_loc: [6, 3], grid_size: [1, 1], inputs: [_fused_op_61, model.model.model.13.m.0.cv1.conv.weight_0, model.model.model.13.m.0.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_62: {type: fused_op, grid_loc: [6, 4], grid_size: [1, 1], inputs: [conv2d_122.dc.matmul.8, dc.input_tensor.sigmoid_123.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_63: {type: fused_op, grid_loc: [6, 5], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_123.1, _fused_op_62, conv2d_122.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [6, 6], grid_size: [1, 1], inputs: [_fused_op_63, dc.input_tensor.conv2d_125.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}

  fwd_0_7_temporal_epoch_7:
    target_device: 0
    input_count: 1
    conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.0, e2e_conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0, lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_125.dc.matmul.12: {type: matmul, grid_loc: [0, 1], grid_size: [4, 1], inputs: [conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.13.m.0.cv2.conv.weight_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 36}}
    conv2d_125.dc.select.13: {type: splice, grid_loc: [0, 2], grid_size: [1, 1], inputs: [conv2d_125.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    conv2d_128.dc.matmul.8: {type: matmul, grid_loc: [0, 4], grid_size: [1, 1], inputs: [e2e_concatenate_118.dc.concatenate.0_0, model.model.model.13.cv2.conv.weight_0, model.model.model.13.cv2.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 16}}
    _fused_op_64: {type: fused_op, grid_loc: [0, 3], grid_size: [1, 1], inputs: [conv2d_125.dc.select.13, model.model.model.13.m.0.cv2.conv.bias_0, dc.input_tensor.sigmoid_126.0, dc.input_tensor.sigmoid_126.1],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 27}}
    _fused_op_65: {type: fused_op, grid_loc: [0, 5], grid_size: [1, 1], inputs: [conv2d_128.dc.matmul.8, dc.input_tensor.sigmoid_129.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_66: {type: fused_op, grid_loc: [0, 6], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_129.1, _fused_op_65, conv2d_128.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    concatenate_131.dc.concatenate.0: {type: splice, grid_loc: [0, 7], grid_size: [1, 1], inputs: [_fused_op_64, _fused_op_66],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_132.dc.matmul.8: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [concatenate_131.dc.concatenate.0, model.model.model.13.cv3.conv.weight_0, model.model.model.13.cv3.conv.bias_0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_67: {type: fused_op, grid_loc: [1, 3], grid_size: [1, 1], inputs: [conv2d_132.dc.matmul.8, dc.input_tensor.sigmoid_133.0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 41}}
    _fused_op_68: {type: fused_op, grid_loc: [1, 4], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_133.1, _fused_op_67, conv2d_132.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_135.dc.matmul.8: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [_fused_op_68, model.model.model.14.conv.weight_0, model.model.model.14.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_69: {type: fused_op, grid_loc: [1, 7], grid_size: [1, 1], inputs: [conv2d_135.dc.matmul.8, dc.input_tensor.sigmoid_136.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_70: {type: fused_op, grid_loc: [2, 2], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_136.1, _fused_op_69, conv2d_135.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    resize2d_138.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [2, 3], grid_size: [1, 1], inputs: [lc.input_tensor.resize2d_138.dc.sparse_matmul.3.0, _fused_op_70, lc.input_tensor.resize2d_138.dc.sparse_matmul.3.1],
         t: 1, mblock: [25, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 24, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 13}}
    concatenate_139.dc.concatenate.0: {type: splice, grid_loc: [2, 4], grid_size: [2, 1], inputs: [resize2d_138.dc.sparse_matmul.3.lc2, e2e__fused_op_26_0],
         t: 1, mblock: [25, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 25, 25], input1: [0, 25, 25]}}
    conv2d_140.dc.matmul.8: {type: matmul, grid_loc: [2, 5], grid_size: [1, 1], inputs: [concatenate_139.dc.concatenate.0, model.model.model.17.cv1.conv.weight_0, model.model.model.17.cv1.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_71: {type: fused_op, grid_loc: [2, 6], grid_size: [1, 1], inputs: [conv2d_140.dc.matmul.8, dc.input_tensor.sigmoid_141.0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 71}}
    _fused_op_72: {type: fused_op, grid_loc: [3, 2], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_141.1, _fused_op_71, conv2d_140.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 386], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 5}}
    conv2d_143.dc.matmul.8: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [_fused_op_72, model.model.model.17.m.0.cv1.conv.weight_0, model.model.model.17.m.0.cv1.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_73: {type: fused_op, grid_loc: [3, 5], grid_size: [1, 1], inputs: [conv2d_143.dc.matmul.8, dc.input_tensor.sigmoid_144.0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 71, kernel_broadcast: {input_1: 4}}}
    _fused_op_74: {type: fused_op, grid_loc: [3, 6], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_144.1, _fused_op_73, conv2d_143.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 390], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 5, kernel_broadcast: {input_0: 2}}}
    conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [5, 1], inputs: [lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_74, lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [30, 1], ublock: [3, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 14, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 25}}
    conv2d_146.dc.matmul.11: {type: matmul, grid_loc: [4, 1], grid_size: [5, 1], inputs: [conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.17.m.0.cv2.conv.weight_0, model.model.model.17.m.0.cv2.conv.bias_0],
         t: 1, mblock: [5, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_149.dc.matmul.8: {type: matmul, grid_loc: [4, 5], grid_size: [1, 1], inputs: [concatenate_139.dc.concatenate.0, model.model.model.17.cv2.conv.weight_0, model.model.model.17.cv2.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 4}}
    _fused_op_75: {type: fused_op, grid_loc: [4, 2], grid_size: [1, 1], inputs: [conv2d_146.dc.matmul.11, dc.input_tensor.sigmoid_147.0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 71}}
    _fused_op_76: {type: fused_op, grid_loc: [4, 3], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_147.1, _fused_op_75, conv2d_146.dc.matmul.11],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 386], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 5}}
    _fused_op_77: {type: fused_op, grid_loc: [4, 6], grid_size: [1, 1], inputs: [conv2d_149.dc.matmul.8, dc.input_tensor.sigmoid_150.0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 71}}
    _fused_op_78: {type: fused_op, grid_loc: [5, 2], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_150.1, _fused_op_77, conv2d_149.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 386], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 5}}

  fwd_0_8_temporal_epoch_8:
    target_device: 0
    input_count: 1
    concatenate_152.dc.concatenate.0: {type: splice, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e__fused_op_76_0, e2e__fused_op_78_0],
         t: 1, mblock: [25, 2], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [24, 24], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 25, 25], input1: [0, 25, 25]}}
    conv2d_153.dc.matmul.8: {type: matmul, grid_loc: [0, 1], grid_size: [1, 1], inputs: [concatenate_152.dc.concatenate.0, model.model.model.17.cv3.conv.weight_0, model.model.model.17.cv3.conv.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_79: {type: fused_op, grid_loc: [0, 2], grid_size: [1, 2], inputs: [conv2d_153.dc.matmul.8, dc.input_tensor.sigmoid_154.0],
         t: 1, mblock: [25, 1], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 71}}
    _fused_op_80: {type: fused_op, grid_loc: [0, 4], grid_size: [1, 4], inputs: [dc.input_tensor.sigmoid_154.1, _fused_op_79, conv2d_153.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 386], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {r: 50}],
         attributes: {approximate_mode: false, fused_op_id: 5}}
    conv2d_156.dc.matmul.8: {type: matmul, grid_loc: [6, 3], grid_size: [1, 2], inputs: [_fused_op_80, model.model.model.24.m.0.weight_0, model.model.model.24.m.0.bias_0],
         t: 1, mblock: [25, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 50}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_81_transpose_nop_11737: {type: nop, grid_loc: [7, 2], grid_size: [1, 1], inputs: [conv2d_156.dc.matmul.8],
         t: 8, mblock: [1, 25], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, vslice: 8]}
    _fused_op_81: {type: fused_op, grid_loc: [8, 0], grid_size: [1, 5], inputs: [_fused_op_81_transpose_nop_11737, dc.input_tensor.sigmoid_157.0],
         t: 8, mblock: [1, 5], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 50}, vslice: 8],
         attributes: {approximate_mode: false, fused_op_id: 81}}
    conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_80, lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 58, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 25}}
    conv2d_177.dc.matmul.11: {type: matmul, grid_loc: [1, 1], grid_size: [4, 1], inputs: [conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.18.conv.weight_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 36}}
    conv2d_177.dc.select.12: {type: splice, grid_loc: [1, 2], grid_size: [1, 1], inputs: [conv2d_177.dc.matmul.11],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    _fused_op_83: {type: fused_op, grid_loc: [1, 3], grid_size: [1, 1], inputs: [conv2d_177.dc.select.12, model.model.model.18.conv.bias_0, dc.input_tensor.sigmoid_178.0, dc.input_tensor.sigmoid_178.1],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 27}}
    concatenate_180.dc.concatenate.0: {type: splice, grid_loc: [1, 4], grid_size: [1, 1], inputs: [_fused_op_83, e2e__fused_op_70_0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_181.dc.matmul.8: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [concatenate_180.dc.concatenate.0, model.model.model.20.cv1.conv.weight_0, model.model.model.20.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_84: {type: fused_op, grid_loc: [1, 6], grid_size: [1, 1], inputs: [conv2d_181.dc.matmul.8, dc.input_tensor.sigmoid_182.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_85: {type: fused_op, grid_loc: [1, 7], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_182.1, _fused_op_84, conv2d_181.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_184.dc.matmul.8: {type: matmul, grid_loc: [2, 2], grid_size: [1, 1], inputs: [_fused_op_85, model.model.model.20.m.0.cv1.conv.weight_0, model.model.model.20.m.0.cv1.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 4}}
    _fused_op_86: {type: fused_op, grid_loc: [2, 3], grid_size: [1, 1], inputs: [conv2d_184.dc.matmul.8, dc.input_tensor.sigmoid_185.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_87: {type: fused_op, grid_loc: [2, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_185.1, _fused_op_86, conv2d_184.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_187.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [2, 5], grid_size: [1, 1], inputs: [_fused_op_87, dc.input_tensor.conv2d_187.dc.pad.8.0],
         t: 1, mblock: [16, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 3, 3]}}
    conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 6], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_187.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 21, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 16}}
    conv2d_187.dc.matmul.12: {type: matmul, grid_loc: [2, 7], grid_size: [4, 1], inputs: [conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.20.m.0.cv2.conv.weight_0],
         t: 1, mblock: [2, 1], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {m_k: 1, min_buffer_input: 0, u_kt: 36}}
    conv2d_187.dc.select.13: {type: splice, grid_loc: [3, 2], grid_size: [1, 1], inputs: [conv2d_187.dc.matmul.12],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 16]}}
    buffer_1_5303_5354: {type: nop, grid_loc: [3, 4], grid_size: [1, 1], inputs: [concatenate_180.dc.concatenate.0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [288], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_5303_5354: {type: nop, grid_loc: [3, 5], grid_size: [1, 1], inputs: [buffer_1_5303_5354],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [288], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    conv2d_190.dc.matmul.8: {type: matmul, grid_loc: [4, 2], grid_size: [1, 1], inputs: [buffer_0_5303_5354, model.model.model.20.cv2.conv.weight_0, model.model.model.20.cv2.conv.bias_0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [288, 0, 0], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 4}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_88: {type: fused_op, grid_loc: [3, 3], grid_size: [1, 1], inputs: [conv2d_187.dc.select.13, model.model.model.20.m.0.cv2.conv.bias_0, dc.input_tensor.sigmoid_188.0, dc.input_tensor.sigmoid_188.1],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 13}],
         attributes: {approximate_mode: false, fused_op_id: 27}}
    _fused_op_89: {type: fused_op, grid_loc: [4, 3], grid_size: [1, 1], inputs: [conv2d_190.dc.matmul.8, dc.input_tensor.sigmoid_191.0],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 28}}
    _fused_op_90: {type: fused_op, grid_loc: [4, 4], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_191.1, _fused_op_89, conv2d_190.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    concatenate_193.dc.concatenate.0: {type: splice, grid_loc: [4, 5], grid_size: [1, 1], inputs: [_fused_op_88, _fused_op_90],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 280], input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 13, 13], input1: [0, 13, 13]}}
    conv2d_194.dc.matmul.8: {type: matmul, grid_loc: [5, 0], grid_size: [1, 1], inputs: [concatenate_193.dc.concatenate.0, model.model.model.20.cv3.conv.weight_0, model.model.model.20.cv3.conv.bias_0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_91: {type: fused_op, grid_loc: [5, 1], grid_size: [1, 1], inputs: [conv2d_194.dc.matmul.8, dc.input_tensor.sigmoid_195.0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 41}}
    _fused_op_92: {type: fused_op, grid_loc: [5, 2], grid_size: [1, 2], inputs: [dc.input_tensor.sigmoid_195.1, _fused_op_91, conv2d_194.dc.matmul.8],
         t: 1, mblock: [13, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 324], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 29}}
    conv2d_197.dc.matmul.8: {type: matmul, grid_loc: [6, 5], grid_size: [1, 1], inputs: [_fused_op_92, model.model.model.24.m.1.weight_0, model.model.model.24.m.1.bias_0],
         t: 1, mblock: [13, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 13}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_93_transpose_nop_11788: {type: nop, grid_loc: [7, 3], grid_size: [1, 1], inputs: [conv2d_197.dc.matmul.8],
         t: 1, mblock: [4, 13], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    _fused_op_93: {type: fused_op, grid_loc: [8, 5], grid_size: [1, 1], inputs: [_fused_op_93_transpose_nop_11788, dc.input_tensor.sigmoid_198.0],
         t: 1, mblock: [4, 13], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 93}}
    conv2d_218.dc.pad.8.dc.concatenate.1.dc.concatenate.0: {type: splice, grid_loc: [5, 4], grid_size: [1, 1], inputs: [_fused_op_92, dc.input_tensor.conv2d_218.dc.pad.8.0],
         t: 1, mblock: [16, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 26, 26], input1: [0, 6, 6]}}
    conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [6, 0], grid_size: [2, 1], inputs: [lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.0, conv2d_218.dc.pad.8.dc.concatenate.1.dc.concatenate.0, lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.1],
         t: 1, mblock: [18, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 70, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 8}}
    conv2d_218.dc.matmul.12: {type: matmul, grid_loc: [6, 1], grid_size: [2, 1], inputs: [conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.lc2, model.model.model.21.conv.weight_0],
         t: 1, mblock: [1, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 9, hstack: 9],
         attributes: {l1_acc: true, m_k: 8, min_buffer_input: 0, u_kt: 9}}
    _fused_op_95: {type: fused_op, grid_loc: [5, 5], grid_size: [1, 1], inputs: [conv2d_218.dc.matmul.12, model.model.model.21.conv.bias_0, dc.input_tensor.sigmoid_219.0, dc.input_tensor.sigmoid_219.1],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}],
         attributes: {approximate_mode: false, fused_op_id: 95}}
    concatenate_221.dc.concatenate.0: {type: splice, grid_loc: [6, 2], grid_size: [1, 1], inputs: [_fused_op_95, e2e__fused_op_59_0],
         t: 1, mblock: [2, 4], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 4, 4], input1: [0, 4, 4]}}
    conv2d_222.dc.matmul.8: {type: matmul, grid_loc: [6, 6], grid_size: [1, 1], inputs: [concatenate_221.dc.concatenate.0, model.model.model.23.cv1.conv.weight_0, model.model.model.23.cv1.conv.bias_0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 16}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 8}}
    _fused_op_96: {type: fused_op, grid_loc: [7, 4], grid_size: [1, 1], inputs: [conv2d_222.dc.matmul.8, dc.input_tensor.sigmoid_223.0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 96}}
    _fused_op_97: {type: fused_op, grid_loc: [7, 5], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_223.1, _fused_op_96, conv2d_222.dc.matmul.8],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 368], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 97}}
    conv2d_225.dc.matmul.8: {type: matmul, grid_loc: [8, 6], grid_size: [1, 1], inputs: [_fused_op_97, model.model.model.23.m.0.cv1.conv.weight_0, model.model.model.23.m.0.cv1.conv.bias_0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 16}, m_k: 1, min_buffer_input: 0, u_kt: 8}}
    _fused_op_98: {type: fused_op, grid_loc: [8, 7], grid_size: [1, 1], inputs: [conv2d_225.dc.matmul.8, dc.input_tensor.sigmoid_226.0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 96}}
    conv2d_231.dc.matmul.8: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [concatenate_221.dc.concatenate.0, model.model.model.23.cv2.conv.weight_0, model.model.model.23.cv2.conv.bias_0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 16}, l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 8}}
    _fused_op_102: {type: fused_op, grid_loc: [7, 6], grid_size: [1, 1], inputs: [conv2d_231.dc.matmul.8, dc.input_tensor.sigmoid_232.0],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 96}}
    _fused_op_103: {type: fused_op, grid_loc: [7, 7], grid_size: [1, 1], inputs: [dc.input_tensor.sigmoid_232.1, _fused_op_102, conv2d_231.dc.matmul.8],
         t: 1, mblock: [2, 2], ublock: [2, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 368], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 97}}

  fwd_0_9_temporal_epoch_9:
    target_device: 0
    input_count: 1
    _fused_op_82: {type: fused_op, grid_loc: [0, 6], grid_size: [4, 2], inputs: [dc.input_tensor.sigmoid_157.1, e2e__fused_op_81_0, input_1_multiply_158, input_2_concatenate_160, input_1_multiply_164, input_1_concatenate_165, input_1_multiply_168, input_1_multiply_171],
         t: 1, mblock: [1, 25], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0, 0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_4_tms: [broadcast: {c: 50}], input_2_tms: [broadcast: {c: 50}], input_1_tms: [vstack: 8], input_0_tms: [broadcast: {c: 50}],
         attributes: {approximate_mode: false, fused_op_id: 82}}
    reshape_174.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [4, 2], grid_size: [3, 1], inputs: [lc.input_tensor.reshape_174.dc.sparse_matmul.3.0, _fused_op_82, lc.input_tensor.reshape_174.dc.sparse_matmul.3.1],
         t: 1, mblock: [1, 25], ublock: [3, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 8, num_index_tiles: 1, num_sparse_tiles: 4, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 1}}
    _fused_op_94: {type: fused_op, grid_loc: [4, 0], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_198.1, e2e__fused_op_93_0, input_1_multiply_199, input_2_concatenate_201, input_1_multiply_205, input_1_concatenate_206, input_1_multiply_209, input_1_multiply_212],
         t: 1, mblock: [1, 13], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0, 0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 94}}
    reshape_215.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [4, 3], grid_size: [3, 1], inputs: [lc.input_tensor.reshape_215.dc.sparse_matmul.3.0, _fused_op_94, lc.input_tensor.reshape_215.dc.sparse_matmul.3.1],
         t: 1, mblock: [1, 13], ublock: [3, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 4, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 8}}
    reshape_217.dc.sparse_matmul.4.lc2: {type: matmul, grid_loc: [4, 7], grid_size: [2, 1], inputs: [lc.input_tensor.reshape_217.dc.sparse_matmul.4.0, reshape_215.dc.sparse_matmul.3.lc2, lc.input_tensor.reshape_217.dc.sparse_matmul.4.1],
         t: 1, mblock: [19, 1], ublock: [1, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose, hslice: 3, vstack: 3],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 3, num_index_tiles: 1, num_sparse_tiles: 5, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 13}}
    _fused_op_99: {type: fused_op, grid_loc: [0, 0], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_226.1, e2e__fused_op_98_0, e2e_conv2d_225.dc.matmul.8_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 24, 24], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 1], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.0, _fused_op_99, lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 1, mblock: [9, 1], ublock: [1, 8], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 14, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 4}}
    conv2d_228.dc.matmul.11: {type: matmul, grid_loc: [0, 2], grid_size: [4, 1], inputs: [conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, model.model.model.23.m.0.cv2.conv.weight_0, model.model.model.23.m.0.cv2.conv.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}], input_0_tms: [vslice: 9, hstack: 9],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 12, min_buffer_input: 0, u_kt: 6}}
    _fused_op_100: {type: fused_op, grid_loc: [0, 3], grid_size: [4, 1], inputs: [conv2d_228.dc.matmul.11, dc.input_tensor.sigmoid_229.0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 44}}
    _fused_op_101: {type: fused_op, grid_loc: [0, 4], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_229.1, _fused_op_100, conv2d_228.dc.matmul.11],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 456], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 45}}
    concatenate_234.dc.concatenate.0: {type: splice, grid_loc: [0, 5], grid_size: [4, 1], inputs: [_fused_op_101, e2e__fused_op_103_0],
         t: 1, mblock: [1, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {input0: [0, 2, 2], input1: [0, 2, 2]}}
    conv2d_235.dc.matmul.8: {type: matmul, grid_loc: [4, 1], grid_size: [4, 1], inputs: [concatenate_234.dc.concatenate.0, model.model.model.23.cv3.conv.weight_0, model.model.model.23.cv3.conv.bias_0],
         t: 1, mblock: [1, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 16}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_104: {type: fused_op, grid_loc: [4, 4], grid_size: [4, 1], inputs: [conv2d_235.dc.matmul.8, dc.input_tensor.sigmoid_236.0],
         t: 1, mblock: [1, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 56}}
    _fused_op_105: {type: fused_op, grid_loc: [4, 5], grid_size: [4, 1], inputs: [dc.input_tensor.sigmoid_236.1, _fused_op_104, conv2d_235.dc.matmul.8],
         t: 1, mblock: [1, 4], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [0, 0, 432], input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 57}}
    concatenate_259.dc.concatenate.2_transpose_nop_11316: {type: nop, grid_loc: [4, 6], grid_size: [3, 1], inputs: [reshape_174.dc.sparse_matmul.3.lc2],
         t: 3, mblock: [1, 25], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vslice: 3]}

  fwd_0_10_temporal_epoch_10:
    target_device: 0
    input_count: 1
    conv2d_238.dc.matmul.8: {type: matmul, grid_loc: [0, 0], grid_size: [4, 1], inputs: [e2e__fused_op_105_0, model.model.model.24.m.2.weight_0, model.model.model.24.m.2.bias_0],
         t: 1, mblock: [1, 2], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_2_tms: [broadcast: {r: 4}],
         attributes: {bias: true, kernel_broadcast: {input_2: 8}, l1_acc: true, m_k: 4, min_buffer_input: 0, u_kt: 4}}
    _fused_op_106_transpose_nop_11840: {type: nop, grid_loc: [0, 2], grid_size: [8, 1], inputs: [conv2d_238.dc.matmul.8],
         t: 1, mblock: [1, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    _fused_op_106: {type: fused_op, grid_loc: [0, 3], grid_size: [8, 1], inputs: [_fused_op_106_transpose_nop_11840, dc.input_tensor.sigmoid_239.0],
         t: 1, mblock: [1, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 106}}
    _fused_op_107: {type: fused_op, grid_loc: [0, 4], grid_size: [8, 1], inputs: [dc.input_tensor.sigmoid_239.1, _fused_op_106, input_1_multiply_240, input_2_concatenate_242, input_1_multiply_246, input_1_concatenate_247, input_1_multiply_250, input_1_multiply_253],
         t: 1, mblock: [1, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0, 0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false, fused_op_id: 107}}
    reshape_256.dc.sparse_matmul.3.lc2: {type: matmul, grid_loc: [0, 5], grid_size: [9, 1], inputs: [lc.input_tensor.reshape_256.dc.sparse_matmul.3.0, _fused_op_107, lc.input_tensor.reshape_256.dc.sparse_matmul.3.1],
         t: 1, mblock: [1, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 3, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 4}}
    reshape_258.dc.sparse_matmul.4.lc2: {type: matmul, grid_loc: [0, 6], grid_size: [5, 1], inputs: [lc.input_tensor.reshape_258.dc.sparse_matmul.4.0, reshape_256.dc.sparse_matmul.3.lc2, lc.input_tensor.reshape_258.dc.sparse_matmul.4.1],
         t: 1, mblock: [1, 1], ublock: [2, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose, hslice: 3, vstack: 3],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 3, num_index_tiles: 1, num_sparse_tiles: 5, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 4}}
    concatenate_259.dc.concatenate.2_transpose_nop_2_11316: {type: nop, grid_loc: [0, 1], grid_size: [5, 1], inputs: [e2e_concatenate_259.dc.concatenate.2_transpose_nop_11316_0],
         t: 3, mblock: [5, 3], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    concatenate_259.dc.concatenate.2: {type: splice, grid_loc: [8, 0], grid_size: [1, 3], inputs: [concatenate_259.dc.concatenate.2_transpose_nop_2_11316, e2e_reshape_217.dc.sparse_matmul.4.lc2_0, reshape_258.dc.sparse_matmul.4.lc2],
         t: 1, mblock: [99, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 3],
         attributes: {input0: [0, 75, 75], input1: [0, 19, 19], input2: [0, 5, 5]}}

  fwd_0_11_temporal_epoch_11:
    target_device: 0
    input_count: 1
    concatenate_259.dc.sparse_matmul.4.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [1, 1], inputs: [lc.input_tensor.concatenate_259.dc.sparse_matmul.4.0, e2e_concatenate_259.dc.concatenate.2_0, lc.input_tensor.concatenate_259.dc.sparse_matmul.4.1],
         t: 197, mblock: [1, 1], ublock: [1, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 3, num_index_tiles: 1, num_sparse_tiles: 6, sparse_tile_ptr_bits: 3, sparse_ublock_idx_bits: 3, u_kt: 66}}
    concatenate_259.dc.sparse_matmul.4.lc2_output_nop_0: {type: nop, grid_loc: [0, 1], grid_size: [1, 3], inputs: [concatenate_259.dc.sparse_matmul.4.lc2], untilize_output: true,
         t: 1, mblock: [197, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 197]}


programs:
  - run_fwd_0:
    - param: [$p_loop_count]
    - var: {$gptr_q4_shadow: 0, $lptr_q2: 0, $gptr_q2: 0, $gptr_q3: 0, $lptr_q3: 0, $lptr_q4: 0, $gptr_q5: 0, $lptr_q5: 0, $gptr_q6: 0, $lptr_q6: 0, $lptr_q1: 0, $c_zero: 0, $c_one: 1, $lptr_q11: 0, $c_microbatch_size: 1, $gptr_q10: 0, $lptr_q10: 0, $lptr_q7: 0, $gptr_q11: 0, $lptr_q9: 0, $gptr_q8: 0, $gptr_q9: 0, $gptr_q1: 0, $lptr_q8: 0, $gptr_q4: 0, $gptr_q7: 0}
    - staticvar: {$gptr_q0: 0, $lptr_q0: 0}
    - loop: $p_loop_count
    -   varinst: [$gptr_q4, set, $gptr_q4_shadow]
    -   allocate_queue: [e2e__fused_op_1_0, e2e_conv2d_6.dc.matmul.8_0]
    -   execute: {graph_name: fwd_0_0_temporal_epoch_0, queue_settings: {
               ims_1: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.0.conv.weight_0_fork_clone1818: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.0.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.0.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_0.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.0.conv.weight_0_fork_clone1816: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.1.conv.weight_0_fork_clone430: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.1.conv.weight_0_fork_clone428: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q0, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q0, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e__fused_op_3_0, e2e_conv2d_16.dc.matmul.8_0, e2e__fused_op_7_0]
    -   execute: {graph_name: fwd_0_1_temporal_epoch_1, queue_settings: {
               e2e__fused_op_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               e2e_conv2d_6.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               dc.input_tensor.sigmoid_7.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_7.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_17.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_1_0, e2e_conv2d_6.dc.matmul.8_0]
    -   varinst: [$gptr_q1, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q1, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_10_0]
    -   execute: {graph_name: fwd_0_2_temporal_epoch_2, queue_settings: {
               e2e__fused_op_3_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               e2e_conv2d_16.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               e2e__fused_op_7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               model.model.model.2.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_10.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_10.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.5.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.weight_0_fork_clone488: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_12.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.m.0.cv2.conv.weight_0_fork_clone486: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_13.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_13.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_17.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.2.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.2.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_21.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_21.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_3_0, e2e_conv2d_16.dc.matmul.8_0, e2e__fused_op_7_0]
    -   varinst: [$gptr_q2, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q2, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_26_0]
    -   execute: {graph_name: fwd_0_3_temporal_epoch_3, queue_settings: {
               e2e__fused_op_10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_23.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_24.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_24.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_27.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_27.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_30.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_30.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_32.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_33.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_33.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.1.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.1.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_37.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_37.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_39.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.m.1.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.m.1.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_40.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_40.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_44.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_44.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.4.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.4.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_48.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_48.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_10_0]
    -   varinst: [$gptr_q3, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q3, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e_conv2d_77.dc.matmul.8_0, e2e__fused_op_38_0, e2e__fused_op_39_0]
    -   execute: {graph_name: fwd_0_4_temporal_epoch_4, queue_settings: {
               e2e__fused_op_26_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_50.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.5.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.5.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_51.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_51.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_54.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_54.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_57.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_57.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_59.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_59.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_60.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_60.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.1.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.1.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_64.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_64.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_66.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_66.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.1.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.1.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_67.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_67.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.2.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.2.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_71.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_71.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_73.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_73.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.m.2.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.m.2.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_74.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_74.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_78.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q4_shadow, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q4, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_42_0, e2e_conv2d_97.dc.matmul.8_0, e2e__fused_op_49_0]
    -   execute: {graph_name: fwd_0_5_temporal_epoch_5, queue_settings: {
               e2e_conv2d_77.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e__fused_op_38_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e__fused_op_39_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               dc.input_tensor.sigmoid_78.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.6.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.6.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_82.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_82.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_84.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_84.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.7.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.7.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_85.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_85.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_88.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_88.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_91.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_91.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_93.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_94.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_94.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_77.dc.matmul.8_0, e2e__fused_op_38_0, e2e__fused_op_39_0]
    -   varinst: [$gptr_q5, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q5, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e_concatenate_118.dc.concatenate.0_0, e2e_conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0, e2e__fused_op_59_0]
    -   execute: {graph_name: fwd_0_6_temporal_epoch_6, queue_settings: {
               e2e__fused_op_42_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e_conv2d_97.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e__fused_op_49_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               dc.input_tensor.sigmoid_98.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_98.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.8.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.8.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_102.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_102.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.9.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.9.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_105.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_105.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_107.dc.sparse_matmul.5.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_108.dc.sparse_matmul.5.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.max_pool2d_109.dc.sparse_matmul.5.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.9.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.9.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_112.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_112.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.10.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.10.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_115.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_115.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_117.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_117.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_120.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_120.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_123.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_123.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_125.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_42_0, e2e_conv2d_97.dc.matmul.8_0, e2e__fused_op_49_0]
    -   varinst: [$gptr_q6, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q6, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_70_0, e2e__fused_op_76_0, e2e__fused_op_78_0]
    -   execute: {graph_name: fwd_0_7_temporal_epoch_7, queue_settings: {
               e2e__fused_op_26_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_concatenate_118.dc.concatenate.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_125.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_126.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_126.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_129.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_129.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.13.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.13.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_133.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_133.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.14.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.14.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_136.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_136.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_138.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.resize2d_138.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_141.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_141.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_144.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_144.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_146.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_147.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_147.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.17.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_150.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_150.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_26_0, e2e_concatenate_118.dc.concatenate.0_0, e2e_conv2d_125.dc.pad.8.dc.concatenate.1.dc.concatenate.0_0]
    -   varinst: [$gptr_q7, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q7, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e__fused_op_81_0, e2e__fused_op_93_0, e2e_conv2d_225.dc.matmul.8_0, e2e__fused_op_98_0, e2e__fused_op_103_0]
    -   execute: {graph_name: fwd_0_8_temporal_epoch_8, queue_settings: {
               e2e__fused_op_59_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e__fused_op_70_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e__fused_op_76_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e__fused_op_78_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               model.model.model.17.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.17.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_154.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_154.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.24.m.0.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.24.m.0.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_157.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_177.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.18.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.18.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_178.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_178.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_182.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_182.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_185.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_185.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_187.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_187.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_188.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_188.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_191.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_191.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.20.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.20.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_195.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_195.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.24.m.1.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.24.m.1.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_198.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.conv2d_218.dc.pad.8.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_218.dc.sparse_matmul.10.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.21.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.21.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_219.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_219.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_223.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_223.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.m.0.cv1.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.m.0.cv1.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_226.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_232.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_232.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_59_0, e2e__fused_op_70_0, e2e__fused_op_76_0, e2e__fused_op_78_0]
    -   varinst: [$gptr_q8, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q8, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e_reshape_217.dc.sparse_matmul.4.lc2_0, e2e__fused_op_105_0, e2e_concatenate_259.dc.concatenate.2_transpose_nop_11316_0]
    -   execute: {graph_name: fwd_0_9_temporal_epoch_9, queue_settings: {
               e2e__fused_op_81_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e__fused_op_93_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_conv2d_225.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e__fused_op_98_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e__fused_op_103_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               dc.input_tensor.sigmoid_157.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_158: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_2_concatenate_160: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_164: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_concatenate_165: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_168: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_171: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_174.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_174.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_198.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_199: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_2_concatenate_201: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_205: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_concatenate_206: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_209: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_212: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_215.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_215.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_217.dc.sparse_matmul.4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_217.dc.sparse_matmul.4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_226.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_228.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.m.0.cv2.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.m.0.cv2.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_229.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_229.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               model.model.model.23.cv3.conv.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.23.cv3.conv.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_236.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_236.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e__fused_op_81_0, e2e__fused_op_93_0, e2e_conv2d_225.dc.matmul.8_0, e2e__fused_op_98_0, e2e__fused_op_103_0]
    -   varinst: [$gptr_q9, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q9, incwrap, $c_microbatch_size, 2]
    -   allocate_queue: [e2e_concatenate_259.dc.concatenate.2_0]
    -   execute: {graph_name: fwd_0_10_temporal_epoch_10, queue_settings: {
               e2e_reshape_217.dc.sparse_matmul.4.lc2_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q10, rd_ptr_global: $gptr_q10},
               e2e__fused_op_105_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q10, rd_ptr_global: $gptr_q10},
               e2e_concatenate_259.dc.concatenate.2_transpose_nop_11316_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q10, rd_ptr_global: $gptr_q10},
               model.model.model.24.m.2.weight_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               model.model.model.24.m.2.bias_0: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_239.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.sigmoid_239.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_240: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_2_concatenate_242: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_246: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_concatenate_247: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_250: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_253: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_256.dc.sparse_matmul.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_256.dc.sparse_matmul.3.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_258.dc.sparse_matmul.4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.reshape_258.dc.sparse_matmul.4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_reshape_217.dc.sparse_matmul.4.lc2_0, e2e__fused_op_105_0, e2e_concatenate_259.dc.concatenate.2_transpose_nop_11316_0]
    -   varinst: [$gptr_q10, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q10, incwrap, $c_microbatch_size, 2]
    -   execute: {graph_name: fwd_0_11_temporal_epoch_11, queue_settings: {
               e2e_concatenate_259.dc.concatenate.2_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               lc.input_tensor.concatenate_259.dc.sparse_matmul.4.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.concatenate_259.dc.sparse_matmul.4.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_concatenate_259.dc.concatenate.2_0]
    -   varinst: [$gptr_q11, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q11, incwrap, $c_microbatch_size, 2]
    - endloop


fused_ops:
  0: 
    inputs: 5
    intermediates: 1
    schedules: 
      -
        - conv2d_0.dc.conv2d.3.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [4, 1], ublock: [2, 1], output: dest}
        - conv2d_0.dc.conv2d.3.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [4, 1], ublock: [2, 1], output: intermed0}
        - sigmoid_1.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input3], mblock: [4, 1], ublock: [2, 1], output: dest}
        - sigmoid_1.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [4, 1], ublock: [2, 1], output: dest}
        - sigmoid_1.dc.add.4.0: { type: add, inputs: [input4, dest], mblock: [4, 1], ublock: [2, 1], output: dest}
        - sigmoid_1.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [4, 1], ublock: [2, 1], output: dest}
        - multiply_2.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [4, 1], ublock: [2, 1], output: output}
  1: 
    inputs: 5
    intermediates: 1
    schedules: 
      -
        - conv2d_3.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 1], output: dest}
        - conv2d_3.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [25, 1], ublock: [1, 1], output: intermed0}
        - sigmoid_4.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input3], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_4.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_4.dc.add.4.0: { type: add, inputs: [input4, dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_4.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - multiply_5.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [25, 1], ublock: [1, 1], output: output}
  2: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_7.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_7.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: output}
  3: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_7.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 1], output: dest}
        - sigmoid_7.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [1, 1], output: dest}
        - multiply_8.0: { type: multiply, inputs: [input2, dest], mblock: [25, 1], ublock: [1, 1], output: output}
  4: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_10.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [25, 1], ublock: [2, 1], output: dest}
        - sigmoid_10.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [2, 1], output: output}
  5: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_10.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [2, 1], output: dest}
        - sigmoid_10.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [2, 1], output: dest}
        - multiply_11.0: { type: multiply, inputs: [input2, dest], mblock: [25, 1], ublock: [2, 1], output: output}
  6: 
    inputs: 6
    intermediates: 1
    schedules: 
      -
        - conv2d_12.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [5, 1], ublock: [1, 1], output: dest}
        - conv2d_12.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [5, 1], ublock: [1, 1], output: intermed0}
        - sigmoid_13.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input3], mblock: [5, 1], ublock: [1, 1], output: dest}
        - sigmoid_13.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [5, 1], ublock: [1, 1], output: dest}
        - sigmoid_13.dc.add.4.0: { type: add, inputs: [input4, dest], mblock: [5, 1], ublock: [1, 1], output: dest}
        - sigmoid_13.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [5, 1], ublock: [1, 1], output: dest}
        - multiply_14.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [5, 1], ublock: [1, 1], output: dest}
        - add_15.0: { type: add, inputs: [input5, dest], mblock: [5, 1], ublock: [1, 1], output: output}
  9: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_21.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [5, 1], ublock: [1, 2], output: dest}
        - sigmoid_21.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [5, 1], ublock: [1, 2], output: output}
  10: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_21.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [5, 1], ublock: [1, 2], output: dest}
        - sigmoid_21.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [5, 1], ublock: [1, 2], output: dest}
        - multiply_22.0: { type: multiply, inputs: [input2, dest], mblock: [5, 1], ublock: [1, 2], output: output}
  18: 
    inputs: 4
    intermediates: 0
    schedules: 
      -
        - sigmoid_33.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [5, 1], ublock: [1, 2], output: dest}
        - sigmoid_33.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [5, 1], ublock: [1, 2], output: dest}
        - multiply_34.0: { type: multiply, inputs: [input2, dest], mblock: [5, 1], ublock: [1, 2], output: dest}
        - add_35.0: { type: add, inputs: [input3, dest], mblock: [5, 1], ublock: [1, 2], output: output}
  26: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_48.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [25, 1], ublock: [1, 2], output: dest}
        - sigmoid_48.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [25, 1], ublock: [1, 2], output: dest}
        - multiply_49.0: { type: multiply, inputs: [input2, dest], mblock: [25, 1], ublock: [1, 2], output: output}
  27: 
    inputs: 4
    intermediates: 1
    schedules: 
      -
        - conv2d_50.dc.add.17.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 4], output: intermed0}
        - sigmoid_51.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_51.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_51.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_51.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - multiply_52.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [13, 1], ublock: [1, 4], output: output}
  28: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_54.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_54.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: output}
  29: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_54.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_54.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - multiply_55.0: { type: multiply, inputs: [input2, dest], mblock: [13, 1], ublock: [1, 4], output: output}
  32: 
    inputs: 5
    intermediates: 1
    schedules: 
      -
        - conv2d_59.dc.add.18.0: { type: add, inputs: [input0, input1], mblock: [13, 1], ublock: [1, 4], output: intermed0}
        - sigmoid_60.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_60.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_60.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - sigmoid_60.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [13, 1], ublock: [1, 4], output: dest}
        - multiply_61.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [13, 1], ublock: [1, 4], output: dest}
        - add_62.0: { type: add, inputs: [input4, dest], mblock: [13, 1], ublock: [1, 4], output: output}
  41: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_82.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [13, 2], ublock: [1, 4], output: dest}
        - sigmoid_82.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [13, 2], ublock: [1, 4], output: output}
  43: 
    inputs: 4
    intermediates: 1
    schedules: 
      -
        - conv2d_84.dc.add.18.0: { type: add, inputs: [input0, input1], mblock: [1, 4], ublock: [1, 4], output: intermed0}
        - sigmoid_85.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 4], ublock: [1, 4], output: dest}
        - sigmoid_85.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 4], ublock: [1, 4], output: dest}
        - sigmoid_85.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [1, 4], ublock: [1, 4], output: dest}
        - sigmoid_85.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 4], ublock: [1, 4], output: dest}
        - multiply_86.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [1, 4], ublock: [1, 4], output: output}
  44: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_88.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 2], ublock: [1, 4], output: dest}
        - sigmoid_88.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 2], ublock: [1, 4], output: output}
  45: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_88.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 2], ublock: [1, 4], output: dest}
        - sigmoid_88.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 2], ublock: [1, 4], output: dest}
        - multiply_89.0: { type: multiply, inputs: [input2, dest], mblock: [1, 2], ublock: [1, 4], output: output}
  49: 
    inputs: 4
    intermediates: 0
    schedules: 
      -
        - sigmoid_94.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 2], ublock: [1, 4], output: dest}
        - sigmoid_94.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 2], ublock: [1, 4], output: dest}
        - multiply_95.0: { type: multiply, inputs: [input2, dest], mblock: [1, 2], ublock: [1, 4], output: dest}
        - add_96.0: { type: add, inputs: [input3, dest], mblock: [1, 2], ublock: [1, 4], output: output}
  50: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_98.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 2], ublock: [2, 4], output: dest}
        - sigmoid_98.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 2], ublock: [2, 4], output: output}
  51: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_98.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 2], ublock: [2, 4], output: dest}
        - sigmoid_98.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 2], ublock: [2, 4], output: dest}
        - multiply_99.0: { type: multiply, inputs: [input2, dest], mblock: [1, 2], ublock: [2, 4], output: output}
  52: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_102.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 4], ublock: [2, 4], output: dest}
        - sigmoid_102.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 4], ublock: [2, 4], output: output}
  53: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_102.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 4], ublock: [2, 4], output: dest}
        - sigmoid_102.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 4], ublock: [2, 4], output: dest}
        - multiply_103.0: { type: multiply, inputs: [input2, dest], mblock: [1, 4], ublock: [2, 4], output: output}
  56: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_112.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 4], ublock: [1, 4], output: dest}
        - sigmoid_112.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 4], ublock: [1, 4], output: output}
  57: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_112.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 4], ublock: [1, 4], output: dest}
        - sigmoid_112.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 4], ublock: [1, 4], output: dest}
        - multiply_113.0: { type: multiply, inputs: [input2, dest], mblock: [1, 4], ublock: [1, 4], output: output}
  71: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_141.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [25, 1], ublock: [2, 2], output: dest}
        - sigmoid_141.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [25, 1], ublock: [2, 2], output: output}
  81: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_157.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 5], ublock: [1, 2], output: dest}
        - sigmoid_157.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 5], ublock: [1, 2], output: output}
  82: 
    inputs: 8
    intermediates: 2
    schedules: 
      -
        - sigmoid_157.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 25], ublock: [2, 1], output: dest}
        - sigmoid_157.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 25], ublock: [2, 1], output: intermed0}
        - multiply_158.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 25], ublock: [2, 1], output: intermed1}
        - multiply_159.0: { type: multiply, inputs: [intermed1, intermed1], pop: [intermed1], mblock: [1, 25], ublock: [2, 1], output: dest}
        - multiply_162.0: { type: multiply, inputs: [dest, input3], mblock: [1, 25], ublock: [2, 1], output: intermed1}
        - multiply_164.0: { type: multiply, inputs: [intermed0, input4], mblock: [1, 25], ublock: [2, 1], output: dest}
        - add_167.0: { type: add, inputs: [dest, input5], mblock: [1, 25], ublock: [2, 1], output: dest}
        - multiply_168.0: { type: multiply, inputs: [dest, input6], mblock: [1, 25], ublock: [2, 1], output: dest}
        - add_170.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 25], ublock: [2, 1], output: intermed1}
        - multiply_171.0: { type: multiply, inputs: [intermed0, input7], pop: [intermed0], mblock: [1, 25], ublock: [2, 1], output: dest}
        - add_172.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 25], ublock: [2, 1], output: output}
  93: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_198.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [4, 13], ublock: [2, 1], output: dest}
        - sigmoid_198.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [4, 13], ublock: [2, 1], output: output}
  94: 
    inputs: 8
    intermediates: 2
    schedules: 
      -
        - sigmoid_198.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 13], ublock: [2, 1], output: dest}
        - sigmoid_198.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 13], ublock: [2, 1], output: intermed0}
        - multiply_199.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 13], ublock: [2, 1], output: intermed1}
        - multiply_200.0: { type: multiply, inputs: [intermed1, intermed1], pop: [intermed1], mblock: [1, 13], ublock: [2, 1], output: dest}
        - multiply_203.0: { type: multiply, inputs: [dest, input3], mblock: [1, 13], ublock: [2, 1], output: intermed1}
        - multiply_205.0: { type: multiply, inputs: [intermed0, input4], mblock: [1, 13], ublock: [2, 1], output: dest}
        - add_208.0: { type: add, inputs: [dest, input5], mblock: [1, 13], ublock: [2, 1], output: dest}
        - multiply_209.0: { type: multiply, inputs: [dest, input6], mblock: [1, 13], ublock: [2, 1], output: dest}
        - add_211.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 13], ublock: [2, 1], output: intermed1}
        - multiply_212.0: { type: multiply, inputs: [intermed0, input7], pop: [intermed0], mblock: [1, 13], ublock: [2, 1], output: dest}
        - add_213.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 13], ublock: [2, 1], output: output}
  95: 
    inputs: 4
    intermediates: 1
    schedules: 
      -
        - conv2d_218.dc.add.18.0: { type: add, inputs: [input0, input1], mblock: [2, 2], ublock: [2, 4], output: intermed0}
        - sigmoid_219.dc.multiply.2.0: { type: multiply, inputs: [intermed0, input2], mblock: [2, 2], ublock: [2, 4], output: dest}
        - sigmoid_219.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [2, 2], ublock: [2, 4], output: dest}
        - sigmoid_219.dc.add.4.0: { type: add, inputs: [input3, dest], mblock: [2, 2], ublock: [2, 4], output: dest}
        - sigmoid_219.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [2, 2], ublock: [2, 4], output: dest}
        - multiply_220.0: { type: multiply, inputs: [intermed0, dest], pop: [intermed0], mblock: [2, 2], ublock: [2, 4], output: output}
  96: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_223.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [2, 2], ublock: [2, 4], output: dest}
        - sigmoid_223.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [2, 2], ublock: [2, 4], output: output}
  97: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - sigmoid_223.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [2, 2], ublock: [2, 4], output: dest}
        - sigmoid_223.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [2, 2], ublock: [2, 4], output: dest}
        - multiply_224.0: { type: multiply, inputs: [input2, dest], mblock: [2, 2], ublock: [2, 4], output: output}
  106: 
    inputs: 2
    intermediates: 0
    schedules: 
      -
        - sigmoid_239.dc.multiply.2.0: { type: multiply, inputs: [input0, input1], mblock: [1, 1], ublock: [1, 4], output: dest}
        - sigmoid_239.dc.exp.3.0: { type: exp, inputs: [dest], mblock: [1, 1], ublock: [1, 4], output: output}
  107: 
    inputs: 8
    intermediates: 2
    schedules: 
      -
        - sigmoid_239.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [1, 1], ublock: [1, 4], output: dest}
        - sigmoid_239.dc.reciprocal.5.0: { type: reciprocal, inputs: [dest], mblock: [1, 1], ublock: [1, 4], output: intermed0}
        - multiply_240.0: { type: multiply, inputs: [intermed0, input2], mblock: [1, 1], ublock: [1, 4], output: intermed1}
        - multiply_241.0: { type: multiply, inputs: [intermed1, intermed1], pop: [intermed1], mblock: [1, 1], ublock: [1, 4], output: dest}
        - multiply_244.0: { type: multiply, inputs: [dest, input3], mblock: [1, 1], ublock: [1, 4], output: intermed1}
        - multiply_246.0: { type: multiply, inputs: [intermed0, input4], mblock: [1, 1], ublock: [1, 4], output: dest}
        - add_249.0: { type: add, inputs: [dest, input5], mblock: [1, 1], ublock: [1, 4], output: dest}
        - multiply_250.0: { type: multiply, inputs: [dest, input6], mblock: [1, 1], ublock: [1, 4], output: dest}
        - add_252.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 1], ublock: [1, 4], output: intermed1}
        - multiply_253.0: { type: multiply, inputs: [intermed0, input7], pop: [intermed0], mblock: [1, 1], ublock: [1, 4], output: dest}
        - add_254.0: { type: add, inputs: [intermed1, dest], pop: [intermed1], mblock: [1, 1], ublock: [1, 4], output: output}
