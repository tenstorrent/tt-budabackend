devices:
  arch: [grayskull, wormhole, wormhole_b0]
queues:
  in_0:  {type: queue, input: HOST, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30000000]]}
  in_1:  {type: queue, input: HOST, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31000000]]}
  in_2:  {type: queue, input: HOST, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [2, 1], df: Bfp8_b, target_device: 0, loc: dram, dram: [[0, 0x35000000]]}
  in_3:  {type: queue, input: HOST, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 1], df: Bfp8_b, target_device: 0, loc: dram, dram: [[1, 0x30000000]]}
  output0:  {type: queue, input: op0 , entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 1], df: Bfp8_b, target_device: 0, loc: dram, dram: [[1, 0x3e000000]]}
graphs:
  test_op:
    target_device: 0
    input_count:  1
    op0:
      type: fused_op
      grid_loc: [0, 0]   # [r,c]
      grid_size: [1, 1] # [r,c]
      inputs: [in_0, in_1, in_2, in_3]
      in_df: [Float16_b, Float16_b, Bfp8_b, Bfp8_b]
      acc_df: Float16_b
      out_df: Bfp8_b
      intermed_df: Float16_b
      ublock_order: r
      buf_size_mb: 2
      math_fidelity: HiFi3
      untilize_output: false
      gradient_op: false
      attributes: {fused_op_id: 0}
      t: 1
      mblock: [3, 2]
      ublock: [1, 1]
programs:
  - program0:
      - staticvar: [$lptr, $gptr, $c_loop_count, $c_input_count]
      - var: [$ramrdptr, $ramwrptr]
      - varinst: [$c_loop_count, set, 1]  # load loop count
      - varinst: [$c_input_count, set, 1]  # load loop count
      - loop: $c_loop_count
      - execute: {graph_name: test_op, queue_settings: {
         in_0: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr},
         in_1: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr},
         in_2: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr},
         in_3: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr}
         }}
      -   varinst: [$lptr, incwrap, $c_input_count, 2]
      -   varinst: [$gptr, incwrap, $c_input_count, 2]
      - endloop
fused_ops:
  0:
    inputs: 4
    intermediates: 5
    schedules:
      -
        - multiply0: { type: multiply, inputs: [input0, input0], mblock: [1, 1], ublock: [1, 2], output: intermed0}  
        # should have its own init call and packer/unpacker reconfig since it has bcast increasing mblock dimensions
        - multiply1: { type: multiply, inputs: [input1, intermed0], pop: [intermed0], input_1_tms: [broadcast: {r: 3}], mblock: [3, 1], ublock: [1, 2], output: intermed1}
        - matmul0: { type: matmul, inputs: [intermed1, input2], pop: [intermed1], attributes: {m_k: 1, u_kt: 2}, mblock: [3, 1], ublock: [1, 1], output: intermed2}
      -
        - nop: { type: nop, inputs: [intermed2], pop: [intermed2], mblock: [3, 1], ublock: [1, 1], output: intermed3}
        # should have its own init call and packer/unpacker reconfig since it has bcast increasing mblock dimensions
        - abs: { type: abs, inputs: [intermed3], pop: [intermed3], input_0_tms: [broadcast: {c: 2}], mblock: [3, 2], ublock: [1, 1], output: intermed4}
        - add: { type: add, inputs: [input3, intermed4], pop: [intermed4], mblock: [3, 2], ublock: [1, 1], output: output}
test-config:
  comparison-config:
    type: AllCloseHw
    atol: 0.01
    rtol: 0.15
    check_pct: 0.9
    check_pcc: 0.99
    verbosity: Concise
  stimulus-config:
    type: Uniform
    uniform_lower_bound: 0.1
    uniform_upper_bound: 1.0