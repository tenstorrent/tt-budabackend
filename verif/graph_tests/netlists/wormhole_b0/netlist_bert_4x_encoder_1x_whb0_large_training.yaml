# git checkout 435f4d73
# pytest pybuda/test/backend/models/test_bert.py::test_pt_encoder[training-Wormhole_B0-chip1-enc4-large]

devices:
  arch: wormhole_b0

queues:

  # input
  hidden_states:                                                               {input: HOST, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [12, 32], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4f65040]]}
  attention_mask:                                                              {input: HOST, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [12, 12], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x90ae1a0]]}

  # output
  bert_encoder.output_layernorm_439:                                           {input: layernorm_439.dc.add.10, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [6, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: host, host: [0x0]}

  # parameter
  layer.0.attention.self.query.weight:                                         {input: opt_in1_layer.0.attention.self.query.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x41fd460], [1, 0x423e480], [1, 0x427f4a0], [1, 0x42c04c0], [1, 0x43014e0], [1, 0x4342500], [1, 0x4383520], [1, 0x43c4540]]}
  layer.0.attention.self.query.bias:                                           {input: opt_in1_layer.0.attention.self.query.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9cabc40]]}
  layer.0.attention.self.key.weight:                                           {input: opt_in1_layer.0.attention.self.key.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4b51e60], [2, 0x4b92e80], [2, 0x4bd3ea0], [2, 0x4c14ec0], [2, 0x4c55ee0], [2, 0x4c96f00], [2, 0x4cd7f20], [2, 0x4d18f40]]}
  layer.0.attention.self.key.bias:                                             {input: opt_in1_layer.0.attention.self.key.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f24120]]}
  layer.0.attention.self.value.weight:                                         {input: opt_in1_layer.0.attention.self.value.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4949d60], [2, 0x498ad80], [2, 0x49cbda0], [2, 0x4a0cdc0], [2, 0x4a4dde0], [2, 0x4a8ee00], [2, 0x4acfe20], [2, 0x4b10e40]]}
  layer.0.attention.self.value.bias:                                           {input: opt_in1_layer.0.attention.self.value.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f13d00]]}
  layer.0.attention.output.dense.weight:                                       {input: opt_in0_layer.0.attention.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4d5c700], [5, 0x4d9d720], [5, 0x4dde740], [5, 0x4e1f760], [5, 0x4e60780], [5, 0x4ea17a0], [5, 0x4ee27c0], [5, 0x4f237e0]]}
  layer.0.attention.output.dense.bias:                                         {input: opt_in1_layer.0.attention.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9c9afe0]]}
  layer.0.attention.output.LayerNorm.weight:                                   {input: opt_in1_layer.0.attention.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4939100]]}
  layer.0.attention.output.LayerNorm.bias:                                     {input: opt_in2_layer.0.attention.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x469d520]]}
  layer.0.intermediate.dense.weight:                                           {input: opt_in0_layer.0.intermediate.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [4, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5489dc0], [5, 0x54cade0], [5, 0x550be00], [5, 0x554ce20], [5, 0x558de40], [5, 0x55cee60], [5, 0x560fe80], [5, 0x5650ea0], [5, 0x5691ec0], [5, 0x56d2ee0], [5, 0x5713f00], [5, 0x5754f20], [5, 0x5795f40], [5, 0x57d6f60], [5, 0x5817f80], [5, 0x5858fa0], [5, 0x5899fc0], [5, 0x58dafe0], [5, 0x591c000], [5, 0x595d020], [5, 0x599e040], [5, 0x59df060], [5, 0x5a20080], [5, 0x5a610a0], [5, 0x5aa20c0], [5, 0x5ae30e0], [5, 0x5b24100], [5, 0x5b65120], [5, 0x5ba6140], [5, 0x5be7160], [5, 0x5c28180], [5, 0x5c691a0]]}
  layer.0.intermediate.dense.bias:                                             {input: opt_in1_layer.0.intermediate.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9cdf980]]}
  layer.0.output.dense.weight:                                                 {input: opt_in0_layer.0.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4f65980], [2, 0x4fa69a0], [2, 0x4fe79c0], [2, 0x50289e0], [2, 0x5069a00], [2, 0x50aaa20], [2, 0x50eba40], [2, 0x512ca60], [2, 0x516da80], [2, 0x51aeaa0], [2, 0x51efac0], [2, 0x5230ae0], [2, 0x5271b00], [2, 0x52b2b20], [2, 0x52f3b40], [2, 0x5334b60], [2, 0x5375b80], [2, 0x53b6ba0], [2, 0x53f7bc0], [2, 0x5438be0], [2, 0x5479c00], [2, 0x54bac20], [2, 0x54fbc40], [2, 0x553cc60], [2, 0x557dc80], [2, 0x55beca0], [2, 0x55ffcc0], [2, 0x5640ce0], [2, 0x5681d00], [2, 0x56c2d20], [2, 0x5703d40], [2, 0x5744d60]]}
  layer.0.output.dense.bias:                                                   {input: opt_in1_layer.0.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f459e0]]}
  layer.0.output.LayerNorm.weight:                                             {input: opt_in1_layer.0.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5479160]]}
  layer.0.output.LayerNorm.bias:                                               {input: opt_in2_layer.0.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9ccc480]]}
  layer.1.attention.self.query.weight:                                         {input: opt_in0_layer.1.attention.self.query.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4d5a7a0], [2, 0x4d9b7c0], [2, 0x4ddc7e0], [2, 0x4e1d800], [2, 0x4e5e820], [2, 0x4e9f840], [2, 0x4ee0860], [2, 0x4f21880]]}
  layer.1.attention.self.query.bias:                                           {input: opt_in1_layer.1.attention.self.query.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f34d80]]}
  layer.1.attention.self.key.weight:                                           {input: opt_in0_layer.1.attention.self.key.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5271060], [5, 0x52b2080], [5, 0x52f30a0], [5, 0x53340c0], [5, 0x53750e0], [5, 0x53b6100], [5, 0x53f7120], [5, 0x5438140]]}
  layer.1.attention.self.key.bias:                                             {input: opt_in1_layer.1.attention.self.key.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9cbc060]]}
  layer.1.attention.self.value.weight:                                         {input: opt_in0_layer.1.attention.self.value.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4493b60], [1, 0x44d4b80], [1, 0x4515ba0], [1, 0x4556bc0], [1, 0x4597be0], [1, 0x45d8c00], [1, 0x4619c20], [1, 0x465ac40]]}
  layer.1.attention.self.value.bias:                                           {input: opt_in1_layer.1.attention.self.value.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9088780]]}
  layer.1.attention.output.dense.weight:                                       {input: opt_in0_layer.1.attention.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9866c80], [3, 0x98a7ca0], [3, 0x98e8cc0], [3, 0x9929ce0], [3, 0x996ad00], [3, 0x99abd20], [3, 0x99ecd40], [3, 0x9a2dd60]]}
  layer.1.attention.output.dense.bias:                                         {input: opt_in1_layer.1.attention.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4472ae0]]}
  layer.1.attention.output.LayerNorm.weight:                                   {input: opt_in1_layer.1.attention.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4ce61e0]]}
  layer.1.attention.output.LayerNorm.bias:                                     {input: opt_in2_layer.1.attention.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9075280]]}
  layer.1.intermediate.dense.weight:                                           {input: opt_in0_layer.1.intermediate.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [4, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x90437a0], [3, 0x90847c0], [3, 0x90c57e0], [3, 0x9106800], [3, 0x9147820], [3, 0x9188840], [3, 0x91c9860], [3, 0x920a880], [3, 0x924b8a0], [3, 0x928c8c0], [3, 0x92cd8e0], [3, 0x930e900], [3, 0x934f920], [3, 0x9390940], [3, 0x93d1960], [3, 0x9412980], [3, 0x94539a0], [3, 0x94949c0], [3, 0x94d59e0], [3, 0x9516a00], [3, 0x9557a20], [3, 0x9598a40], [3, 0x95d9a60], [3, 0x961aa80], [3, 0x965baa0], [3, 0x969cac0], [3, 0x96ddae0], [3, 0x971eb00], [3, 0x975fb20], [3, 0x97a0b40], [3, 0x97e1b60], [3, 0x9822b80]]}
  layer.1.intermediate.dense.bias:                                             {input: opt_in1_layer.1.intermediate.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4431280]]}
  layer.1.output.dense.weight:                                                 {input: opt_in0_layer.1.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x44c5de0], [0, 0x4506e00], [0, 0x4547e20], [0, 0x4588e40], [0, 0x45c9e60], [0, 0x460ae80], [0, 0x464bea0], [0, 0x468cec0], [0, 0x46cdee0], [0, 0x470ef00], [0, 0x474ff20], [0, 0x4790f40], [0, 0x47d1f60], [0, 0x4812f80], [0, 0x4853fa0], [0, 0x4894fc0], [0, 0x48d5fe0], [0, 0x4917000], [0, 0x4958020], [0, 0x4999040], [0, 0x49da060], [0, 0x4a1b080], [0, 0x4a5c0a0], [0, 0x4a9d0c0], [0, 0x4ade0e0], [0, 0x4b1f100], [0, 0x4b60120], [0, 0x4ba1140], [0, 0x4be2160], [0, 0x4c23180], [0, 0x4c641a0], [0, 0x4ca51c0]]}
  layer.1.output.dense.bias:                                                   {input: opt_in1_layer.1.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9064e60]]}
  layer.1.output.LayerNorm.weight:                                             {input: opt_in1_layer.1.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4d49200]]}
  layer.1.output.LayerNorm.bias:                                               {input: opt_in2_layer.1.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9c8a380]]}
  layer.2.attention.self.query.weight:                                         {input: opt_in0_layer.2.attention.self.query.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4731000], [2, 0x4772020], [2, 0x47b3040], [2, 0x47f4060], [2, 0x4835080], [2, 0x48760a0], [2, 0x48b70c0], [2, 0x48f80e0]]}
  layer.2.attention.self.query.bias:                                           {input: opt_in1_layer.2.attention.self.query.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4efffc0]]}
  layer.2.attention.self.key.weight:                                           {input: opt_in0_layer.2.attention.self.key.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b41100], [5, 0x4b82120], [5, 0x4bc3140], [5, 0x4c04160], [5, 0x4c45180], [5, 0x4c861a0], [5, 0x4cc71c0], [5, 0x4d081e0]]}
  layer.2.attention.self.key.bias:                                             {input: opt_in1_layer.2.attention.self.key.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9c79f60]]}
  layer.2.attention.self.value.weight:                                         {input: opt_in0_layer.2.attention.self.value.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4cf7ec0], [0, 0x4d38ee0], [0, 0x4d79f00], [0, 0x4dbaf20], [0, 0x4dfbf40], [0, 0x4e3cf60], [0, 0x4e7df80], [0, 0x4ebefa0]]}
  layer.2.attention.self.value.bias:                                           {input: opt_in1_layer.2.attention.self.value.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x909bc80]]}
  layer.2.attention.output.dense.weight:                                       {input: opt_in0_layer.2.attention.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9a71e60], [3, 0x9ab2e80], [3, 0x9af3ea0], [3, 0x9b34ec0], [3, 0x9b75ee0], [3, 0x9bb6f00], [3, 0x9bf7f20], [3, 0x9c38f40]]}
  layer.2.attention.output.dense.bias:                                         {input: opt_in1_layer.2.attention.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4483740]]}
  layer.2.attention.output.LayerNorm.weight:                                   {input: opt_in1_layer.2.attention.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46e1720]]}
  layer.2.attention.output.LayerNorm.bias:                                     {input: opt_in2_layer.2.attention.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x926a100]]}
  layer.2.intermediate.dense.weight:                                           {input: opt_in0_layer.2.intermediate.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [4, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xaa46ac0], [3, 0xaa87ae0], [3, 0xaac8b00], [3, 0xab09b20], [3, 0xab4ab40], [3, 0xab8bb60], [3, 0xabccb80], [3, 0xac0dba0], [3, 0xac4ebc0], [3, 0xac8fbe0], [3, 0xacd0c00], [3, 0xad11c20], [3, 0xad52c40], [3, 0xad93c60], [3, 0xadd4c80], [3, 0xae15ca0], [3, 0xae56cc0], [3, 0xae97ce0], [3, 0xaed8d00], [3, 0xaf19d20], [3, 0xaf5ad40], [3, 0xaf9bd60], [3, 0xafdcd80], [3, 0xb01dda0], [3, 0xb05edc0], [3, 0xb09fde0], [3, 0xb0e0e00], [3, 0xb121e20], [3, 0xb162e40], [3, 0xb1a3e60], [3, 0xb1e4e80], [3, 0xb225ea0]]}
  layer.2.intermediate.dense.bias:                                             {input: opt_in1_layer.2.intermediate.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4726900]]}
  layer.2.output.dense.weight:                                                 {input: opt_in0_layer.2.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x5b9c800], [0, 0x5bdd820], [0, 0x5c1e840], [0, 0x5c5f860], [0, 0x5ca0880], [0, 0x5ce18a0], [0, 0x5d228c0], [0, 0x5d638e0], [0, 0x5da4900], [0, 0x5de5920], [0, 0x5e26940], [0, 0x5e67960], [0, 0x5ea8980], [0, 0x5ee99a0], [0, 0x5f2a9c0], [0, 0x5f6b9e0], [0, 0x5faca00], [0, 0x5feda20], [0, 0x602ea40], [0, 0x606fa60], [0, 0x60b0a80], [0, 0x60f1aa0], [0, 0x6132ac0], [0, 0x6173ae0], [0, 0x61b4b00], [0, 0x61f5b20], [0, 0x6236b40], [0, 0x6277b60], [0, 0x62b8b80], [0, 0x62f9ba0], [0, 0x633abc0], [0, 0x637bbe0]]}
  layer.2.output.dense.bias:                                                   {input: opt_in1_layer.2.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9259ce0]]}
  layer.2.output.LayerNorm.weight:                                             {input: opt_in1_layer.2.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xaa35e60]]}
  layer.2.output.LayerNorm.bias:                                               {input: opt_in2_layer.2.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4713400]]}
  layer.3.attention.self.query.weight:                                         {input: opt_in0_layer.3.attention.self.query.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x5991620], [0, 0x59d2640], [0, 0x5a13660], [0, 0x5a54680], [0, 0x5a956a0], [0, 0x5ad66c0], [0, 0x5b176e0], [0, 0x5b58700]]}
  layer.3.attention.self.query.bias:                                           {input: opt_in1_layer.3.attention.self.query.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9249080]]}
  layer.3.attention.self.key.weight:                                           {input: opt_in0_layer.3.attention.self.key.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa82dd60], [3, 0xa86ed80], [3, 0xa8afda0], [3, 0xa8f0dc0], [3, 0xa931de0], [3, 0xa972e00], [3, 0xa9b3e20], [3, 0xa9f4e40]]}
  layer.3.attention.self.key.bias:                                             {input: opt_in1_layer.3.attention.self.key.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4702fe0]]}
  layer.3.attention.self.value.weight:                                         {input: opt_in0_layer.3.attention.self.value.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x62854a0], [5, 0x62c64c0], [5, 0x63074e0], [5, 0x6348500], [5, 0x6389520], [5, 0x63ca540], [5, 0x640b560], [5, 0x644c580]]}
  layer.3.attention.self.value.bias:                                           {input: opt_in1_layer.3.attention.self.value.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb28a7e0]]}
  layer.3.attention.output.dense.weight:                                       {input: opt_in0_layer.3.attention.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x61d6da0], [2, 0x6217dc0], [2, 0x6258de0], [2, 0x6299e00], [2, 0x62dae20], [2, 0x631be40], [2, 0x635ce60], [2, 0x639de80]]}
  layer.3.attention.output.dense.bias:                                         {input: opt_in1_layer.3.attention.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x6401540]]}
  layer.3.attention.output.LayerNorm.weight:                                   {input: opt_in1_layer.3.attention.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6cad9a0]]}
  layer.3.attention.output.LayerNorm.bias:                                     {input: opt_in2_layer.3.attention.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb2772e0]]}
  layer.3.intermediate.dense.weight:                                           {input: opt_in0_layer.3.intermediate.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [4, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x59b38c0], [2, 0x59f48e0], [2, 0x5a35900], [2, 0x5a76920], [2, 0x5ab7940], [2, 0x5af8960], [2, 0x5b39980], [2, 0x5b7a9a0], [2, 0x5bbb9c0], [2, 0x5bfc9e0], [2, 0x5c3da00], [2, 0x5c7ea20], [2, 0x5cbfa40], [2, 0x5d00a60], [2, 0x5d41a80], [2, 0x5d82aa0], [2, 0x5dc3ac0], [2, 0x5e04ae0], [2, 0x5e45b00], [2, 0x5e86b20], [2, 0x5ec7b40], [2, 0x5f08b60], [2, 0x5f49b80], [2, 0x5f8aba0], [2, 0x5fcbbc0], [2, 0x600cbe0], [2, 0x604dc00], [2, 0x608ec20], [2, 0x60cfc40], [2, 0x6110c60], [2, 0x6151c80], [2, 0x6192ca0]]}
  layer.3.intermediate.dense.bias:                                             {input: opt_in1_layer.3.intermediate.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x63bfce0]]}
  layer.3.output.dense.weight:                                                 {input: opt_in0_layer.3.output.dense.weight_subtract_2, type: ram, entries: 1, grid_size: [4, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x648d5a0], [5, 0x64ce5c0], [5, 0x650f5e0], [5, 0x6550600], [5, 0x6591620], [5, 0x65d2640], [5, 0x6613660], [5, 0x6654680], [5, 0x66956a0], [5, 0x66d66c0], [5, 0x67176e0], [5, 0x6758700], [5, 0x6799720], [5, 0x67da740], [5, 0x681b760], [5, 0x685c780], [5, 0x689d7a0], [5, 0x68de7c0], [5, 0x691f7e0], [5, 0x6960800], [5, 0x69a1820], [5, 0x69e2840], [5, 0x6a23860], [5, 0x6a64880], [5, 0x6aa58a0], [5, 0x6ae68c0], [5, 0x6b278e0], [5, 0x6b68900], [5, 0x6ba9920], [5, 0x6bea940], [5, 0x6c2b960], [5, 0x6c6c980]]}
  layer.3.output.dense.bias:                                                   {input: opt_in1_layer.3.output.dense.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb266ec0]]}
  layer.3.output.LayerNorm.weight:                                             {input: opt_in1_layer.3.output.LayerNorm.weight_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa604420]]}
  layer.3.output.LayerNorm.bias:                                               {input: opt_in2_layer.3.output.LayerNorm.bias_subtract_2, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46d1300]]}

  # constant
  lc.input_tensor.layer.0.attention.self.query.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x91d29c0]]}
  lc.input_tensor.layer.0.attention.self.key.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46ad940]]}
  input_1_multiply_244_fork_clone1647_tile_bcast_tile_bcast:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4f64800]]}
  lc.input_tensor.softmax_246.dc.reduce_sum.1.0:                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9cab400]]}
  lc.input_tensor.layer.0.attention.self.value.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f103e0]]}
  lc.input_tensor.layer.0.attention.output.dense.bias_s_brcst_m2_1_0.0:        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x90ad960]]}
  lc.input_tensor.layernorm_266.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4949520]]}
  lc.input_tensor.layernorm_266.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x469cce0]]}
  dc.input_tensor.layernorm_266.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4d59620], [0, 0x4f10c20]]}
  lc.input_tensor.layernorm_266.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x90ad120]]}
  lc.input_tensor.layer.0.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9c9a7a0]]}
  lc.input_tensor.layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0:    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x469c4a0]]}
  lc.input_tensor.layer.0.intermediate.dense.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x91d4ac0]]}
  lc.input_tensor.layer.0.output.dense.bias_s_brcst_m2_1_0.0:                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46afa40]]}
  lc.input_tensor.layernorm_280.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5489580]]}
  lc.input_tensor.layernorm_280.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x91d4280]]}
  dc.input_tensor.layernorm_280.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4f628a0], [3, 0x9cdc8a0]]}
  lc.input_tensor.layernorm_280.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46af200]]}
  lc.input_tensor.layer.0.output.LayerNorm.weight_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f34540]]}
  lc.input_tensor.layer.0.output.LayerNorm.bias_s_brcst_m2_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x91d3a40]]}
  lc.input_tensor.layer.1.attention.self.query.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46ae9c0]]}
  lc.input_tensor.layer.1.attention.self.key.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x91d3200]]}
  input_1_multiply_297_fork_clone1670_tile_bcast_tile_bcast:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4d59f60]]}
  lc.input_tensor.softmax_299.dc.reduce_sum.1.0:                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46ae180]]}
  lc.input_tensor.layer.1.attention.self.value.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b3f840]]}
  lc.input_tensor.layer.1.attention.output.dense.bias_s_brcst_m2_1_0.0:        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472ef00]]}
  lc.input_tensor.layernorm_319.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4cf6600]]}
  lc.input_tensor.layernorm_319.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b3f000]]}
  dc.input_tensor.layernorm_319.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9863ba0], [4, 0x90856a0]]}
  lc.input_tensor.layernorm_319.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472e6c0]]}
  lc.input_tensor.layer.1.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x44722a0]]}
  lc.input_tensor.layer.1.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0:    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9064620]]}
  lc.input_tensor.layer.1.intermediate.dense.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472de80]]}
  lc.input_tensor.layer.1.output.dense.bias_s_brcst_m2_1_0.0:                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b3df80]]}
  lc.input_tensor.layernorm_333.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9042f60]]}
  lc.input_tensor.layernorm_333.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472d640]]}
  dc.input_tensor.layernorm_333.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x44c2d00], [1, 0x442e1a0]]}
  lc.input_tensor.layernorm_333.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b3d740]]}
  lc.input_tensor.layer.1.output.LayerNorm.weight_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b3e7c0]]}
  lc.input_tensor.layer.1.output.LayerNorm.bias_s_brcst_m2_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x90ac8e0]]}
  lc.input_tensor.layer.2.attention.self.query.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x469bc60]]}
  lc.input_tensor.layer.2.attention.self.key.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x90ac0a0]]}
  input_1_multiply_350_fork_clone1693_tile_bcast_tile_bcast:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x47307c0]]}
  lc.input_tensor.softmax_352.dc.reduce_sum.1.0:                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4cf6e40]]}
  lc.input_tensor.layer.2.attention.self.value.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b408c0]]}
  lc.input_tensor.layer.2.attention.output.dense.bias_s_brcst_m2_1_0.0:        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472ff80]]}
  lc.input_tensor.layernorm_372.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4cf7680]]}
  lc.input_tensor.layernorm_372.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b40080]]}
  dc.input_tensor.layernorm_372.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9a6ed80], [4, 0x9098ba0]]}
  lc.input_tensor.layernorm_372.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472f740]]}
  lc.input_tensor.layer.2.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4482f00]]}
  lc.input_tensor.layer.2.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0:    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x598fd60]]}
  lc.input_tensor.layer.2.intermediate.dense.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x59b2840]]}
  lc.input_tensor.layer.2.output.dense.bias_s_brcst_m2_1_0.0:                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6284c60]]}
  lc.input_tensor.layernorm_386.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xaa46280]]}
  lc.input_tensor.layernorm_386.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x59b2000]]}
  dc.input_tensor.layernorm_386.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x5b99720], [1, 0x4723820]]}
  lc.input_tensor.layernorm_386.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x62833a0]]}
  lc.input_tensor.layer.2.output.LayerNorm.weight_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x92594a0]]}
  lc.input_tensor.layer.2.output.LayerNorm.bias_s_brcst_m2_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x59b17c0]]}
  lc.input_tensor.layer.3.attention.self.query.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6283be0]]}
  lc.input_tensor.layer.3.attention.self.key.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x59b0f80]]}
  input_1_multiply_403_fork_clone1716_tile_bcast_tile_bcast:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x5990de0]]}
  lc.input_tensor.softmax_405.dc.reduce_sum.1.0:                               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6cbe600]]}
  lc.input_tensor.layer.3.attention.self.value.bias_s_brcst_m2_1_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x927bde0]]}
  lc.input_tensor.layer.3.attention.output.dense.bias_s_brcst_m2_1_0.0:        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x476ba80]]}
  lc.input_tensor.layernorm_425.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6cbddc0]]}
  lc.input_tensor.layernorm_425.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x927b5a0]]}
  dc.input_tensor.layernorm_425.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x61d3cc0], [3, 0xb287700]]}
  lc.input_tensor.layernorm_425.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x476b240]]}
  lc.input_tensor.layer.3.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x6400d00]]}
  lc.input_tensor.layer.3.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0:    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x927ad60]]}
  lc.input_tensor.layer.3.intermediate.dense.bias_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x476aa00]]}
  lc.input_tensor.layer.3.output.dense.bias_s_brcst_m2_1_0.0:                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x927a520]]}
  lc.input_tensor.layernorm_439.dc.reduce_avg.0.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x59b3080]]}
  lc.input_tensor.layernorm_439.dc.reduce_avg.3.0:                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6284420]]}
  dc.input_tensor.layernorm_439.4:                                             {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x63bcc00], [1, 0x4767920]]}
  lc.input_tensor.layernorm_439.dc.reciprocal.7_s_brcst_m1_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5fb7260]]}
  lc.input_tensor.layer.3.output.LayerNorm.weight_s_brcst_m2_1_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9226f80]]}
  lc.input_tensor.layer.3.output.LayerNorm.bias_s_brcst_m2_1_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x5797220]]}
  lc.input_tensor.bw_in2_layernorm_439_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x5777080]]}
  lc.input_tensor.bw_in1_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa603be0]]}
  lc.input_tensor.layernorm_439.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46d0ac0]]}
  lc.input_tensor.layer.3.output.LayerNorm.weight_s_brcst_m2_2_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f55e00]]}
  lc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5caaa00]]}
  lc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9216320]]}
  dc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa540ba0], [3, 0xa5a23c0]]}
  lc.input_tensor.bw_in1_add_436_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x57865c0]]}
  lc.input_tensor.bw_in1_add_430_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5caa1c0]]}
  lc.input_tensor.bw_in2_layernorm_425_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x5785d80]]}
  lc.input_tensor.bw_in1_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x5776840]]}
  lc.input_tensor.layernorm_425.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa82d520]]}
  lc.input_tensor.layer.3.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x59b0740]]}
  lc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x47027a0]]}
  lc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x59905a0]]}
  dc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x61c0360], [5, 0x6221b80]]}
  lc.input_tensor.bw_in1_add_422_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9238420]]}
  lc.input_tensor.bw_in1_add_411_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4701f60]]}
  lc.input_tensor.bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9237be0]]}
  input_1_multiply_403_tile_bcast_tile_bcast:                                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa81c8c0]]}
  lc.input_tensor.bw_in1_add_397_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x57a7e80]]}
  lc.input_tensor.bw_in1_add_391_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5fb7aa0]]}
  lc.input_tensor.bw_in2_layernorm_386_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f451a0]]}
  lc.input_tensor.bw_in1_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38f8120]]}
  lc.input_tensor.layernorm_386.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42f4900]]}
  lc.input_tensor.layer.2.output.LayerNorm.weight_s_brcst_m2_2_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8c1c540]]}
  lc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x895f9a0]]}
  lc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x44dc980]]}
  dc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x413a420], [1, 0x419bc40]]}
  lc.input_tensor.bw_in1_add_383_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4089fc0]]}
  lc.input_tensor.bw_in1_add_377_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83fb2c0]]}
  lc.input_tensor.bw_in2_layernorm_372_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4089780]]}
  lc.input_tensor.bw_in1_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83fbb00]]}
  lc.input_tensor.layernorm_372.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x449b120]]}
  lc.input_tensor.layer.2.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x39199e0]]}
  lc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4088f40]]}
  lc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42d3880]]}
  dc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x889c960], [3, 0x88fe180]]}
  lc.input_tensor.bw_in1_add_369_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x43065e0]]}
  lc.input_tensor.bw_in1_add_358_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4705a80]]}
  lc.input_tensor.bw_in0_softmax_352_softmax_bw_0.dc.reduce_sum.1.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4305da0]]}
  input_1_multiply_350_tile_bcast_tile_bcast:                                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e25640]]}
  lc.input_tensor.bw_in1_add_344_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8961260]]}
  lc.input_tensor.bw_in1_add_338_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40ab040]]}
  lc.input_tensor.bw_in2_layernorm_333_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8960a20]]}
  lc.input_tensor.bw_in1_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4405560]]}
  lc.input_tensor.layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42f5140]]}
  lc.input_tensor.layer.1.output.LayerNorm.weight_s_brcst_m2_2_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8c1cd80]]}
  lc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x89601e0]]}
  lc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4405da0]]}
  dc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ca91c0], [0, 0x3d0a9e0]]}
  lc.input_tensor.bw_in1_add_330_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83d9a00]]}
  lc.input_tensor.bw_in1_add_324_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38f78e0]]}
  lc.input_tensor.bw_in2_layernorm_319_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83d91c0]]}
  lc.input_tensor.bw_in1_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x3c785e0]]}
  lc.input_tensor.layernorm_319.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38e6440]]}
  lc.input_tensor.layer.1.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x7c3a140]]}
  lc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83d8140]]}
  lc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3a60140]]}
  dc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3be6180], [0, 0x3c479a0]]}
  lc.input_tensor.bw_in1_add_316_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38e6c80]]}
  lc.input_tensor.bw_in1_add_305_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83d8980]]}
  lc.input_tensor.bw_in0_softmax_299_softmax_bw_0.dc.reduce_sum.1.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42d2800]]}
  input_1_multiply_297_tile_bcast_tile_bcast:                                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x888bd00]]}
  lc.input_tensor.bw_in1_add_291_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x449a8e0]]}
  lc.input_tensor.bw_in1_add_285_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42d3040]]}
  lc.input_tensor.bw_in2_layernorm_280_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x449a0a0]]}
  lc.input_tensor.bw_in1_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3e80680]]}
  lc.input_tensor.layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83ea660]]}
  lc.input_tensor.layer.0.output.LayerNorm.weight_s_brcst_m2_2_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8683440]]}
  lc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4499860]]}
  lc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38f8960]]}
  dc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3dbd640], [0, 0x3e1ee60]]}
  lc.input_tensor.bw_in1_add_277_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42d1fc0]]}
  lc.input_tensor.bw_in1_add_271_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4499020]]}
  lc.input_tensor.bw_in2_layernorm_266_layernorm_bw_0.dc.reduce_sum.0.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x431bc80]]}
  lc.input_tensor.bw_in1_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8e38de0]]}
  lc.input_tensor.layernorm_266.dc.reciprocal.7_s_brcst_m1_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x442b860]]}
  lc.input_tensor.layer.0.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x44c03c0]]}
  lc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x431b440]]}
  lc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.3.0:       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9052100]]}
  dc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.6:                       {input: HOST, type: queue, entries: 1, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8d75da0], [3, 0x8dd75c0]]}
  lc.input_tensor.bw_in1_add_263_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x471a8e0]]}
  lc.input_tensor.bw_in1_add_252_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x431ac00]]}
  lc.input_tensor.bw_in0_softmax_246_softmax_bw_0.dc.reduce_sum.1.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x471a0a0]]}
  input_1_multiply_244_tile_bcast_tile_bcast:                                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x441ac00]]}
  lc.input_tensor.bw_in1_add_238_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b7b00]]}
  lc.input_tensor.bw_in1_add_232_brcst_reduce_sum_0.0:                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6d4e0]]}

  # epoch_to_epoch
  e2e_layernorm_266.dc.multiply.9_0:                                           {input: layernorm_266.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc3690c0], [3, 0xc42c0e0]]}
  e2e_layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1_0:            {input: layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360]]}
  e2e_layernorm_280.dc.sqrt.6_0:                                               {input: layernorm_280.dc.sqrt.6, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa03eba0], [4, 0xa044d40]]}
  e2e_buffer_0_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8_0:      {input: buffer_0_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x778d9c0], [5, 0x78509e0]]}
  e2e_layernorm_319.dc.multiply.2_0:                                           {input: layernorm_319.dc.multiply.2, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7df7da0], [0, 0x7ebadc0]]}
  e2e_buffer_0_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8_0:      {input: buffer_0_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x6776a00], [1, 0x6839a20]]}
  e2e_add_332_0:                                                               {input: add_332, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360], [2, 0x7570380]]}
  e2e_add_369_0:                                                               {input: add_369, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc3690c0], [3, 0xc42c0e0]]}
  e2e_layernorm_333.dc.add.10_0:                                               {input: layernorm_333.dc.add.10, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x95949e0], [4, 0x9657a00]]}
  e2e_gelu_378_0:                                                              {input: gelu_378, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x583a780], [1, 0x58fd7a0], [1, 0x59c07c0], [1, 0x5a837e0], [1, 0x5b46800], [1, 0x5c09820], [1, 0x5ccc840], [1, 0x5d8f860]]}
  e2e_layernorm_372.dc.add.10_0:                                               {input: layernorm_372.dc.add.10, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x971aa20], [4, 0x97dda40]]}
  e2e_softmax_405.dc.exp.0_0:                                                  {input: softmax_405.dc.exp.0, type: queue, entries: 2, grid_size: [2, 2], t: 16, mblock: [3, 3], ublock: [2, 2], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa03eba0], [4, 0xa287bc0], [4, 0xa4d0be0], [4, 0xa719c00]]}
  e2e_lc.input_tensor.softmax_405.dc.reduce_sum.1.0_splt_brcst_1_0_0:          {input: lc.input_tensor.softmax_405.dc.reduce_sum.1.0_splt_brcst_1_0, type: queue, entries: 2, grid_size: [1, 1], t: 16, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x778d9c0]]}
  e2e_layernorm_386.dc.add.10_0:                                               {input: layernorm_386.dc.add.10, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x5e52880], [1, 0x5f158a0]]}
  e2e_matmul_428_0:                                                            {input: matmul_428, type: queue, entries: 2, grid_size: [2, 8], t: 1, mblock: [3, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7df7da0], [0, 0x7e595c0], [0, 0x7ebade0], [0, 0x7f1c600], [0, 0x7f7de20], [0, 0x7fdf640], [0, 0x8040e60], [0, 0x80a2680], [0, 0x8103ea0], [0, 0x81656c0], [0, 0x81c6ee0], [0, 0x8228700], [0, 0x8289f20], [0, 0x82eb740], [0, 0x834cf60], [0, 0x83ae780]]}
  e2e_layer.3.intermediate.dense.bias_s_brcst_m2_1_0.lc1_0:                    {input: layer.3.intermediate.dense.bias_s_brcst_m2_1_0.lc1, type: queue, entries: 2, grid_size: [1, 2], t: 1, mblock: [1, 16], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x6776a00], [1, 0x67b7a20]]}
  e2e_layernorm_425.dc.add.10_0:                                               {input: layernorm_425.dc.add.10, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98a0a60], [4, 0x9963a80]]}
  e2e_layernorm_439.dc.multiply.8_0:                                           {input: layernorm_439.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7c71d60], [0, 0x7d34d80]]}
  e2e_layernorm_439.dc.reciprocal.7_0:                                         {input: layernorm_439.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x7781680], [5, 0x7787820]]}
  e2e_gelu_431_0:                                                              {input: gelu_431, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9a26aa0], [4, 0x9ae9ac0], [4, 0x9bacae0], [4, 0x9c6fb00], [4, 0x9d32b20], [4, 0x9df5b40], [4, 0x9eb8b60], [4, 0x9f7bb80]]}
  e2e_add_430_0:                                                               {input: add_430, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x615e900], [1, 0x6221920], [1, 0x62e4940], [1, 0x63a7960], [1, 0x646a980], [1, 0x652d9a0], [1, 0x65f09c0], [1, 0x66b39e0]]}
  e2e_bw_in0_matmul_434_matmul_1_0:                                            {input: bw_in0_matmul_434_matmul_1, type: queue, entries: 2, grid_size: [2, 8], t: 1, mblock: [3, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360], [2, 0x750eb80], [2, 0x75703a0], [2, 0x75d1bc0], [2, 0x76333e0], [2, 0x7694c00], [2, 0x76f6420], [2, 0x7757c40], [2, 0x77b9460], [2, 0x781ac80], [2, 0x787c4a0], [2, 0x78ddcc0], [2, 0x793f4e0], [2, 0x79a0d00], [2, 0x7a02520], [2, 0x7a63d40]]}
  e2e_bw_in1_matmul_428_transpose_0_0:                                         {input: bw_in1_matmul_428_transpose_0, type: queue, entries: 2, grid_size: [1, 2], t: 1, mblock: [16, 3], ublock: [2, 2], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7df7da0], [0, 0x7ebadc0]]}
  e2e_bw_in0_gelu_431_multiply_1_0:                                            {input: bw_in0_gelu_431_multiply_1, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa03eba0], [4, 0xa101bc0], [4, 0xa1c4be0], [4, 0xa287c00], [4, 0xa34ac20], [4, 0xa40dc40], [4, 0xa4d0c60], [4, 0xa593c80]]}
  e2e_bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9_0:                     {input: bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc3690c0], [3, 0xc42c0e0]]}
  e2e_bw_in0_matmul_428_matmul_1_0:                                            {input: bw_in0_matmul_428_matmul_1, type: queue, entries: 2, grid_size: [2, 8], t: 1, mblock: [3, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x778d9c0], [5, 0x77a5fe0], [5, 0x77be600], [5, 0x77d6c20], [5, 0x77ef240], [5, 0x7807860], [5, 0x781fe80], [5, 0x78384a0], [5, 0x7850ac0], [5, 0x78690e0], [5, 0x7881700], [5, 0x7899d20], [5, 0x78b2340], [5, 0x78ca960], [5, 0x78e2f80], [5, 0x78fb5a0]]}
  e2e_layernorm_425.dc.multiply.8_0:                                           {input: layernorm_425.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x7327320], [2, 0x73ea340]]}
  e2e_layernorm_425.dc.reciprocal.7_0:                                         {input: layernorm_425.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x7775340], [5, 0x777b4e0]]}
  e2e_matmul_416_0:                                                            {input: matmul_416, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 1], ublock: [2, 2], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7aebd20], [0, 0x7baed40]]}
  e2e_add_411_0:                                                               {input: add_411, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x5fd88c0], [1, 0x609b8e0]]}
  e2e_softmax_405.dc.multiply.3_0:                                             {input: softmax_405.dc.multiply.3, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 3], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xba45080], [3, 0xbed70a0]]}
  e2e_bw_in0_matmul_416_matmul_1_0:                                            {input: bw_in0_matmul_416_matmul_1, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 3], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa656ca0], [4, 0xaae8cc0]]}
  e2e_bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.lc1_0:                   {input: bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.lc1, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360], [2, 0x750eb80]]}
  e2e_add_397_0:                                                               {input: add_397, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb8bf040], [3, 0xb982060]]}
  e2e_add_391_0:                                                               {input: add_391, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x71a12e0], [2, 0x7264300]]}
  e2e_bw_in0_matmul_409_matmul_1_0:                                            {input: bw_in0_matmul_409_matmul_1, type: queue, entries: 2, grid_size: [2, 2], t: 1, mblock: [3, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc4ef100], [3, 0xc550920], [3, 0xc5b2140], [3, 0xc613960]]}
  e2e_bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9_0:                     {input: bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x6776a00], [1, 0x6839a20]]}
  e2e_layernorm_386.dc.multiply.8_0:                                           {input: layernorm_386.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7965ce0], [0, 0x7a28d00]]}
  e2e_layernorm_386.dc.reciprocal.7_0:                                         {input: layernorm_386.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x7769000], [5, 0x776f1a0]]}
  e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0:                     {input: bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x7913bc0], [5, 0x79d6be0]]}
  e2e_add_377_0:                                                               {input: add_377, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x734dbe0], [0, 0x7410c00], [0, 0x74d3c20], [0, 0x7596c40], [0, 0x7659c60], [0, 0x771cc80], [0, 0x77dfca0], [0, 0x78a2cc0]]}
  e2e_bw_in0_gelu_378_multiply_1_0:                                            {input: bw_in0_gelu_378_multiply_1, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7df7da0], [0, 0x7ebadc0], [0, 0x7f7dde0], [0, 0x8040e00], [0, 0x8103e20], [0, 0x81c6e40], [0, 0x8289e60], [0, 0x834ce80]]}
  e2e_layernorm_372.dc.multiply.8_0:                                           {input: layernorm_372.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb739000], [3, 0xb7fc020]]}
  e2e_layernorm_372.dc.reciprocal.7_0:                                         {input: layernorm_372.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x7194fa0], [2, 0x719b140]]}
  e2e_matmul_363_0:                                                            {input: matmul_363, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 1], ublock: [2, 2], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x940e9a0], [4, 0x94d19c0]]}
  e2e_bw_in0_matmul_367_matmul_1_0:                                            {input: bw_in0_matmul_367_matmul_1, type: queue, entries: 2, grid_size: [2, 2], t: 1, mblock: [3, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360], [2, 0x750eb80], [2, 0x75703a0], [2, 0x75d1bc0]]}
  e2e_add_358_0:                                                               {input: add_358, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x71c7ba0], [0, 0x728abc0]]}
  e2e_softmax_352.dc.multiply.3_0:                                             {input: softmax_352.dc.multiply.3, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 3], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4f16740], [1, 0x53a8760]]}
  e2e_add_344_0:                                                               {input: add_344, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x700ef60], [2, 0x70d1f80]]}
  e2e_add_338_0:                                                               {input: add_338, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x745cf80], [5, 0x751ffa0]]}
  e2e_bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9_0:                     {input: bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x6776a00], [1, 0x6839a20]]}
  e2e_bw_in0_layernorm_333_combine_add_0_0:                                    {input: bw_in0_layernorm_333_combine_add_0, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7df7da0], [0, 0x7ebadc0]]}
  e2e_layernorm_333.dc.multiply.8_0:                                           {input: layernorm_333.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x75e2fc0], [5, 0x76a5fe0]]}
  e2e_layernorm_333.dc.reciprocal.7_0:                                         {input: layernorm_333.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb72ccc0], [3, 0xb732e60]]}
  e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.lc1_0:               {input: bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.lc1, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc3690c0], [3, 0xc36f260]]}
  e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1_0:               {input: bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa03eba0], [4, 0xa044d40]]}
  e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0_0:                     {input: bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x778d9c0], [5, 0x78509e0]]}
  e2e_layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0:                      {input: layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.lc1, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x68fca40], [1, 0x6902be0]]}
  e2e_gelu_325_0:                                                              {input: gelu_325, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x6bafaa0], [0, 0x6c72ac0], [0, 0x6d35ae0], [0, 0x6df8b00], [0, 0x6ebbb20], [0, 0x6f7eb40], [0, 0x7041b60], [0, 0x7104b80]]}
  e2e_add_324_0:                                                               {input: add_324, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6e44e80], [5, 0x6f07ea0], [5, 0x6fcaec0], [5, 0x708dee0], [5, 0x7150f00], [5, 0x7213f20], [5, 0x72d6f40], [5, 0x7399f60]]}
  e2e_bw_in0_gelu_325_multiply_1_0:                                            {input: bw_in0_gelu_325_multiply_1, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc375400], [3, 0xc438420], [3, 0xc4fb440], [3, 0xc5be460], [3, 0xc681480], [3, 0xc7444a0], [3, 0xc8074c0], [3, 0xc8ca4e0]]}
  e2e_layernorm_319.dc.add.10_0:                                               {input: layernorm_319.dc.add.10, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb5a6c80], [3, 0xb669ca0]]}
  e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9_0:                     {input: bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x76333e0], [2, 0x76f6400]]}
  e2e_layernorm_319.dc.multiply.8_0:                                           {input: layernorm_319.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x6e88f20], [2, 0x6f4bf40]]}
  e2e_layernorm_319.dc.reciprocal.7_0:                                         {input: layernorm_319.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4f0a400], [1, 0x4f105a0]]}
  e2e_matmul_310_0:                                                            {input: matmul_310, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 1], ublock: [2, 2], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb29ac00], [3, 0xb35dc20]]}
  e2e_bw_in0_matmul_314_matmul_1_0:                                            {input: bw_in0_matmul_314_matmul_1, type: queue, entries: 2, grid_size: [2, 2], t: 1, mblock: [3, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x778d9c0], [5, 0x77ef1e0], [5, 0x7850a00], [5, 0x78b2220]]}
  e2e_add_305_0:                                                               {input: add_305, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xb420c40], [3, 0xb4e3c60]]}
  e2e_softmax_299.dc.multiply.3_0:                                             {input: softmax_299.dc.multiply.3, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 3], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x6564ee0], [2, 0x69f6f00]]}
  e2e_layernorm_280.dc.add.10_0:                                               {input: layernorm_280.dc.add.10, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x6cbee40], [5, 0x6d81e60]]}
  e2e_add_291_0:                                                               {input: add_291, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4d843c0], [1, 0x4e473e0]]}
  e2e_add_285_0:                                                               {input: add_285, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x6a29a60], [0, 0x6aeca80]]}
  e2e_bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9_0:                     {input: bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa04aee0], [4, 0xa10df00]]}
  e2e_bw_in0_layernorm_280_combine_add_0_0:                                    {input: bw_in0_layernorm_280_combine_add_0, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7df7da0], [0, 0x7ebadc0]]}
  e2e_layernorm_280.dc.multiply.8_0:                                           {input: layernorm_280.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9288960], [4, 0x934b980]]}
  e2e_layernorm_280.dc.reciprocal.7_0:                                         {input: layernorm_280.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x927c620], [4, 0x92827c0]]}
  e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.lc1_0:               {input: bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.lc1, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa03eba0], [4, 0xa044d40]]}
  e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1_0:               {input: bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc3690c0], [3, 0xc36f260]]}
  e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0_0:                     {input: bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360], [2, 0x7570380]]}
  e2e_layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0:                      {input: layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.lc1, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x6776a00], [1, 0x677cba0]]}
  e2e_gelu_272_0:                                                              {input: gelu_272, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x476c2c0], [1, 0x482f2e0], [1, 0x48f2300], [1, 0x49b5320], [1, 0x4a78340], [1, 0x4b3b360], [1, 0x4bfe380], [1, 0x4cc13a0]]}
  e2e_add_271_0:                                                               {input: add_271, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x6411960], [0, 0x64d4980], [0, 0x65979a0], [0, 0x665a9c0], [0, 0x671d9e0], [0, 0x67e0a00], [0, 0x68a3a20], [0, 0x6966a40]]}
  e2e_bw_in0_gelu_272_multiply_1_0:                                            {input: bw_in0_gelu_272_multiply_1, type: queue, entries: 2, grid_size: [2, 4], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x7913a40], [5, 0x79d6a60], [5, 0x7a99a80], [5, 0x7b5caa0], [5, 0x7c1fac0], [5, 0x7ce2ae0], [5, 0x7da5b00], [5, 0x7e68b20]]}
  e2e_layernorm_266.dc.add.10_0:                                               {input: layernorm_266.dc.add.10, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x63deea0], [2, 0x64a1ec0]]}
  e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9_0:                     {input: bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7f7dde0], [0, 0x8040e00]]}
  e2e_layernorm_266.dc.multiply.8_0:                                           {input: layernorm_266.dc.multiply.8, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38da100], [0, 0x399d120]]}
  e2e_layernorm_266.dc.reciprocal.7_0:                                         {input: layernorm_266.dc.reciprocal.7, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 1], ublock: [2, 1], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38da100], [1, 0x38e02a0]]}
  e2e_matmul_257_0:                                                            {input: matmul_257, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 1], ublock: [2, 2], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x38da100], [2, 0x399d120]]}
  e2e_bw_in0_matmul_261_matmul_1_0:                                            {input: bw_in0_matmul_261_matmul_1, type: queue, entries: 2, grid_size: [2, 2], t: 1, mblock: [3, 4], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x6782d40], [1, 0x67e4560], [1, 0x6845d80], [1, 0x68a75a0]]}
  e2e_add_252_0:                                                               {input: add_252, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x7ab4100], [3, 0x7b77120]]}
  e2e_softmax_246.dc.multiply.3_0:                                             {input: softmax_246.dc.multiply.3, type: queue, entries: 2, grid_size: [2, 1], t: 16, mblock: [3, 3], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x7ab4100], [4, 0x7f46120]]}
  e2e_add_238_0:                                                               {input: add_238, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x38da100], [5, 0x399d120]]}
  e2e_add_232_0:                                                               {input: add_232, type: queue, entries: 2, grid_size: [2, 1], t: 1, mblock: [3, 8], ublock: [2, 4], ublock_order: c, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a60140], [0, 0x3b23160]]}
  e2e_input_opt_layer.0.output.dense.weight_0.lr_splt_brcst_3_0_0:             {input: input_opt_layer.0.output.dense.weight_0.lr_splt_brcst_3_0, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360], [2, 0x74b5580]]}
  e2e_opt_in0_layer.1.attention.self.query.weight_multiply_1_0:                {input: opt_in0_layer.1.attention.self.query.weight_multiply_1, type: queue, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc3690c0], [3, 0xc3aa0e0], [3, 0xc3eb100], [3, 0xc42c120], [3, 0xc46d140], [3, 0xc4ae160], [3, 0xc4ef180], [3, 0xc5301a0]]}
  e2e_input_opt_layer.1.intermediate.dense.weight_0.lr_splt_brcst_3_0_0:       {input: input_opt_layer.1.intermediate.dense.weight_0.lr_splt_brcst_3_0, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 16], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa03eba0], [4, 0xa05f3c0]]}
  e2e_input_opt_layer.1.output.dense.weight_0.lr_splt_brcst_3_0_0:             {input: input_opt_layer.1.output.dense.weight_0.lr_splt_brcst_3_0, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x778d9c0], [5, 0x7795be0]]}
  e2e_opt_in0_layer.2.attention.self.query.weight_multiply_1_0:                {input: opt_in0_layer.2.attention.self.query.weight_multiply_1, type: queue, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x7df7da0], [0, 0x7e38dc0], [0, 0x7e79de0], [0, 0x7ebae00], [0, 0x7efbe20], [0, 0x7f3ce40], [0, 0x7f7de60], [0, 0x7fbee80]]}
  e2e_input_opt_layer.2.intermediate.dense.weight_0.lr_splt_brcst_3_0_0:       {input: input_opt_layer.2.intermediate.dense.weight_0.lr_splt_brcst_3_0, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 16], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x6776a00], [1, 0x6797220]]}
  e2e_input_opt_layer.2.output.dense.weight_0.lr_splt_brcst_3_0_0:             {input: input_opt_layer.2.output.dense.weight_0.lr_splt_brcst_3_0, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x74ad360], [2, 0x74b5580]]}
  e2e_opt_in0_layer.3.attention.self.query.weight_multiply_1_0:                {input: opt_in0_layer.3.attention.self.query.weight_multiply_1, type: queue, entries: 1, grid_size: [1, 8], t: 1, mblock: [16, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xc3690c0], [3, 0xc3aa0e0], [3, 0xc3eb100], [3, 0xc42c120], [3, 0xc46d140], [3, 0xc4ae160], [3, 0xc4ef180], [3, 0xc5301a0]]}
  e2e_input_opt_layer.3.intermediate.dense.weight_0.lr_splt_brcst_3_0_0:       {input: input_opt_layer.3.intermediate.dense.weight_0.lr_splt_brcst_3_0, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 16], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0xa03eba0], [4, 0xa05f3c0]]}
  e2e_input_opt_layer.3.output.dense.weight_0.lr_splt_brcst_3_0_0:             {input: input_opt_layer.3.output.dense.weight_0.lr_splt_brcst_3_0, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 4], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x778d9c0], [5, 0x7795be0]]}

  # optimizer_parameter
  input_opt_layer.0.attention.self.query.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472ce00]]}
  input_opt_layer.0.attention.self.query.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x442d960]]}
  input_opt_layer.0.attention.self.key.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x44c24c0]]}
  input_opt_layer.0.attention.self.key.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4b3cf00]]}
  input_opt_layer.0.attention.self.value.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9063de0]]}
  input_opt_layer.0.attention.self.value.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8e3a6a0]]}
  input_opt_layer.0.attention.output.dense.weight_0.lr:                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472c5c0]]}
  input_opt_layer.0.attention.output.dense.bias_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x442d120]]}
  input_opt_layer.0.attention.output.LayerNorm.weight_0.lr:                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x44c1c80]]}
  input_opt_layer.0.attention.output.LayerNorm.bias_0.lr:                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x44c0c00]]}
  input_opt_layer.0.intermediate.dense.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x90635a0]]}
  input_opt_layer.0.intermediate.dense.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8e39e60]]}
  input_opt_layer.0.output.dense.weight_0.lr:                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472bd80]]}
  input_opt_layer.0.output.dense.bias_0.lr:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x442c8e0]]}
  input_opt_layer.0.output.LayerNorm.weight_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x44c1440]]}
  input_opt_layer.0.output.LayerNorm.bias_0.lr:                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x431c4c0]]}
  input_opt_layer.1.attention.self.query.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9062d60]]}
  input_opt_layer.1.attention.self.query.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8e39620]]}
  input_opt_layer.1.attention.self.key.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x472b540]]}
  input_opt_layer.1.attention.self.key.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x442c0a0]]}
  input_opt_layer.1.attention.self.value.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6c460]]}
  input_opt_layer.1.attention.self.value.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6b3e0]]}
  input_opt_layer.1.attention.output.dense.weight_0.lr:                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4707b80]]}
  input_opt_layer.1.attention.output.dense.bias_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x44182c0]]}
  input_opt_layer.1.attention.output.LayerNorm.weight_0.lr:                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b51c0]]}
  input_opt_layer.1.attention.output.LayerNorm.bias_0.lr:                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4307ea0]]}
  input_opt_layer.1.intermediate.dense.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e37320]]}
  input_opt_layer.1.intermediate.dense.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6aba0]]}
  input_opt_layer.1.output.dense.weight_0.lr:                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4707340]]}
  input_opt_layer.1.output.dense.bias_0.lr:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4417a80]]}
  input_opt_layer.1.output.LayerNorm.weight_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b4980]]}
  input_opt_layer.1.output.LayerNorm.bias_0.lr:                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b3900]]}
  input_opt_layer.2.attention.self.query.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e36ae0]]}
  input_opt_layer.2.attention.self.query.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6a360]]}
  input_opt_layer.2.attention.self.key.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4706b00]]}
  input_opt_layer.2.attention.self.key.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4417240]]}
  input_opt_layer.2.attention.self.value.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b4140]]}
  input_opt_layer.2.attention.self.value.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4306e20]]}
  input_opt_layer.2.attention.output.dense.weight_0.lr:                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e362a0]]}
  input_opt_layer.2.attention.output.dense.bias_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b69b20]]}
  input_opt_layer.2.attention.output.LayerNorm.weight_0.lr:                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x47062c0]]}
  input_opt_layer.2.attention.output.LayerNorm.bias_0.lr:                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4416a00]]}
  input_opt_layer.2.intermediate.dense.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4307660]]}
  input_opt_layer.2.intermediate.dense.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x441a3c0]]}
  input_opt_layer.2.output.dense.weight_0.lr:                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b72c0]]}
  input_opt_layer.2.output.dense.bias_0.lr:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4309fa0]]}
  input_opt_layer.2.output.LayerNorm.weight_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e39420]]}
  input_opt_layer.2.output.LayerNorm.bias_0.lr:                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6cca0]]}
  input_opt_layer.3.attention.self.query.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4709440]]}
  input_opt_layer.3.attention.self.query.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4419b80]]}
  input_opt_layer.3.attention.self.key.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b6a80]]}
  input_opt_layer.3.attention.self.key.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4309760]]}
  input_opt_layer.3.attention.self.value.weight_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e38be0]]}
  input_opt_layer.3.attention.self.value.bias_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e37b60]]}
  input_opt_layer.3.attention.output.dense.weight_0.lr:                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4708c00]]}
  input_opt_layer.3.attention.output.dense.bias_0.lr:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4419340]]}
  input_opt_layer.3.attention.output.LayerNorm.weight_0.lr:                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b6240]]}
  input_opt_layer.3.attention.output.LayerNorm.bias_0.lr:                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4308f20]]}
  input_opt_layer.3.intermediate.dense.weight_0.lr:                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e383a0]]}
  input_opt_layer.3.intermediate.dense.bias_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6bc20]]}
  input_opt_layer.3.output.dense.weight_0.lr:                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x47083c0]]}
  input_opt_layer.3.output.dense.bias_0.lr:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4418b00]]}
  input_opt_layer.3.output.LayerNorm.weight_0.lr:                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b5a00]]}
  input_opt_layer.3.output.LayerNorm.bias_0.lr:                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x43086e0]]}

  # loss
  loss_bert_encoder.output_layernorm_439:                                      {input: HOST, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [12, 32], ublock: [1, 1], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5cab240]]}

  # grad_accumulator
  grad_acc_layer.3.output.LayerNorm.bias:                                      {input: bw_in2_layernorm_439_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9216b60]]}
  grad_acc_layer.3.output.LayerNorm.weight:                                    {input: bw_in1_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x5786e00]]}
  grad_acc_layer.3.output.dense.bias:                                          {input: bw_in1_add_436_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46c06a0]]}
  grad_acc_layer.3.output.dense.weight:                                        {input: bw_in1_matmul_434_matmul_1, type: ram, entries: 1, grid_size: [2, 8], t: 1, mblock: [32, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4f56640], [0, 0x4fd8660], [0, 0x505a680], [0, 0x50dc6a0], [0, 0x515e6c0], [0, 0x51e06e0], [0, 0x5262700], [0, 0x52e4720], [0, 0x5366740], [0, 0x53e8760], [0, 0x546a780], [0, 0x54ec7a0], [0, 0x556e7c0], [0, 0x55f07e0], [0, 0x5672800], [0, 0x56f4820]]}
  grad_acc_layer.3.intermediate.dense.bias:                                    {input: bw_in1_add_430_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x91d5300]]}
  grad_acc_layer.3.intermediate.dense.weight:                                  {input: bw_in1_matmul_428_matmul_1, type: ram, entries: 1, grid_size: [8, 2], t: 1, mblock: [2, 16], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x9d209a0], [3, 0x9da29c0], [3, 0x9e249e0], [3, 0x9ea6a00], [3, 0x9f28a20], [3, 0x9faaa40], [3, 0xa02ca60], [3, 0xa0aea80], [3, 0xa130aa0], [3, 0xa1b2ac0], [3, 0xa234ae0], [3, 0xa2b6b00], [3, 0xa338b20], [3, 0xa3bab40], [3, 0xa43cb60], [3, 0xa4beb80]]}
  grad_acc_layer.3.attention.output.LayerNorm.bias:                            {input: bw_in2_layernorm_425_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46b0280]]}
  grad_acc_layer.3.attention.output.LayerNorm.weight:                          {input: bw_in1_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9238c60]]}
  grad_acc_layer.3.attention.output.dense.bias:                                {input: bw_in1_add_422_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa81d100]]}
  grad_acc_layer.3.attention.output.dense.weight:                              {input: bw_in1_matmul_420_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x57a86c0], [2, 0x582a6e0], [2, 0x58ac700], [2, 0x592e720]]}
  grad_acc_layer.3.attention.self.value.bias:                                  {input: bw_in1_add_411_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x57778c0]]}
  grad_acc_layer.3.attention.self.value.weight:                                {input: bw_in1_matmul_409_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x5fb82e0], [5, 0x603a300], [5, 0x60bc320], [5, 0x613e340]]}
  grad_acc_layer.3.attention.self.key.bias:                                    {input: bw_in1_add_397_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x46f1b40]]}
  grad_acc_layer.3.attention.self.key.weight:                                  {input: bw_in1_matmul_395_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x5787ce0], [0, 0x5809d00], [0, 0x588bd20], [0, 0x590dd40]]}
  grad_acc_layer.3.attention.self.query.bias:                                  {input: bw_in1_add_391_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x92277c0]]}
  grad_acc_layer.3.attention.self.query.weight:                                {input: bw_in1_matmul_389_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0xa614840], [3, 0xa696860], [3, 0xa718880], [3, 0xa79a8a0]]}
  grad_acc_layer.2.output.LayerNorm.bias:                                      {input: bw_in2_layernorm_386_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x5797a60]]}
  grad_acc_layer.2.output.LayerNorm.weight:                                    {input: bw_in1_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x408a800]]}
  grad_acc_layer.2.output.dense.bias:                                          {input: bw_in1_add_383_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42e44e0]]}
  grad_acc_layer.2.output.dense.weight:                                        {input: bw_in1_matmul_381_matmul_1, type: ram, entries: 1, grid_size: [2, 8], t: 1, mblock: [32, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83fc340], [4, 0x847e360], [4, 0x8500380], [4, 0x85823a0], [4, 0x86043c0], [4, 0x86863e0], [4, 0x8708400], [4, 0x878a420], [4, 0x880c440], [4, 0x888e460], [4, 0x8910480], [4, 0x89924a0], [4, 0x8a144c0], [4, 0x8a964e0], [4, 0x8b18500], [4, 0x8b9a520]]}
  grad_acc_layer.2.intermediate.dense.bias:                                    {input: bw_in1_add_377_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x449b960]]}
  grad_acc_layer.2.intermediate.dense.weight:                                  {input: bw_in1_matmul_375_matmul_1, type: ram, entries: 1, grid_size: [8, 2], t: 1, mblock: [2, 16], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x391a220], [1, 0x399c240], [1, 0x3a1e260], [1, 0x3aa0280], [1, 0x3b222a0], [1, 0x3ba42c0], [1, 0x3c262e0], [1, 0x3ca8300], [1, 0x3d2a320], [1, 0x3dac340], [1, 0x3e2e360], [1, 0x3eb0380], [1, 0x3f323a0], [1, 0x3fb43c0], [1, 0x40363e0], [1, 0x40b8400]]}
  grad_acc_layer.2.attention.output.LayerNorm.bias:                            {input: bw_in2_layernorm_372_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42d40c0]]}
  grad_acc_layer.2.attention.output.LayerNorm.weight:                          {input: bw_in1_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x888c540]]}
  grad_acc_layer.2.attention.output.dense.bias:                                {input: bw_in1_add_369_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e25e80]]}
  grad_acc_layer.2.attention.output.dense.weight:                              {input: bw_in1_matmul_367_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8961aa0], [3, 0x89e3ac0], [3, 0x8a65ae0], [3, 0x8ae7b00]]}
  grad_acc_layer.2.attention.self.value.bias:                                  {input: bw_in1_add_358_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x44065e0]]}
  grad_acc_layer.2.attention.self.value.weight:                                {input: bw_in1_matmul_356_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40ab880], [0, 0x412d8a0], [0, 0x41af8c0], [0, 0x42318e0]]}
  grad_acc_layer.2.attention.self.key.bias:                                    {input: bw_in1_add_344_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x46f5660]]}
  grad_acc_layer.2.attention.self.key.weight:                                  {input: bw_in1_matmul_342_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x44dd1c0], [2, 0x455f1e0], [2, 0x45e1200], [2, 0x4663220]]}
  grad_acc_layer.2.attention.self.query.bias:                                  {input: bw_in1_add_338_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42f5980]]}
  grad_acc_layer.2.attention.self.query.weight:                                {input: bw_in1_matmul_336_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8c1d5c0], [4, 0x8c9f5e0], [4, 0x8d21600], [4, 0x8da3620]]}
  grad_acc_layer.1.output.LayerNorm.bias:                                      {input: bw_in2_layernorm_333_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x46e5240]]}
  grad_acc_layer.1.output.LayerNorm.weight:                                    {input: bw_in1_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x409ac20]]}
  grad_acc_layer.1.output.dense.bias:                                          {input: bw_in1_add_330_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x7e52e20]]}
  grad_acc_layer.1.output.dense.weight:                                        {input: bw_in1_matmul_328_matmul_1, type: ram, entries: 1, grid_size: [2, 8], t: 1, mblock: [32, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x3c78e20], [2, 0x3cfae40], [2, 0x3d7ce60], [2, 0x3dfee80], [2, 0x3e80ea0], [2, 0x3f02ec0], [2, 0x3f84ee0], [2, 0x4006f00], [2, 0x4088f20], [2, 0x410af40], [2, 0x418cf60], [2, 0x420ef80], [2, 0x4290fa0], [2, 0x4312fc0], [2, 0x4394fe0], [2, 0x4417000]]}
  grad_acc_layer.1.intermediate.dense.bias:                                    {input: bw_in1_add_324_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3d6c200]]}
  grad_acc_layer.1.intermediate.dense.weight:                                  {input: bw_in1_matmul_322_matmul_1, type: ram, entries: 1, grid_size: [8, 2], t: 1, mblock: [2, 16], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3a70da0], [5, 0x3af2dc0], [5, 0x3b74de0], [5, 0x3bf6e00], [5, 0x3c78e20], [5, 0x3cfae40], [5, 0x3d7ce60], [5, 0x3dfee80], [5, 0x3e80ea0], [5, 0x3f02ec0], [5, 0x3f84ee0], [5, 0x4006f00], [5, 0x4088f20], [5, 0x410af40], [5, 0x418cf60], [5, 0x420ef80]]}
  grad_acc_layer.1.attention.output.LayerNorm.bias:                            {input: bw_in2_layernorm_319_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x7e42a00]]}
  grad_acc_layer.1.attention.output.LayerNorm.weight:                          {input: bw_in1_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38e74c0]]}
  grad_acc_layer.1.attention.output.dense.bias:                                {input: bw_in1_add_316_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x3c681c0]]}
  grad_acc_layer.1.attention.output.dense.weight:                              {input: bw_in1_matmul_314_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x7c3a980], [3, 0x7cbc9a0], [3, 0x7d3e9c0], [3, 0x7dc09e0]]}
  grad_acc_layer.1.attention.self.value.bias:                                  {input: bw_in1_add_305_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3a60980]]}
  grad_acc_layer.1.attention.self.value.weight:                                {input: bw_in1_matmul_303_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x3a60140], [2, 0x3ae2160], [2, 0x3b64180], [2, 0x3be61a0]]}
  grad_acc_layer.1.attention.self.key.bias:                                    {input: bw_in1_add_291_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x39095c0]]}
  grad_acc_layer.1.attention.self.key.weight:                                  {input: bw_in1_matmul_289_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3e80ec0], [0, 0x3f02ee0], [0, 0x3f84f00], [0, 0x4006f20]]}
  grad_acc_layer.1.attention.self.query.bias:                                  {input: bw_in1_add_285_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83eaea0]]}
  grad_acc_layer.1.attention.self.query.weight:                                {input: bw_in1_matmul_283_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8683c80], [3, 0x8705ca0], [3, 0x8787cc0], [3, 0x8809ce0]]}
  grad_acc_layer.0.output.LayerNorm.bias:                                      {input: bw_in2_layernorm_280_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x38f91a0]]}
  grad_acc_layer.0.output.LayerNorm.weight:                                    {input: bw_in1_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3dad220]]}
  grad_acc_layer.0.output.dense.bias:                                          {input: bw_in1_add_277_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x83da240]]}
  grad_acc_layer.0.output.dense.weight:                                        {input: bw_in1_matmul_275_matmul_1, type: ram, entries: 1, grid_size: [2, 8], t: 1, mblock: [32, 1], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x7e63240], [3, 0x7ee5260], [3, 0x7f67280], [3, 0x7fe92a0], [3, 0x806b2c0], [3, 0x80ed2e0], [3, 0x816f300], [3, 0x81f1320], [3, 0x8273340], [3, 0x82f5360], [3, 0x8377380], [3, 0x83f93a0], [3, 0x847b3c0], [3, 0x84fd3e0], [3, 0x857f400], [3, 0x8601420]]}
  grad_acc_layer.0.intermediate.dense.bias:                                    {input: bw_in1_add_271_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 32], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4290fa0]]}
  grad_acc_layer.0.intermediate.dense.weight:                                  {input: bw_in1_matmul_269_matmul_1, type: ram, entries: 1, grid_size: [8, 2], t: 1, mblock: [2, 16], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x431cd00], [5, 0x439ed20], [5, 0x4420d40], [5, 0x44a2d60], [5, 0x4524d80], [5, 0x45a6da0], [5, 0x4628dc0], [5, 0x46aade0], [5, 0x472ce00], [5, 0x47aee20], [5, 0x4830e40], [5, 0x48b2e60], [5, 0x4934e80], [5, 0x49b6ea0], [5, 0x4a38ec0], [5, 0x4abaee0]]}
  grad_acc_layer.0.attention.output.LayerNorm.bias:                            {input: bw_in2_layernorm_266_layernorm_bw_0.dc.reduce_sum.0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9052940]]}
  grad_acc_layer.0.attention.output.LayerNorm.weight:                          {input: bw_in1_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x471b120]]}
  grad_acc_layer.0.attention.output.dense.bias:                                {input: bw_in1_add_263_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4709c80]]}
  grad_acc_layer.0.attention.output.dense.weight:                              {input: bw_in1_matmul_261_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x42b8340], [0, 0x433a360], [0, 0x43bc380], [0, 0x443e3a0]]}
  grad_acc_layer.0.attention.self.value.bias:                                  {input: bw_in1_add_252_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x9041ce0]]}
  grad_acc_layer.0.attention.self.value.weight:                                {input: bw_in1_matmul_250_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8b6dd20], [3, 0x8befd40], [3, 0x8c71d60], [3, 0x8cf3d80]]}
  grad_acc_layer.0.attention.self.key.bias:                                    {input: bw_in1_add_238_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x430a7e0]]}
  grad_acc_layer.0.attention.self.key.weight:                                  {input: bw_in1_matmul_236_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x8e39c60], [4, 0x8ebbc80], [4, 0x8f3dca0], [4, 0x8fbfcc0]]}
  grad_acc_layer.0.attention.self.query.bias:                                  {input: bw_in1_add_232_brcst_reduce_sum_0.lc1, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x441b440]]}
  grad_acc_layer.0.attention.self.query.weight:                                {input: bw_in1_matmul_230_matmul_1, type: ram, entries: 1, grid_size: [1, 4], t: 1, mblock: [16, 2], ublock: [2, 4], ublock_order: r, df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x8e3aee0], [3, 0x8ebcf00], [3, 0x8f3ef20], [3, 0x8fc0f40]]}

graphs:
  fwd_0:
    target_device: 0
    input_count: 2
    matmul_230: {type: matmul, grid_loc: [0, 0], grid_size: [2, 2], inputs: [hidden_states, layer.0.attention.self.query.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.0.attention.self.query.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.attention.self.query.bias_s_brcst_m2_1_0.0, layer.0.attention.self.query.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_232: {type: add, grid_loc: [0, 7], grid_size: [2, 1], inputs: [matmul_230, layer.0.attention.self.query.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_236: {type: matmul, grid_loc: [0, 2], grid_size: [2, 2], inputs: [hidden_states, layer.0.attention.self.key.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.0.attention.self.key.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.attention.self.key.bias_s_brcst_m2_1_0.0, layer.0.attention.self.key.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_238: {type: add, grid_loc: [2, 0], grid_size: [2, 1], inputs: [matmul_236, layer.0.attention.self.key.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_242: {type: matmul, grid_loc: [2, 1], grid_size: [2, 1], inputs: [add_232, add_238],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    input_1_multiply_244_fork_clone1647_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [2, 2], grid_size: [1, 1], inputs: [input_1_multiply_244_fork_clone1647_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_244_fork_clone1647_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [2, 3], grid_size: [1, 1], inputs: [input_1_multiply_244_fork_clone1647_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    multiply_244: {type: multiply, grid_loc: [2, 4], grid_size: [2, 1], inputs: [matmul_242, input_1_multiply_244_fork_clone1647_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_245: {type: add, grid_loc: [2, 5], grid_size: [2, 1], inputs: [multiply_244, attention_mask],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 16}]}
    softmax_246.dc.exp.0: {type: exp, grid_loc: [2, 6], grid_size: [2, 2], inputs: [add_245],
         t: 16, mblock: [3, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    lc.input_tensor.softmax_246.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [3, 2], grid_size: [1, 1], inputs: [lc.input_tensor.softmax_246.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    softmax_246.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [3, 3], grid_size: [2, 1], inputs: [softmax_246.dc.exp.0, lc.input_tensor.softmax_246.dc.reduce_sum.1.0_splt_brcst_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}
    softmax_246.dc.reciprocal.2: {type: reciprocal, grid_loc: [4, 0], grid_size: [2, 1], inputs: [softmax_246.dc.reduce_sum.1.lc1],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    softmax_246.dc.multiply.3: {type: multiply, grid_loc: [4, 1], grid_size: [2, 1], inputs: [softmax_246.dc.exp.0, softmax_246.dc.reciprocal.2],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [232, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    matmul_250: {type: matmul, grid_loc: [0, 4], grid_size: [2, 2], inputs: [hidden_states, layer.0.attention.self.value.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.0.attention.self.value.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [4, 2], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.attention.self.value.bias_s_brcst_m2_1_0.0, layer.0.attention.self.value.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_252: {type: add, grid_loc: [4, 4], grid_size: [2, 1], inputs: [matmul_250, layer.0.attention.self.value.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_257: {type: matmul, grid_loc: [4, 5], grid_size: [2, 1], inputs: [softmax_246.dc.multiply.3, add_252],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    matmul_261: {type: matmul, grid_loc: [4, 6], grid_size: [2, 2], inputs: [matmul_257, layer.0.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 16],
         attributes: {m_k: 32, u_kt: 1}}
    layer.0.attention.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.attention.output.dense.bias_s_brcst_m2_1_0.0, layer.0.attention.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_263: {type: add, grid_loc: [5, 3], grid_size: [2, 1], inputs: [matmul_261, layer.0.attention.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_265: {type: add, grid_loc: [6, 0], grid_size: [2, 1], inputs: [add_263, hidden_states],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_266.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [6, 1], grid_size: [2, 1], inputs: [add_265, lc.input_tensor.layernorm_266.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_266.dc.subtract.1: {type: subtract, grid_loc: [6, 2], grid_size: [2, 1], inputs: [add_265, layernorm_266.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_266.dc.multiply.2: {type: multiply, grid_loc: [6, 7], grid_size: [2, 1], inputs: [layernorm_266.dc.subtract.1, layernorm_266.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_266.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [7, 3], grid_size: [2, 1], inputs: [layernorm_266.dc.multiply.2, lc.input_tensor.layernorm_266.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_266.dc.add.5: {type: add, grid_loc: [8, 0], grid_size: [2, 1], inputs: [layernorm_266.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_266.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_266.dc.sqrt.6: {type: sqrt, grid_loc: [8, 1], grid_size: [2, 1], inputs: [layernorm_266.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_266.dc.reciprocal.7: {type: reciprocal, grid_loc: [8, 2], grid_size: [2, 1], inputs: [layernorm_266.dc.sqrt.6],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_266.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [8, 4], grid_size: [2, 1], inputs: [layernorm_266.dc.reciprocal.7, lc.input_tensor.layernorm_266.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    buffer_0_layernorm_266.dc.subtract.1_buffer_1_layernorm_266.dc.subtract.1_layernorm_266.dc.multiply.8: {type: nop, grid_loc: [6, 4], grid_size: [2, 1], inputs: [layernorm_266.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_266.dc.subtract.1_layernorm_266.dc.multiply.8: {type: nop, grid_loc: [6, 5], grid_size: [2, 1], inputs: [buffer_0_layernorm_266.dc.subtract.1_buffer_1_layernorm_266.dc.subtract.1_layernorm_266.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_266.dc.subtract.1_layernorm_266.dc.multiply.8: {type: nop, grid_loc: [6, 6], grid_size: [2, 1], inputs: [buffer_1_layernorm_266.dc.subtract.1_layernorm_266.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_266.dc.multiply.8: {type: multiply, grid_loc: [8, 5], grid_size: [2, 1], inputs: [buffer_0_layernorm_266.dc.subtract.1_layernorm_266.dc.multiply.8, layernorm_266.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.0.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [8, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.0.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_266.dc.multiply.9: {type: multiply, grid_loc: [8, 7], grid_size: [2, 1], inputs: [layernorm_266.dc.multiply.8, layer.0.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [9, 3], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.0.attention.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}

  fwd_1:
    target_device: 0
    input_count: 2
    layernorm_266.dc.add.10: {type: add, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_layernorm_266.dc.multiply.9_0, e2e_layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_269: {type: matmul, grid_loc: [2, 0], grid_size: [2, 8], inputs: [layernorm_266.dc.add.10, layer.0.intermediate.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.0.intermediate.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 1], grid_size: [1, 2], inputs: [lc.input_tensor.layer.0.intermediate.dense.bias_s_brcst_m2_1_0.0, layer.0.intermediate.dense.bias],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_271: {type: add, grid_loc: [0, 3], grid_size: [2, 4], inputs: [matmul_269, layer.0.intermediate.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    gelu_272: {type: gelu, grid_loc: [4, 0], grid_size: [2, 4], inputs: [add_271],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    matmul_275: {type: matmul, grid_loc: [6, 0], grid_size: [2, 8], inputs: [gelu_272, layer.0.output.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 16, u_kt: 8}}
    layer.0.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.output.dense.bias_s_brcst_m2_1_0.0, layer.0.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_277: {type: add, grid_loc: [4, 4], grid_size: [2, 1], inputs: [matmul_275, layer.0.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    buffer_1_layernorm_266.dc.add.10_add_279: {type: nop, grid_loc: [4, 5], grid_size: [2, 1], inputs: [layernorm_266.dc.add.10],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [120], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_266.dc.add.10_add_279: {type: nop, grid_loc: [4, 6], grid_size: [2, 1], inputs: [buffer_1_layernorm_266.dc.add.10_add_279],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [72], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_279: {type: add, grid_loc: [4, 7], grid_size: [2, 1], inputs: [add_277, buffer_0_layernorm_266.dc.add.10_add_279],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_280.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [8, 0], grid_size: [2, 1], inputs: [add_279, lc.input_tensor.layernorm_280.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_280.dc.subtract.1: {type: subtract, grid_loc: [8, 1], grid_size: [2, 1], inputs: [add_279, layernorm_280.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_280.dc.multiply.2: {type: multiply, grid_loc: [8, 4], grid_size: [2, 1], inputs: [layernorm_280.dc.subtract.1, layernorm_280.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_280.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [8, 5], grid_size: [2, 1], inputs: [layernorm_280.dc.multiply.2, lc.input_tensor.layernorm_280.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_280.dc.add.5: {type: add, grid_loc: [8, 6], grid_size: [2, 1], inputs: [layernorm_280.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_280.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_280.dc.sqrt.6: {type: sqrt, grid_loc: [8, 7], grid_size: [2, 1], inputs: [layernorm_280.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8: {type: nop, grid_loc: [8, 2], grid_size: [2, 1], inputs: [layernorm_280.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8: {type: nop, grid_loc: [8, 3], grid_size: [2, 1], inputs: [buffer_1_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_2:
    target_device: 0
    input_count: 2
    layernorm_280.dc.reciprocal.7: {type: reciprocal, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_layernorm_280.dc.sqrt.6_0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_280.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [0, 1], grid_size: [2, 1], inputs: [layernorm_280.dc.reciprocal.7, lc.input_tensor.layernorm_280.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_280.dc.multiply.8: {type: multiply, grid_loc: [0, 2], grid_size: [2, 1], inputs: [e2e_buffer_0_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8_0, layernorm_280.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.0.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 3], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.0.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_280.dc.multiply.9: {type: multiply, grid_loc: [0, 4], grid_size: [2, 1], inputs: [layernorm_280.dc.multiply.8, layer.0.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.0.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 5], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.0.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_280.dc.add.10: {type: add, grid_loc: [0, 6], grid_size: [2, 1], inputs: [layernorm_280.dc.multiply.9, layer.0.output.LayerNorm.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_283: {type: matmul, grid_loc: [2, 0], grid_size: [2, 2], inputs: [layernorm_280.dc.add.10, layer.1.attention.self.query.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.1.attention.self.query.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.attention.self.query.bias_s_brcst_m2_1_0.0, layer.1.attention.self.query.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_285: {type: add, grid_loc: [1, 3], grid_size: [2, 1], inputs: [matmul_283, layer.1.attention.self.query.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_289: {type: matmul, grid_loc: [2, 4], grid_size: [2, 2], inputs: [layernorm_280.dc.add.10, layer.1.attention.self.key.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.1.attention.self.key.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.attention.self.key.bias_s_brcst_m2_1_0.0, layer.1.attention.self.key.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_291: {type: add, grid_loc: [1, 7], grid_size: [2, 1], inputs: [matmul_289, layer.1.attention.self.key.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_295: {type: matmul, grid_loc: [2, 2], grid_size: [2, 1], inputs: [add_285, add_291],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    input_1_multiply_297_fork_clone1670_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [2, 6], grid_size: [1, 1], inputs: [input_1_multiply_297_fork_clone1670_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_297_fork_clone1670_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [3, 3], grid_size: [1, 1], inputs: [input_1_multiply_297_fork_clone1670_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    multiply_297: {type: multiply, grid_loc: [3, 6], grid_size: [2, 1], inputs: [matmul_295, input_1_multiply_297_fork_clone1670_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_298: {type: add, grid_loc: [3, 7], grid_size: [2, 1], inputs: [multiply_297, attention_mask],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 16}]}
    softmax_299.dc.exp.0: {type: exp, grid_loc: [4, 0], grid_size: [2, 2], inputs: [add_298],
         t: 16, mblock: [3, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    lc.input_tensor.softmax_299.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [4, 2], grid_size: [1, 1], inputs: [lc.input_tensor.softmax_299.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    softmax_299.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [4, 3], grid_size: [2, 1], inputs: [softmax_299.dc.exp.0, lc.input_tensor.softmax_299.dc.reduce_sum.1.0_splt_brcst_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}
    softmax_299.dc.reciprocal.2: {type: reciprocal, grid_loc: [4, 4], grid_size: [2, 1], inputs: [softmax_299.dc.reduce_sum.1.lc1],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    softmax_299.dc.multiply.3: {type: multiply, grid_loc: [4, 5], grid_size: [2, 1], inputs: [softmax_299.dc.exp.0, softmax_299.dc.reciprocal.2],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [232, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    matmul_303: {type: matmul, grid_loc: [5, 6], grid_size: [2, 2], inputs: [layernorm_280.dc.add.10, layer.1.attention.self.value.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.1.attention.self.value.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.attention.self.value.bias_s_brcst_m2_1_0.0, layer.1.attention.self.value.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_305: {type: add, grid_loc: [6, 0], grid_size: [2, 1], inputs: [matmul_303, layer.1.attention.self.value.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_310: {type: matmul, grid_loc: [6, 1], grid_size: [2, 1], inputs: [softmax_299.dc.multiply.3, add_305],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    matmul_314: {type: matmul, grid_loc: [6, 2], grid_size: [2, 2], inputs: [matmul_310, layer.1.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 16],
         attributes: {m_k: 32, u_kt: 1}}
    layer.1.attention.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [6, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.attention.output.dense.bias_s_brcst_m2_1_0.0, layer.1.attention.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_316: {type: add, grid_loc: [6, 5], grid_size: [2, 1], inputs: [matmul_314, layer.1.attention.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    buffer_1_layernorm_280.dc.add.10_add_318: {type: nop, grid_loc: [7, 4], grid_size: [2, 1], inputs: [layernorm_280.dc.add.10],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_280.dc.add.10_add_318: {type: nop, grid_loc: [7, 6], grid_size: [2, 1], inputs: [buffer_1_layernorm_280.dc.add.10_add_318],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_318: {type: add, grid_loc: [7, 7], grid_size: [2, 1], inputs: [add_316, buffer_0_layernorm_280.dc.add.10_add_318],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_319.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [8, 0], grid_size: [2, 1], inputs: [add_318, lc.input_tensor.layernorm_319.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_319.dc.subtract.1: {type: subtract, grid_loc: [8, 1], grid_size: [2, 1], inputs: [add_318, layernorm_319.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_319.dc.multiply.2: {type: multiply, grid_loc: [8, 5], grid_size: [2, 1], inputs: [layernorm_319.dc.subtract.1, layernorm_319.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8: {type: nop, grid_loc: [8, 2], grid_size: [2, 1], inputs: [layernorm_319.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8: {type: nop, grid_loc: [8, 3], grid_size: [2, 1], inputs: [buffer_1_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_3:
    target_device: 0
    input_count: 2
    layernorm_319.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_layernorm_319.dc.multiply.2_0, lc.input_tensor.layernorm_319.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_319.dc.add.5: {type: add, grid_loc: [0, 1], grid_size: [2, 1], inputs: [layernorm_319.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_319.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_319.dc.sqrt.6: {type: sqrt, grid_loc: [0, 2], grid_size: [2, 1], inputs: [layernorm_319.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_319.dc.reciprocal.7: {type: reciprocal, grid_loc: [0, 3], grid_size: [2, 1], inputs: [layernorm_319.dc.sqrt.6],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_319.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [0, 4], grid_size: [2, 1], inputs: [layernorm_319.dc.reciprocal.7, lc.input_tensor.layernorm_319.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_319.dc.multiply.8: {type: multiply, grid_loc: [0, 5], grid_size: [2, 1], inputs: [e2e_buffer_0_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8_0, layernorm_319.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.1.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.1.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_319.dc.multiply.9: {type: multiply, grid_loc: [0, 7], grid_size: [2, 1], inputs: [layernorm_319.dc.multiply.8, layer.1.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.1.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.1.attention.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_319.dc.add.10: {type: add, grid_loc: [2, 0], grid_size: [2, 1], inputs: [layernorm_319.dc.multiply.9, layer.1.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_322: {type: matmul, grid_loc: [4, 0], grid_size: [2, 8], inputs: [layernorm_319.dc.add.10, layer.1.intermediate.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.1.intermediate.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [2, 1], grid_size: [1, 2], inputs: [lc.input_tensor.layer.1.intermediate.dense.bias_s_brcst_m2_1_0.0, layer.1.intermediate.dense.bias],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_324: {type: add, grid_loc: [2, 3], grid_size: [2, 4], inputs: [matmul_322, layer.1.intermediate.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    gelu_325: {type: gelu, grid_loc: [6, 0], grid_size: [2, 4], inputs: [add_324],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    matmul_328: {type: matmul, grid_loc: [8, 0], grid_size: [2, 8], inputs: [gelu_325, layer.1.output.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 16, u_kt: 8}}
    layer.1.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.output.dense.bias_s_brcst_m2_1_0.0, layer.1.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_330: {type: add, grid_loc: [6, 4], grid_size: [2, 1], inputs: [matmul_328, layer.1.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    buffer_1_layernorm_319.dc.add.10_add_332: {type: nop, grid_loc: [6, 5], grid_size: [2, 1], inputs: [layernorm_319.dc.add.10],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [120], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_319.dc.add.10_add_332: {type: nop, grid_loc: [6, 6], grid_size: [2, 1], inputs: [buffer_1_layernorm_319.dc.add.10_add_332],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [72], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_332: {type: add, grid_loc: [6, 7], grid_size: [2, 1], inputs: [add_330, buffer_0_layernorm_319.dc.add.10_add_332],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_4:
    target_device: 0
    input_count: 2
    layernorm_333.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_add_332_0, lc.input_tensor.layernorm_333.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_333.dc.subtract.1: {type: subtract, grid_loc: [0, 1], grid_size: [2, 1], inputs: [e2e_add_332_0, layernorm_333.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_333.dc.multiply.2: {type: multiply, grid_loc: [0, 5], grid_size: [2, 1], inputs: [layernorm_333.dc.subtract.1, layernorm_333.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_333.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [2, 1], inputs: [layernorm_333.dc.multiply.2, lc.input_tensor.layernorm_333.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_333.dc.add.5: {type: add, grid_loc: [0, 7], grid_size: [2, 1], inputs: [layernorm_333.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_333.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_333.dc.sqrt.6: {type: sqrt, grid_loc: [2, 0], grid_size: [2, 1], inputs: [layernorm_333.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_333.dc.reciprocal.7: {type: reciprocal, grid_loc: [2, 1], grid_size: [2, 1], inputs: [layernorm_333.dc.sqrt.6],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_333.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [2, 2], grid_size: [2, 1], inputs: [layernorm_333.dc.reciprocal.7, lc.input_tensor.layernorm_333.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    buffer_0_layernorm_333.dc.subtract.1_buffer_1_layernorm_333.dc.subtract.1_layernorm_333.dc.multiply.8: {type: nop, grid_loc: [0, 2], grid_size: [2, 1], inputs: [layernorm_333.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_333.dc.subtract.1_layernorm_333.dc.multiply.8: {type: nop, grid_loc: [0, 3], grid_size: [2, 1], inputs: [buffer_0_layernorm_333.dc.subtract.1_buffer_1_layernorm_333.dc.subtract.1_layernorm_333.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_333.dc.subtract.1_layernorm_333.dc.multiply.8: {type: nop, grid_loc: [0, 4], grid_size: [2, 1], inputs: [buffer_1_layernorm_333.dc.subtract.1_layernorm_333.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_333.dc.multiply.8: {type: multiply, grid_loc: [2, 3], grid_size: [2, 1], inputs: [buffer_0_layernorm_333.dc.subtract.1_layernorm_333.dc.multiply.8, layernorm_333.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.1.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.1.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_333.dc.multiply.9: {type: multiply, grid_loc: [2, 5], grid_size: [2, 1], inputs: [layernorm_333.dc.multiply.8, layer.1.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.1.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.1.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_333.dc.add.10: {type: add, grid_loc: [2, 7], grid_size: [2, 1], inputs: [layernorm_333.dc.multiply.9, layer.1.output.LayerNorm.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_336: {type: matmul, grid_loc: [4, 0], grid_size: [2, 2], inputs: [layernorm_333.dc.add.10, layer.2.attention.self.query.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.2.attention.self.query.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [3, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.attention.self.query.bias_s_brcst_m2_1_0.0, layer.2.attention.self.query.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_338: {type: add, grid_loc: [3, 6], grid_size: [2, 1], inputs: [matmul_336, layer.2.attention.self.query.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_342: {type: matmul, grid_loc: [4, 2], grid_size: [2, 2], inputs: [layernorm_333.dc.add.10, layer.2.attention.self.key.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.2.attention.self.key.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [4, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.attention.self.key.bias_s_brcst_m2_1_0.0, layer.2.attention.self.key.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_344: {type: add, grid_loc: [4, 5], grid_size: [2, 1], inputs: [matmul_342, layer.2.attention.self.key.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_348: {type: matmul, grid_loc: [4, 7], grid_size: [2, 1], inputs: [add_338, add_344],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    input_1_multiply_350_fork_clone1693_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [5, 4], grid_size: [1, 1], inputs: [input_1_multiply_350_fork_clone1693_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_350_fork_clone1693_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [5, 6], grid_size: [1, 1], inputs: [input_1_multiply_350_fork_clone1693_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    multiply_350: {type: multiply, grid_loc: [6, 0], grid_size: [2, 1], inputs: [matmul_348, input_1_multiply_350_fork_clone1693_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_351: {type: add, grid_loc: [6, 1], grid_size: [2, 1], inputs: [multiply_350, attention_mask],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 16}]}
    softmax_352.dc.exp.0: {type: exp, grid_loc: [6, 2], grid_size: [2, 2], inputs: [add_351],
         t: 16, mblock: [3, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    lc.input_tensor.softmax_352.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [6, 4], grid_size: [1, 1], inputs: [lc.input_tensor.softmax_352.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    softmax_352.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [6, 5], grid_size: [2, 1], inputs: [softmax_352.dc.exp.0, lc.input_tensor.softmax_352.dc.reduce_sum.1.0_splt_brcst_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}
    softmax_352.dc.reciprocal.2: {type: reciprocal, grid_loc: [6, 6], grid_size: [2, 1], inputs: [softmax_352.dc.reduce_sum.1.lc1],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    softmax_352.dc.multiply.3: {type: multiply, grid_loc: [6, 7], grid_size: [2, 1], inputs: [softmax_352.dc.exp.0, softmax_352.dc.reciprocal.2],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [232, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    matmul_356: {type: matmul, grid_loc: [8, 0], grid_size: [2, 2], inputs: [layernorm_333.dc.add.10, layer.2.attention.self.value.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.2.attention.self.value.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [7, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.attention.self.value.bias_s_brcst_m2_1_0.0, layer.2.attention.self.value.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_358: {type: add, grid_loc: [8, 2], grid_size: [2, 1], inputs: [matmul_356, layer.2.attention.self.value.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_363: {type: matmul, grid_loc: [8, 3], grid_size: [2, 1], inputs: [softmax_352.dc.multiply.3, add_358],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    matmul_367: {type: matmul, grid_loc: [8, 4], grid_size: [2, 2], inputs: [matmul_363, layer.2.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 16],
         attributes: {m_k: 32, u_kt: 1}}
    layer.2.attention.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [8, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.attention.output.dense.bias_s_brcst_m2_1_0.0, layer.2.attention.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_369: {type: add, grid_loc: [8, 7], grid_size: [2, 1], inputs: [matmul_367, layer.2.attention.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}

  fwd_5:
    target_device: 0
    input_count: 2
    buffer_1_layernorm_333.dc.add.10_add_371: {type: nop, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_layernorm_333.dc.add.10_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_333.dc.add.10_add_371: {type: nop, grid_loc: [0, 1], grid_size: [2, 1], inputs: [buffer_1_layernorm_333.dc.add.10_add_371],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_371: {type: add, grid_loc: [0, 2], grid_size: [2, 1], inputs: [e2e_add_369_0, buffer_0_layernorm_333.dc.add.10_add_371],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_372.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [0, 3], grid_size: [2, 1], inputs: [add_371, lc.input_tensor.layernorm_372.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_372.dc.subtract.1: {type: subtract, grid_loc: [0, 4], grid_size: [2, 1], inputs: [add_371, layernorm_372.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_372.dc.multiply.2: {type: multiply, grid_loc: [2, 0], grid_size: [2, 1], inputs: [layernorm_372.dc.subtract.1, layernorm_372.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_372.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [2, 1], grid_size: [2, 1], inputs: [layernorm_372.dc.multiply.2, lc.input_tensor.layernorm_372.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_372.dc.add.5: {type: add, grid_loc: [2, 2], grid_size: [2, 1], inputs: [layernorm_372.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_372.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_372.dc.sqrt.6: {type: sqrt, grid_loc: [2, 3], grid_size: [2, 1], inputs: [layernorm_372.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_372.dc.reciprocal.7: {type: reciprocal, grid_loc: [2, 4], grid_size: [2, 1], inputs: [layernorm_372.dc.sqrt.6],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_372.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [2, 5], grid_size: [2, 1], inputs: [layernorm_372.dc.reciprocal.7, lc.input_tensor.layernorm_372.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    buffer_0_layernorm_372.dc.subtract.1_buffer_1_layernorm_372.dc.subtract.1_layernorm_372.dc.multiply.8: {type: nop, grid_loc: [0, 5], grid_size: [2, 1], inputs: [layernorm_372.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_372.dc.subtract.1_layernorm_372.dc.multiply.8: {type: nop, grid_loc: [0, 6], grid_size: [2, 1], inputs: [buffer_0_layernorm_372.dc.subtract.1_buffer_1_layernorm_372.dc.subtract.1_layernorm_372.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_372.dc.subtract.1_layernorm_372.dc.multiply.8: {type: nop, grid_loc: [0, 7], grid_size: [2, 1], inputs: [buffer_1_layernorm_372.dc.subtract.1_layernorm_372.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_372.dc.multiply.8: {type: multiply, grid_loc: [2, 6], grid_size: [2, 1], inputs: [buffer_0_layernorm_372.dc.subtract.1_layernorm_372.dc.multiply.8, layernorm_372.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.2.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.2.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_372.dc.multiply.9: {type: multiply, grid_loc: [3, 7], grid_size: [2, 1], inputs: [layernorm_372.dc.multiply.8, layer.2.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.2.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [4, 0], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.2.attention.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_372.dc.add.10: {type: add, grid_loc: [4, 1], grid_size: [2, 1], inputs: [layernorm_372.dc.multiply.9, layer.2.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_375: {type: matmul, grid_loc: [6, 0], grid_size: [2, 8], inputs: [layernorm_372.dc.add.10, layer.2.intermediate.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.2.intermediate.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [4, 2], grid_size: [1, 2], inputs: [lc.input_tensor.layer.2.intermediate.dense.bias_s_brcst_m2_1_0.0, layer.2.intermediate.dense.bias],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_377: {type: add, grid_loc: [8, 0], grid_size: [2, 4], inputs: [matmul_375, layer.2.intermediate.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    gelu_378: {type: gelu, grid_loc: [8, 4], grid_size: [2, 4], inputs: [add_377],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}

  fwd_6:
    target_device: 0
    input_count: 2
    matmul_381: {type: matmul, grid_loc: [0, 0], grid_size: [2, 8], inputs: [e2e_gelu_378_0, layer.2.output.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 16, u_kt: 8}}
    layer.2.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [2, 0], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.output.dense.bias_s_brcst_m2_1_0.0, layer.2.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_383: {type: add, grid_loc: [2, 1], grid_size: [2, 1], inputs: [matmul_381, layer.2.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_385: {type: add, grid_loc: [2, 2], grid_size: [2, 1], inputs: [add_383, e2e_layernorm_372.dc.add.10_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_386.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [2, 3], grid_size: [2, 1], inputs: [add_385, lc.input_tensor.layernorm_386.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_386.dc.subtract.1: {type: subtract, grid_loc: [2, 4], grid_size: [2, 1], inputs: [add_385, layernorm_386.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_386.dc.multiply.2: {type: multiply, grid_loc: [3, 0], grid_size: [2, 1], inputs: [layernorm_386.dc.subtract.1, layernorm_386.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_386.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [4, 1], grid_size: [2, 1], inputs: [layernorm_386.dc.multiply.2, lc.input_tensor.layernorm_386.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_386.dc.add.5: {type: add, grid_loc: [4, 2], grid_size: [2, 1], inputs: [layernorm_386.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_386.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_386.dc.sqrt.6: {type: sqrt, grid_loc: [4, 3], grid_size: [2, 1], inputs: [layernorm_386.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_386.dc.reciprocal.7: {type: reciprocal, grid_loc: [4, 4], grid_size: [2, 1], inputs: [layernorm_386.dc.sqrt.6],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_386.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [4, 5], grid_size: [2, 1], inputs: [layernorm_386.dc.reciprocal.7, lc.input_tensor.layernorm_386.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    buffer_0_layernorm_386.dc.subtract.1_buffer_1_layernorm_386.dc.subtract.1_layernorm_386.dc.multiply.8: {type: nop, grid_loc: [2, 5], grid_size: [2, 1], inputs: [layernorm_386.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_386.dc.subtract.1_layernorm_386.dc.multiply.8: {type: nop, grid_loc: [2, 6], grid_size: [2, 1], inputs: [buffer_0_layernorm_386.dc.subtract.1_buffer_1_layernorm_386.dc.subtract.1_layernorm_386.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_386.dc.subtract.1_layernorm_386.dc.multiply.8: {type: nop, grid_loc: [2, 7], grid_size: [2, 1], inputs: [buffer_1_layernorm_386.dc.subtract.1_layernorm_386.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_386.dc.multiply.8: {type: multiply, grid_loc: [4, 6], grid_size: [2, 1], inputs: [buffer_0_layernorm_386.dc.subtract.1_layernorm_386.dc.multiply.8, layernorm_386.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.2.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.2.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_386.dc.multiply.9: {type: multiply, grid_loc: [5, 0], grid_size: [2, 1], inputs: [layernorm_386.dc.multiply.8, layer.2.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.2.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [5, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.2.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_386.dc.add.10: {type: add, grid_loc: [6, 1], grid_size: [2, 1], inputs: [layernorm_386.dc.multiply.9, layer.2.output.LayerNorm.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_389: {type: matmul, grid_loc: [6, 2], grid_size: [2, 2], inputs: [layernorm_386.dc.add.10, layer.3.attention.self.query.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.3.attention.self.query.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [6, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.attention.self.query.bias_s_brcst_m2_1_0.0, layer.3.attention.self.query.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_391: {type: add, grid_loc: [6, 5], grid_size: [2, 1], inputs: [matmul_389, layer.3.attention.self.query.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_395: {type: matmul, grid_loc: [6, 6], grid_size: [2, 2], inputs: [layernorm_386.dc.add.10, layer.3.attention.self.key.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.3.attention.self.key.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [7, 0], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.attention.self.key.bias_s_brcst_m2_1_0.0, layer.3.attention.self.key.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_397: {type: add, grid_loc: [7, 4], grid_size: [2, 1], inputs: [matmul_395, layer.3.attention.self.key.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_401: {type: matmul, grid_loc: [8, 0], grid_size: [2, 1], inputs: [add_391, add_397],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    input_1_multiply_403_fork_clone1716_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [8, 1], grid_size: [1, 1], inputs: [input_1_multiply_403_fork_clone1716_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_403_fork_clone1716_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [8, 2], grid_size: [1, 1], inputs: [input_1_multiply_403_fork_clone1716_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    multiply_403: {type: multiply, grid_loc: [8, 3], grid_size: [2, 1], inputs: [matmul_401, input_1_multiply_403_fork_clone1716_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_404: {type: add, grid_loc: [8, 5], grid_size: [2, 1], inputs: [multiply_403, attention_mask],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 16}]}
    softmax_405.dc.exp.0: {type: exp, grid_loc: [8, 6], grid_size: [2, 2], inputs: [add_404],
         t: 16, mblock: [3, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    lc.input_tensor.softmax_405.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [9, 1], grid_size: [1, 1], inputs: [lc.input_tensor.softmax_405.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}

  fwd_7:
    target_device: 0
    input_count: 2
    softmax_405.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_softmax_405.dc.exp.0_0, e2e_lc.input_tensor.softmax_405.dc.reduce_sum.1.0_splt_brcst_1_0_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}
    softmax_405.dc.reciprocal.2: {type: reciprocal, grid_loc: [0, 1], grid_size: [2, 1], inputs: [softmax_405.dc.reduce_sum.1.lc1],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    softmax_405.dc.multiply.3: {type: multiply, grid_loc: [0, 2], grid_size: [2, 1], inputs: [e2e_softmax_405.dc.exp.0_0, softmax_405.dc.reciprocal.2],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    matmul_409: {type: matmul, grid_loc: [0, 3], grid_size: [2, 2], inputs: [e2e_layernorm_386.dc.add.10_0, layer.3.attention.self.value.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.3.attention.self.value.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [0, 5], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.attention.self.value.bias_s_brcst_m2_1_0.0, layer.3.attention.self.value.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_411: {type: add, grid_loc: [0, 6], grid_size: [2, 1], inputs: [matmul_409, layer.3.attention.self.value.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_416: {type: matmul, grid_loc: [0, 7], grid_size: [2, 1], inputs: [softmax_405.dc.multiply.3, add_411],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    matmul_420: {type: matmul, grid_loc: [2, 0], grid_size: [2, 2], inputs: [matmul_416, layer.3.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 16],
         attributes: {m_k: 32, u_kt: 1}}
    layer.3.attention.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.attention.output.dense.bias_s_brcst_m2_1_0.0, layer.3.attention.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_422: {type: add, grid_loc: [2, 2], grid_size: [2, 1], inputs: [matmul_420, layer.3.attention.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_424: {type: add, grid_loc: [2, 3], grid_size: [2, 1], inputs: [add_422, e2e_layernorm_386.dc.add.10_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_425.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [2, 1], inputs: [add_424, lc.input_tensor.layernorm_425.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_425.dc.subtract.1: {type: subtract, grid_loc: [2, 5], grid_size: [2, 1], inputs: [add_424, layernorm_425.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_425.dc.multiply.2: {type: multiply, grid_loc: [2, 6], grid_size: [2, 1], inputs: [layernorm_425.dc.subtract.1, layernorm_425.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_425.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [2, 1], inputs: [layernorm_425.dc.multiply.2, lc.input_tensor.layernorm_425.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_425.dc.add.5: {type: add, grid_loc: [4, 0], grid_size: [2, 1], inputs: [layernorm_425.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_425.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_425.dc.sqrt.6: {type: sqrt, grid_loc: [4, 1], grid_size: [2, 1], inputs: [layernorm_425.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_425.dc.reciprocal.7: {type: reciprocal, grid_loc: [4, 2], grid_size: [2, 1], inputs: [layernorm_425.dc.sqrt.6],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_425.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [4, 6], grid_size: [2, 1], inputs: [layernorm_425.dc.reciprocal.7, lc.input_tensor.layernorm_425.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    buffer_0_layernorm_425.dc.subtract.1_buffer_1_layernorm_425.dc.subtract.1_layernorm_425.dc.multiply.8: {type: nop, grid_loc: [4, 3], grid_size: [2, 1], inputs: [layernorm_425.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_425.dc.subtract.1_layernorm_425.dc.multiply.8: {type: nop, grid_loc: [4, 4], grid_size: [2, 1], inputs: [buffer_0_layernorm_425.dc.subtract.1_buffer_1_layernorm_425.dc.subtract.1_layernorm_425.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_425.dc.subtract.1_layernorm_425.dc.multiply.8: {type: nop, grid_loc: [4, 5], grid_size: [2, 1], inputs: [buffer_1_layernorm_425.dc.subtract.1_layernorm_425.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_425.dc.multiply.8: {type: multiply, grid_loc: [4, 7], grid_size: [2, 1], inputs: [buffer_0_layernorm_425.dc.subtract.1_layernorm_425.dc.multiply.8, layernorm_425.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.3.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [6, 0], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.3.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_425.dc.multiply.9: {type: multiply, grid_loc: [6, 1], grid_size: [2, 1], inputs: [layernorm_425.dc.multiply.8, layer.3.attention.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.3.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [6, 2], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.3.attention.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_425.dc.add.10: {type: add, grid_loc: [6, 3], grid_size: [2, 1], inputs: [layernorm_425.dc.multiply.9, layer.3.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    matmul_428: {type: matmul, grid_loc: [8, 0], grid_size: [2, 8], inputs: [layernorm_425.dc.add.10, layer.3.intermediate.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 32, u_kt: 1}}
    layer.3.intermediate.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [6, 4], grid_size: [1, 2], inputs: [lc.input_tensor.layer.3.intermediate.dense.bias_s_brcst_m2_1_0.0, layer.3.intermediate.dense.bias],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}

  fwd_8:
    target_device: 0
    input_count: 2
    add_430: {type: add, grid_loc: [0, 0], grid_size: [2, 4], inputs: [e2e_matmul_428_0, e2e_layer.3.intermediate.dense.bias_s_brcst_m2_1_0.lc1_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    gelu_431: {type: gelu, grid_loc: [0, 4], grid_size: [2, 4], inputs: [add_430],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    matmul_434: {type: matmul, grid_loc: [2, 0], grid_size: [2, 8], inputs: [gelu_431, layer.3.output.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 16, u_kt: 8}}
    layer.3.output.dense.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [4, 0], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.output.dense.bias_s_brcst_m2_1_0.0, layer.3.output.dense.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    add_436: {type: add, grid_loc: [4, 1], grid_size: [2, 1], inputs: [matmul_434, layer.3.output.dense.bias_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    add_438: {type: add, grid_loc: [4, 2], grid_size: [2, 1], inputs: [add_436, e2e_layernorm_425.dc.add.10_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_439.dc.reduce_avg.0.lc1: {type: matmul, grid_loc: [4, 3], grid_size: [2, 1], inputs: [add_438, lc.input_tensor.layernorm_439.dc.reduce_avg.0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_439.dc.subtract.1: {type: subtract, grid_loc: [4, 4], grid_size: [2, 1], inputs: [add_438, layernorm_439.dc.reduce_avg.0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layernorm_439.dc.multiply.2: {type: multiply, grid_loc: [4, 5], grid_size: [2, 1], inputs: [layernorm_439.dc.subtract.1, layernorm_439.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_439.dc.reduce_avg.3.lc1: {type: matmul, grid_loc: [4, 6], grid_size: [2, 1], inputs: [layernorm_439.dc.multiply.2, lc.input_tensor.layernorm_439.dc.reduce_avg.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    layernorm_439.dc.add.5: {type: add, grid_loc: [4, 7], grid_size: [2, 1], inputs: [layernorm_439.dc.reduce_avg.3.lc1, dc.input_tensor.layernorm_439.4],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_439.dc.sqrt.6: {type: sqrt, grid_loc: [5, 0], grid_size: [2, 1], inputs: [layernorm_439.dc.add.5],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_439.dc.reciprocal.7: {type: reciprocal, grid_loc: [6, 1], grid_size: [2, 1], inputs: [layernorm_439.dc.sqrt.6],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    layernorm_439.dc.reciprocal.7_s_brcst_m1_1_0.lc1: {type: matmul, grid_loc: [6, 5], grid_size: [2, 1], inputs: [layernorm_439.dc.reciprocal.7, lc.input_tensor.layernorm_439.dc.reciprocal.7_s_brcst_m1_1_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    buffer_0_layernorm_439.dc.subtract.1_buffer_1_layernorm_439.dc.subtract.1_layernorm_439.dc.multiply.8: {type: nop, grid_loc: [6, 2], grid_size: [2, 1], inputs: [layernorm_439.dc.subtract.1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_1_layernorm_439.dc.subtract.1_layernorm_439.dc.multiply.8: {type: nop, grid_loc: [6, 3], grid_size: [2, 1], inputs: [buffer_0_layernorm_439.dc.subtract.1_buffer_1_layernorm_439.dc.subtract.1_layernorm_439.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_layernorm_439.dc.subtract.1_layernorm_439.dc.multiply.8: {type: nop, grid_loc: [6, 4], grid_size: [2, 1], inputs: [buffer_1_layernorm_439.dc.subtract.1_layernorm_439.dc.multiply.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_439.dc.multiply.8: {type: multiply, grid_loc: [6, 6], grid_size: [2, 1], inputs: [buffer_0_layernorm_439.dc.subtract.1_layernorm_439.dc.multiply.8, layernorm_439.dc.reciprocal.7_s_brcst_m1_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    layer.3.output.LayerNorm.weight_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.output.LayerNorm.weight_s_brcst_m2_1_0.0, layer.3.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_439.dc.multiply.9: {type: multiply, grid_loc: [7, 0], grid_size: [2, 1], inputs: [layernorm_439.dc.multiply.8, layer.3.output.LayerNorm.weight_s_brcst_m2_1_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    layer.3.output.LayerNorm.bias_s_brcst_m2_1_0.lc1: {type: matmul, grid_loc: [7, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.output.LayerNorm.bias_s_brcst_m2_1_0.0, layer.3.output.LayerNorm.bias],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_439.dc.add.10: {type: add, grid_loc: [8, 1], grid_size: [2, 1], inputs: [layernorm_439.dc.multiply.9, layer.3.output.LayerNorm.bias_s_brcst_m2_1_0.lc1], untilize_output: true,
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}

  bwd_9:
    target_device: 0
    input_count: 2
    bw_in2_layernorm_439_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [2, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_439_layernorm_bw_0.dc.reduce_sum.0.0, loss_bert_encoder.output_layernorm_439], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_439_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [2, 4], grid_size: [2, 1], inputs: [e2e_layernorm_439.dc.multiply.8_0, loss_bert_encoder.output_layernorm_439],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [2, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_439_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    layernorm_439.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_layernorm_439.dc.reciprocal.7_0, lc.input_tensor.layernorm_439.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.3.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [0, 1], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.3.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [0, 2], grid_size: [2, 1], inputs: [loss_bert_encoder.output_layernorm_439, layer.3.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [0, 3], grid_size: [2, 1], inputs: [bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [0, 4], grid_size: [2, 1], inputs: [bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.0, e2e_layernorm_439.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [0, 5], grid_size: [2, 1], inputs: [bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [0, 6], grid_size: [2, 1], inputs: [e2e_layernorm_439.dc.multiply.8_0, bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.3.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_439_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [0, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.lc1, bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [1, 1], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.6, bw_in0_layernorm_439_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_439_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [2, 0], grid_size: [2, 1], inputs: [bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.0, bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [2, 2], grid_size: [2, 1], inputs: [layernorm_439.dc.reciprocal.7_s_brcst_m1_0_0.lc1, bw_in0_layernorm_439_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_436_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_436_brcst_reduce_sum_0.0, bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_434_matmul_1: {type: matmul, grid_loc: [4, 0], grid_size: [2, 8], inputs: [bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9, layer.3.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_434_transpose_0: {type: nop, grid_loc: [6, 0], grid_size: [2, 4], inputs: [e2e_gelu_431_0],
         t: 1, mblock: [32, 3], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_434_matmul_1: {type: matmul, grid_loc: [8, 0], grid_size: [2, 8], inputs: [bw_in1_matmul_434_transpose_0, bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [32, 1], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}

  bwd_10:
    target_device: 0
    input_count: 2
    bw_in0_gelu_431_gelu_derivative_0: {type: gelu_derivative, grid_loc: [0, 0], grid_size: [2, 8], inputs: [e2e_add_430_0],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    bw_in0_gelu_431_multiply_1: {type: multiply, grid_loc: [2, 0], grid_size: [2, 4], inputs: [bw_in0_gelu_431_gelu_derivative_0, e2e_bw_in0_matmul_434_matmul_1_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_add_430_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_430_brcst_reduce_sum_0.0, bw_in0_gelu_431_multiply_1], gradient_op: true,
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_matmul_428_matmul_1: {type: matmul, grid_loc: [4, 0], grid_size: [2, 8], inputs: [bw_in0_gelu_431_multiply_1, layer.3.intermediate.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 16, u_kt: 8}}
    bw_in1_matmul_428_transpose_0: {type: nop, grid_loc: [2, 5], grid_size: [1, 2], inputs: [e2e_layernorm_425.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}

  bwd_11:
    target_device: 0
    input_count: 2
    bw_in1_matmul_428_matmul_1: {type: matmul, grid_loc: [0, 0], grid_size: [8, 2], inputs: [e2e_bw_in1_matmul_428_transpose_0_0, e2e_bw_in0_gelu_431_multiply_1_0], gradient_op: true,
         t: 1, mblock: [2, 16], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_layernorm_425_combine_add_0: {type: add, grid_loc: [0, 3], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_matmul_428_matmul_1_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in2_layernorm_425_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [4, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_425_layernorm_bw_0.dc.reduce_sum.0.0, bw_in0_layernorm_425_combine_add_0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_425_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [3, 4], grid_size: [2, 1], inputs: [e2e_layernorm_425.dc.multiply.8_0, bw_in0_layernorm_425_combine_add_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [4, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_425_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    layernorm_425.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [0, 2], grid_size: [2, 1], inputs: [e2e_layernorm_425.dc.reciprocal.7_0, lc.input_tensor.layernorm_425.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.3.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [0, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.3.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.3.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [0, 5], grid_size: [2, 1], inputs: [bw_in0_layernorm_425_combine_add_0, layer.3.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [2, 1], inputs: [bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [0, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.0, e2e_layernorm_425.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [1, 4], grid_size: [2, 1], inputs: [bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [2, 2], grid_size: [2, 1], inputs: [e2e_layernorm_425.dc.multiply.8_0, bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.3.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_425_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [2, 3], grid_size: [2, 1], inputs: [bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.lc1, bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [2, 5], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.6, bw_in0_layernorm_425_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_425_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [2, 6], grid_size: [2, 1], inputs: [bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.0, bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [2, 7], grid_size: [2, 1], inputs: [layernorm_425.dc.reciprocal.7_s_brcst_m1_0_0.lc1, bw_in0_layernorm_425_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_422_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [4, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_422_brcst_reduce_sum_0.0, bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_420_matmul_1: {type: matmul, grid_loc: [4, 6], grid_size: [2, 2], inputs: [bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9, layer.3.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_420_transpose_0: {type: nop, grid_loc: [5, 2], grid_size: [1, 2], inputs: [e2e_matmul_416_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, vstack: 16]}
    bw_in1_matmul_420_matmul_1: {type: matmul, grid_loc: [6, 2], grid_size: [1, 4], inputs: [bw_in1_matmul_420_transpose_0, bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_matmul_416_matmul_1: {type: matmul, grid_loc: [7, 2], grid_size: [2, 1], inputs: [bw_in0_matmul_420_matmul_1, e2e_add_411_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    bw_in1_matmul_416_transpose_0: {type: nop, grid_loc: [6, 6], grid_size: [2, 1], inputs: [e2e_softmax_405.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_416_matmul_1: {type: matmul, grid_loc: [6, 7], grid_size: [2, 1], inputs: [bw_in1_matmul_416_transpose_0, bw_in0_matmul_420_matmul_1],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_411_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [5, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_411_brcst_reduce_sum_0.0, bw_in1_matmul_416_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_409_add_411_unsqueeze3_746_squeeze_0: {type: nop, grid_loc: [7, 3], grid_size: [2, 1], inputs: [bw_in1_matmul_416_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 16]}
    bw_in0_matmul_409_matmul_1: {type: matmul, grid_loc: [7, 4], grid_size: [2, 2], inputs: [bw_in0_matmul_409_add_411_unsqueeze3_746_squeeze_0, layer.3.attention.self.value.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_409_transpose_0: {type: nop, grid_loc: [8, 0], grid_size: [1, 2], inputs: [e2e_layernorm_386.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_409_matmul_1: {type: matmul, grid_loc: [9, 0], grid_size: [1, 4], inputs: [bw_in1_matmul_409_transpose_0, bw_in0_matmul_409_add_411_unsqueeze3_746_squeeze_0], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_softmax_405_softmax_bw_0.dc.multiply.0: {type: multiply, grid_loc: [8, 6], grid_size: [2, 1], inputs: [bw_in0_matmul_416_matmul_1, e2e_softmax_405.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    lc.input_tensor.bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [5, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [8, 7], grid_size: [2, 1], inputs: [bw_in0_softmax_405_softmax_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}

  bwd_12:
    target_device: 0
    input_count: 2
    bw_in0_softmax_405_softmax_bw_0.dc.subtract.2: {type: subtract, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_bw_in0_matmul_416_matmul_1_0, e2e_bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.lc1_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    bw_in0_softmax_405_softmax_bw_0.dc.multiply.3: {type: multiply, grid_loc: [0, 1], grid_size: [2, 1], inputs: [bw_in0_softmax_405_softmax_bw_0.dc.subtract.2, e2e_softmax_405.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_1_multiply_403_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [0, 2], grid_size: [1, 1], inputs: [input_1_multiply_403_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_403_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [0, 3], grid_size: [1, 1], inputs: [input_1_multiply_403_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    bw_in0_multiply_403_multiply_0: {type: multiply, grid_loc: [0, 4], grid_size: [2, 1], inputs: [bw_in0_softmax_405_softmax_bw_0.dc.multiply.3, input_1_multiply_403_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_matmul_401_matmul_1: {type: matmul, grid_loc: [1, 2], grid_size: [2, 1], inputs: [bw_in0_multiply_403_multiply_0, e2e_add_397_0],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_matmul_401_transpose_0: {type: nop, grid_loc: [0, 5], grid_size: [1, 1], inputs: [e2e_add_391_0],
         t: 16, mblock: [1, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hslice: 16, transpose]}
    bw_in1_matmul_401_matmul_1: {type: matmul, grid_loc: [0, 6], grid_size: [1, 2], inputs: [bw_in1_matmul_401_transpose_0, bw_in0_multiply_403_multiply_0],
         t: 16, mblock: [1, 3], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_397_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [1, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_397_brcst_reduce_sum_0.0, bw_in1_matmul_401_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose, hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_395_add_397_unsqueeze3_734_squeeze_0: {type: nop, grid_loc: [1, 5], grid_size: [2, 1], inputs: [bw_in1_matmul_401_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, hstack: 16]}
    bw_in0_matmul_395_matmul_1: {type: matmul, grid_loc: [1, 6], grid_size: [2, 2], inputs: [bw_in0_matmul_395_add_397_unsqueeze3_734_squeeze_0, layer.3.attention.self.key.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_395_transpose_0: {type: nop, grid_loc: [2, 0], grid_size: [1, 2], inputs: [e2e_layernorm_386.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_395_matmul_1: {type: matmul, grid_loc: [3, 0], grid_size: [1, 4], inputs: [bw_in1_matmul_395_transpose_0, bw_in0_matmul_395_add_397_unsqueeze3_734_squeeze_0], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}
    bw_in1_add_391_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [2, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_391_brcst_reduce_sum_0.0, bw_in0_matmul_401_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_389_matmul_1: {type: matmul, grid_loc: [3, 4], grid_size: [2, 2], inputs: [bw_in0_matmul_401_matmul_1, layer.3.attention.self.query.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose], input_0_tms: [hstack: 16],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_389_transpose_0: {type: nop, grid_loc: [3, 6], grid_size: [1, 2], inputs: [e2e_layernorm_386.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_389_matmul_1: {type: matmul, grid_loc: [4, 0], grid_size: [1, 4], inputs: [bw_in1_matmul_389_transpose_0, bw_in0_matmul_401_matmul_1], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16],
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_reshape_387_combine_add_0: {type: add, grid_loc: [4, 7], grid_size: [2, 1], inputs: [e2e_bw_in0_matmul_409_matmul_1_0, bw_in0_matmul_395_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_reshape_387_combine_add_1: {type: add, grid_loc: [5, 0], grid_size: [2, 1], inputs: [bw_in0_reshape_387_combine_add_0, bw_in0_matmul_389_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_386_combine_add_0: {type: add, grid_loc: [5, 1], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9_0, bw_in0_reshape_387_combine_add_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in2_layernorm_386_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [7, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_386_layernorm_bw_0.dc.reduce_sum.0.0, bw_in0_layernorm_386_combine_add_0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_386_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [7, 3], grid_size: [2, 1], inputs: [e2e_layernorm_386.dc.multiply.8_0, bw_in0_layernorm_386_combine_add_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [7, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_386_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    layernorm_386.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [4, 6], grid_size: [2, 1], inputs: [e2e_layernorm_386.dc.reciprocal.7_0, lc.input_tensor.layernorm_386.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.2.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.2.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [5, 2], grid_size: [2, 1], inputs: [bw_in0_layernorm_386_combine_add_0, layer.2.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [5, 3], grid_size: [2, 1], inputs: [bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [5, 4], grid_size: [2, 1], inputs: [bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.0, e2e_layernorm_386.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [5, 5], grid_size: [2, 1], inputs: [bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [6, 6], grid_size: [2, 1], inputs: [e2e_layernorm_386.dc.multiply.8_0, bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.3.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_386_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [6, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.lc1, bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [7, 0], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.6, bw_in0_layernorm_386_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_386_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [7, 1], grid_size: [2, 1], inputs: [bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.0, bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [7, 2], grid_size: [2, 1], inputs: [layernorm_386.dc.reciprocal.7_s_brcst_m1_0_0.lc1, bw_in0_layernorm_386_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_383_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [8, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_383_brcst_reduce_sum_0.0, bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}

  bwd_13:
    target_device: 0
    input_count: 2
    bw_in0_matmul_381_matmul_1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 8], inputs: [e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0, layer.2.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_381_transpose_0: {type: nop, grid_loc: [2, 0], grid_size: [2, 4], inputs: [e2e_gelu_378_0],
         t: 1, mblock: [32, 3], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_381_matmul_1: {type: matmul, grid_loc: [4, 0], grid_size: [2, 8], inputs: [bw_in1_matmul_381_transpose_0, e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0], gradient_op: true,
         t: 1, mblock: [32, 1], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_gelu_378_gelu_derivative_0: {type: gelu_derivative, grid_loc: [6, 0], grid_size: [2, 8], inputs: [e2e_add_377_0],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    bw_in0_gelu_378_multiply_1: {type: multiply, grid_loc: [2, 4], grid_size: [2, 4], inputs: [bw_in0_gelu_378_gelu_derivative_0, bw_in0_matmul_381_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_add_377_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [8, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_377_brcst_reduce_sum_0.0, bw_in0_gelu_378_multiply_1], gradient_op: true,
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 12, u_kt: 1}}

  bwd_14:
    target_device: 0
    input_count: 2
    bw_in0_matmul_375_matmul_1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 8], inputs: [e2e_bw_in0_gelu_378_multiply_1_0, layer.2.intermediate.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 16, u_kt: 8}}
    bw_in1_matmul_375_transpose_0: {type: nop, grid_loc: [2, 0], grid_size: [1, 2], inputs: [e2e_layernorm_372.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_375_matmul_1: {type: matmul, grid_loc: [2, 2], grid_size: [8, 2], inputs: [bw_in1_matmul_375_transpose_0, e2e_bw_in0_gelu_378_multiply_1_0], gradient_op: true,
         t: 1, mblock: [2, 16], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_layernorm_372_combine_add_0: {type: add, grid_loc: [2, 5], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0, bw_in0_matmul_375_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in2_layernorm_372_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [6, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_372_layernorm_bw_0.dc.reduce_sum.0.0, bw_in0_layernorm_372_combine_add_0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_372_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [5, 6], grid_size: [2, 1], inputs: [e2e_layernorm_372.dc.multiply.8_0, bw_in0_layernorm_372_combine_add_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [6, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_372_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    layernorm_372.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [2, 1], inputs: [e2e_layernorm_372.dc.reciprocal.7_0, lc.input_tensor.layernorm_372.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.2.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.2.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.2.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [2, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_372_combine_add_0, layer.2.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [3, 0], grid_size: [2, 1], inputs: [bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [3, 1], grid_size: [2, 1], inputs: [bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.0, e2e_layernorm_372.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [3, 6], grid_size: [2, 1], inputs: [bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [4, 4], grid_size: [2, 1], inputs: [e2e_layernorm_372.dc.multiply.8_0, bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.3.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_372_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [4, 5], grid_size: [2, 1], inputs: [bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.lc1, bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [4, 7], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.6, bw_in0_layernorm_372_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_372_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [5, 0], grid_size: [2, 1], inputs: [bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.0, bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [5, 1], grid_size: [2, 1], inputs: [layernorm_372.dc.reciprocal.7_s_brcst_m1_0_0.lc1, bw_in0_layernorm_372_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_369_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_369_brcst_reduce_sum_0.0, bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_367_matmul_1: {type: matmul, grid_loc: [7, 0], grid_size: [2, 2], inputs: [bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9, layer.2.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_367_transpose_0: {type: nop, grid_loc: [7, 4], grid_size: [1, 2], inputs: [e2e_matmul_363_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, vstack: 16]}
    bw_in1_matmul_367_matmul_1: {type: matmul, grid_loc: [8, 4], grid_size: [1, 4], inputs: [bw_in1_matmul_367_transpose_0, bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}

  bwd_15:
    target_device: 0
    input_count: 2
    bw_in0_matmul_363_matmul_1: {type: matmul, grid_loc: [0, 2], grid_size: [2, 1], inputs: [e2e_bw_in0_matmul_367_matmul_1_0, e2e_add_358_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    bw_in1_matmul_363_transpose_0: {type: nop, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_softmax_352.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_363_matmul_1: {type: matmul, grid_loc: [0, 1], grid_size: [2, 1], inputs: [bw_in1_matmul_363_transpose_0, e2e_bw_in0_matmul_367_matmul_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_358_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [0, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_358_brcst_reduce_sum_0.0, bw_in1_matmul_363_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_356_add_358_unsqueeze3_704_squeeze_0: {type: nop, grid_loc: [0, 4], grid_size: [2, 1], inputs: [bw_in1_matmul_363_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 16]}
    bw_in0_matmul_356_matmul_1: {type: matmul, grid_loc: [0, 5], grid_size: [2, 2], inputs: [bw_in0_matmul_356_add_358_unsqueeze3_704_squeeze_0, layer.2.attention.self.value.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_356_transpose_0: {type: nop, grid_loc: [2, 0], grid_size: [1, 2], inputs: [e2e_layernorm_333.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_356_matmul_1: {type: matmul, grid_loc: [2, 2], grid_size: [1, 4], inputs: [bw_in1_matmul_356_transpose_0, bw_in0_matmul_356_add_358_unsqueeze3_704_squeeze_0], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_softmax_352_softmax_bw_0.dc.multiply.0: {type: multiply, grid_loc: [0, 7], grid_size: [2, 1], inputs: [bw_in0_matmul_363_matmul_1, e2e_softmax_352.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    lc.input_tensor.bw_in0_softmax_352_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [1, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in0_softmax_352_softmax_bw_0.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    bw_in0_softmax_352_softmax_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [2, 1], inputs: [bw_in0_softmax_352_softmax_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_softmax_352_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}
    bw_in0_softmax_352_softmax_bw_0.dc.subtract.2: {type: subtract, grid_loc: [2, 7], grid_size: [2, 1], inputs: [bw_in0_matmul_363_matmul_1, bw_in0_softmax_352_softmax_bw_0.dc.reduce_sum.1.lc1],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [232, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    bw_in0_softmax_352_softmax_bw_0.dc.multiply.3: {type: multiply, grid_loc: [3, 0], grid_size: [2, 1], inputs: [bw_in0_softmax_352_softmax_bw_0.dc.subtract.2, e2e_softmax_352.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_1_multiply_350_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [3, 1], grid_size: [1, 1], inputs: [input_1_multiply_350_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_350_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [3, 2], grid_size: [1, 1], inputs: [input_1_multiply_350_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    bw_in0_multiply_350_multiply_0: {type: multiply, grid_loc: [3, 3], grid_size: [2, 1], inputs: [bw_in0_softmax_352_softmax_bw_0.dc.multiply.3, input_1_multiply_350_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_matmul_348_matmul_1: {type: matmul, grid_loc: [3, 5], grid_size: [2, 1], inputs: [bw_in0_multiply_350_multiply_0, e2e_add_344_0],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_matmul_348_transpose_0: {type: nop, grid_loc: [3, 4], grid_size: [1, 1], inputs: [e2e_add_338_0],
         t: 16, mblock: [1, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hslice: 16, transpose]}
    bw_in1_matmul_348_matmul_1: {type: matmul, grid_loc: [4, 1], grid_size: [1, 2], inputs: [bw_in1_matmul_348_transpose_0, bw_in0_multiply_350_multiply_0],
         t: 16, mblock: [1, 3], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_344_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [4, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_344_brcst_reduce_sum_0.0, bw_in1_matmul_348_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose, hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_342_add_344_unsqueeze3_692_squeeze_0: {type: nop, grid_loc: [4, 6], grid_size: [2, 1], inputs: [bw_in1_matmul_348_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, hstack: 16]}
    bw_in0_matmul_342_matmul_1: {type: matmul, grid_loc: [5, 0], grid_size: [2, 2], inputs: [bw_in0_matmul_342_add_344_unsqueeze3_692_squeeze_0, layer.2.attention.self.key.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_342_transpose_0: {type: nop, grid_loc: [5, 2], grid_size: [1, 2], inputs: [e2e_layernorm_333.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_342_matmul_1: {type: matmul, grid_loc: [6, 2], grid_size: [1, 4], inputs: [bw_in1_matmul_342_transpose_0, bw_in0_matmul_342_add_344_unsqueeze3_692_squeeze_0], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}
    bw_in1_add_338_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_338_brcst_reduce_sum_0.0, bw_in0_matmul_348_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_336_matmul_1: {type: matmul, grid_loc: [6, 6], grid_size: [2, 2], inputs: [bw_in0_matmul_348_matmul_1, layer.2.attention.self.query.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose], input_0_tms: [hstack: 16],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_336_transpose_0: {type: nop, grid_loc: [5, 4], grid_size: [1, 2], inputs: [e2e_layernorm_333.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_336_matmul_1: {type: matmul, grid_loc: [7, 0], grid_size: [1, 4], inputs: [bw_in1_matmul_336_transpose_0, bw_in0_matmul_348_matmul_1], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16],
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_reshape_334_combine_add_0: {type: add, grid_loc: [7, 5], grid_size: [2, 1], inputs: [bw_in0_matmul_356_matmul_1, bw_in0_matmul_342_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_reshape_334_combine_add_1: {type: add, grid_loc: [8, 0], grid_size: [2, 1], inputs: [bw_in0_reshape_334_combine_add_0, bw_in0_matmul_336_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_333_combine_add_0: {type: add, grid_loc: [8, 1], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9_0, bw_in0_reshape_334_combine_add_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [7, 4], grid_size: [2, 1], inputs: [e2e_layernorm_333.dc.reciprocal.7_0, lc.input_tensor.layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.1.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [5, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.1.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [8, 2], grid_size: [2, 1], inputs: [bw_in0_layernorm_333_combine_add_0, layer.1.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [8, 3], grid_size: [2, 1], inputs: [bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [8, 6], grid_size: [2, 1], inputs: [bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0, e2e_layernorm_333.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [8, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}

  bwd_16:
    target_device: 0
    input_count: 2
    bw_in2_layernorm_333_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_333_layernorm_bw_0.dc.reduce_sum.0.0, e2e_bw_in0_layernorm_333_combine_add_0_0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_333_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [0, 5], grid_size: [2, 1], inputs: [e2e_layernorm_333.dc.multiply.8_0, e2e_bw_in0_layernorm_333_combine_add_0_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_333_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_layernorm_333.dc.multiply.8_0, e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.lc1_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_333_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [0, 1], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1_0, bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [0, 2], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.6, bw_in0_layernorm_333_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_333_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [0, 3], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0_0, bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [0, 4], grid_size: [2, 1], inputs: [e2e_layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0, bw_in0_layernorm_333_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_330_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_330_brcst_reduce_sum_0.0, bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_328_matmul_1: {type: matmul, grid_loc: [2, 0], grid_size: [2, 8], inputs: [bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9, layer.1.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_328_transpose_0: {type: nop, grid_loc: [4, 0], grid_size: [2, 4], inputs: [e2e_gelu_325_0],
         t: 1, mblock: [32, 3], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_328_matmul_1: {type: matmul, grid_loc: [6, 0], grid_size: [2, 8], inputs: [bw_in1_matmul_328_transpose_0, bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [32, 1], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_gelu_325_gelu_derivative_0: {type: gelu_derivative, grid_loc: [8, 0], grid_size: [2, 8], inputs: [e2e_add_324_0],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    bw_in0_gelu_325_multiply_1: {type: multiply, grid_loc: [4, 4], grid_size: [2, 4], inputs: [bw_in0_gelu_325_gelu_derivative_0, bw_in0_matmul_328_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_add_324_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [1, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_324_brcst_reduce_sum_0.0, bw_in0_gelu_325_multiply_1], gradient_op: true,
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 12, u_kt: 1}}

  bwd_17:
    target_device: 0
    input_count: 2
    bw_in0_matmul_322_matmul_1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 8], inputs: [e2e_bw_in0_gelu_325_multiply_1_0, layer.1.intermediate.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 16, u_kt: 8}}
    bw_in1_matmul_322_transpose_0: {type: nop, grid_loc: [2, 0], grid_size: [1, 2], inputs: [e2e_layernorm_319.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_322_matmul_1: {type: matmul, grid_loc: [2, 2], grid_size: [8, 2], inputs: [bw_in1_matmul_322_transpose_0, e2e_bw_in0_gelu_325_multiply_1_0], gradient_op: true,
         t: 1, mblock: [2, 16], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_layernorm_319_combine_add_0: {type: add, grid_loc: [2, 5], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9_0, bw_in0_matmul_322_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in2_layernorm_319_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [6, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_319_layernorm_bw_0.dc.reduce_sum.0.0, bw_in0_layernorm_319_combine_add_0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_319_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [5, 6], grid_size: [2, 1], inputs: [e2e_layernorm_319.dc.multiply.8_0, bw_in0_layernorm_319_combine_add_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [6, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_319_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    layernorm_319.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [2, 1], inputs: [e2e_layernorm_319.dc.reciprocal.7_0, lc.input_tensor.layernorm_319.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.1.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.1.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.1.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [2, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_319_combine_add_0, layer.1.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [3, 0], grid_size: [2, 1], inputs: [bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [3, 1], grid_size: [2, 1], inputs: [bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.0, e2e_layernorm_319.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [3, 6], grid_size: [2, 1], inputs: [bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [4, 4], grid_size: [2, 1], inputs: [e2e_layernorm_319.dc.multiply.8_0, bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.3.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_319_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [4, 5], grid_size: [2, 1], inputs: [bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.lc1, bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [4, 7], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.6, bw_in0_layernorm_319_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_319_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [5, 0], grid_size: [2, 1], inputs: [bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.0, bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [5, 1], grid_size: [2, 1], inputs: [layernorm_319.dc.reciprocal.7_s_brcst_m1_0_0.lc1, bw_in0_layernorm_319_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_316_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_316_brcst_reduce_sum_0.0, bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_314_matmul_1: {type: matmul, grid_loc: [7, 0], grid_size: [2, 2], inputs: [bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9, layer.1.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_314_transpose_0: {type: nop, grid_loc: [7, 4], grid_size: [1, 2], inputs: [e2e_matmul_310_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, vstack: 16]}
    bw_in1_matmul_314_matmul_1: {type: matmul, grid_loc: [8, 4], grid_size: [1, 4], inputs: [bw_in1_matmul_314_transpose_0, bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}

  bwd_18:
    target_device: 0
    input_count: 2
    bw_in0_matmul_310_matmul_1: {type: matmul, grid_loc: [0, 2], grid_size: [2, 1], inputs: [e2e_bw_in0_matmul_314_matmul_1_0, e2e_add_305_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    bw_in1_matmul_310_transpose_0: {type: nop, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_softmax_299.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_310_matmul_1: {type: matmul, grid_loc: [0, 1], grid_size: [2, 1], inputs: [bw_in1_matmul_310_transpose_0, e2e_bw_in0_matmul_314_matmul_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_305_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [0, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_305_brcst_reduce_sum_0.0, bw_in1_matmul_310_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_303_add_305_unsqueeze3_662_squeeze_0: {type: nop, grid_loc: [0, 4], grid_size: [2, 1], inputs: [bw_in1_matmul_310_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 16]}
    bw_in0_matmul_303_matmul_1: {type: matmul, grid_loc: [0, 5], grid_size: [2, 2], inputs: [bw_in0_matmul_303_add_305_unsqueeze3_662_squeeze_0, layer.1.attention.self.value.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_303_transpose_0: {type: nop, grid_loc: [2, 0], grid_size: [1, 2], inputs: [e2e_layernorm_280.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_303_matmul_1: {type: matmul, grid_loc: [2, 2], grid_size: [1, 4], inputs: [bw_in1_matmul_303_transpose_0, bw_in0_matmul_303_add_305_unsqueeze3_662_squeeze_0], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_softmax_299_softmax_bw_0.dc.multiply.0: {type: multiply, grid_loc: [0, 7], grid_size: [2, 1], inputs: [bw_in0_matmul_310_matmul_1, e2e_softmax_299.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    lc.input_tensor.bw_in0_softmax_299_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [1, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in0_softmax_299_softmax_bw_0.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    bw_in0_softmax_299_softmax_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [2, 1], inputs: [bw_in0_softmax_299_softmax_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_softmax_299_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}
    bw_in0_softmax_299_softmax_bw_0.dc.subtract.2: {type: subtract, grid_loc: [2, 7], grid_size: [2, 1], inputs: [bw_in0_matmul_310_matmul_1, bw_in0_softmax_299_softmax_bw_0.dc.reduce_sum.1.lc1],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [232, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    bw_in0_softmax_299_softmax_bw_0.dc.multiply.3: {type: multiply, grid_loc: [3, 0], grid_size: [2, 1], inputs: [bw_in0_softmax_299_softmax_bw_0.dc.subtract.2, e2e_softmax_299.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_1_multiply_297_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [3, 1], grid_size: [1, 1], inputs: [input_1_multiply_297_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_297_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [3, 2], grid_size: [1, 1], inputs: [input_1_multiply_297_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    bw_in0_multiply_297_multiply_0: {type: multiply, grid_loc: [3, 3], grid_size: [2, 1], inputs: [bw_in0_softmax_299_softmax_bw_0.dc.multiply.3, input_1_multiply_297_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_matmul_295_matmul_1: {type: matmul, grid_loc: [3, 5], grid_size: [2, 1], inputs: [bw_in0_multiply_297_multiply_0, e2e_add_291_0],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_matmul_295_transpose_0: {type: nop, grid_loc: [3, 4], grid_size: [1, 1], inputs: [e2e_add_285_0],
         t: 16, mblock: [1, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hslice: 16, transpose]}
    bw_in1_matmul_295_matmul_1: {type: matmul, grid_loc: [4, 1], grid_size: [1, 2], inputs: [bw_in1_matmul_295_transpose_0, bw_in0_multiply_297_multiply_0],
         t: 16, mblock: [1, 3], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_291_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [4, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_291_brcst_reduce_sum_0.0, bw_in1_matmul_295_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose, hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_289_add_291_unsqueeze3_650_squeeze_0: {type: nop, grid_loc: [4, 6], grid_size: [2, 1], inputs: [bw_in1_matmul_295_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, hstack: 16]}
    bw_in0_matmul_289_matmul_1: {type: matmul, grid_loc: [5, 0], grid_size: [2, 2], inputs: [bw_in0_matmul_289_add_291_unsqueeze3_650_squeeze_0, layer.1.attention.self.key.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_289_transpose_0: {type: nop, grid_loc: [5, 2], grid_size: [1, 2], inputs: [e2e_layernorm_280.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_289_matmul_1: {type: matmul, grid_loc: [6, 2], grid_size: [1, 4], inputs: [bw_in1_matmul_289_transpose_0, bw_in0_matmul_289_add_291_unsqueeze3_650_squeeze_0], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}
    bw_in1_add_285_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_285_brcst_reduce_sum_0.0, bw_in0_matmul_295_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_283_matmul_1: {type: matmul, grid_loc: [6, 6], grid_size: [2, 2], inputs: [bw_in0_matmul_295_matmul_1, layer.1.attention.self.query.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose], input_0_tms: [hstack: 16],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_283_transpose_0: {type: nop, grid_loc: [5, 4], grid_size: [1, 2], inputs: [e2e_layernorm_280.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_283_matmul_1: {type: matmul, grid_loc: [7, 0], grid_size: [1, 4], inputs: [bw_in1_matmul_283_transpose_0, bw_in0_matmul_295_matmul_1], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16],
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_reshape_281_combine_add_0: {type: add, grid_loc: [7, 5], grid_size: [2, 1], inputs: [bw_in0_matmul_303_matmul_1, bw_in0_matmul_289_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_reshape_281_combine_add_1: {type: add, grid_loc: [8, 0], grid_size: [2, 1], inputs: [bw_in0_reshape_281_combine_add_0, bw_in0_matmul_283_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_280_combine_add_0: {type: add, grid_loc: [8, 1], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9_0, bw_in0_reshape_281_combine_add_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [7, 4], grid_size: [2, 1], inputs: [e2e_layernorm_280.dc.reciprocal.7_0, lc.input_tensor.layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.0.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [5, 7], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.0.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [8, 2], grid_size: [2, 1], inputs: [bw_in0_layernorm_280_combine_add_0, layer.0.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [8, 3], grid_size: [2, 1], inputs: [bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [8, 6], grid_size: [2, 1], inputs: [bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0, e2e_layernorm_280.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [8, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}

  bwd_19:
    target_device: 0
    input_count: 2
    bw_in2_layernorm_280_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_280_layernorm_bw_0.dc.reduce_sum.0.0, e2e_bw_in0_layernorm_280_combine_add_0_0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_280_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [0, 5], grid_size: [2, 1], inputs: [e2e_layernorm_280.dc.multiply.8_0, e2e_bw_in0_layernorm_280_combine_add_0_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_280_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_layernorm_280.dc.multiply.8_0, e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.lc1_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_280_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [0, 1], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1_0, bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [0, 2], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.6, bw_in0_layernorm_280_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_280_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [0, 3], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0_0, bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [0, 4], grid_size: [2, 1], inputs: [e2e_layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0, bw_in0_layernorm_280_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_277_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_277_brcst_reduce_sum_0.0, bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_275_matmul_1: {type: matmul, grid_loc: [2, 0], grid_size: [2, 8], inputs: [bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9, layer.0.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_275_transpose_0: {type: nop, grid_loc: [4, 0], grid_size: [2, 4], inputs: [e2e_gelu_272_0],
         t: 1, mblock: [32, 3], ublock: [2, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_275_matmul_1: {type: matmul, grid_loc: [6, 0], grid_size: [2, 8], inputs: [bw_in1_matmul_275_transpose_0, bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [32, 1], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_gelu_272_gelu_derivative_0: {type: gelu_derivative, grid_loc: [8, 0], grid_size: [2, 8], inputs: [e2e_add_271_0],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {approximate_mode: false}}
    bw_in0_gelu_272_multiply_1: {type: multiply, grid_loc: [4, 4], grid_size: [2, 4], inputs: [bw_in0_gelu_272_gelu_derivative_0, bw_in0_matmul_275_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_add_271_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [1, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_271_brcst_reduce_sum_0.0, bw_in0_gelu_272_multiply_1], gradient_op: true,
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 12, u_kt: 1}}

  bwd_20:
    target_device: 0
    input_count: 2
    bw_in0_matmul_269_matmul_1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 8], inputs: [e2e_bw_in0_gelu_272_multiply_1_0, layer.0.intermediate.dense.weight],
         t: 1, mblock: [3, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 16, u_kt: 8}}
    bw_in1_matmul_269_transpose_0: {type: nop, grid_loc: [2, 0], grid_size: [1, 2], inputs: [e2e_layernorm_266.dc.add.10_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_269_matmul_1: {type: matmul, grid_loc: [2, 2], grid_size: [8, 2], inputs: [bw_in1_matmul_269_transpose_0, e2e_bw_in0_gelu_272_multiply_1_0], gradient_op: true,
         t: 1, mblock: [2, 16], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 12, u_kt: 1}}
    bw_in0_layernorm_266_combine_add_0: {type: add, grid_loc: [2, 5], grid_size: [2, 1], inputs: [e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9_0, bw_in0_matmul_269_matmul_1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in2_layernorm_266_layernorm_bw_0.dc.reduce_sum.0.lc1: {type: matmul, grid_loc: [6, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in2_layernorm_266_layernorm_bw_0.dc.reduce_sum.0.0, bw_in0_layernorm_266_combine_add_0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_layernorm_266_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [5, 6], grid_size: [2, 1], inputs: [e2e_layernorm_266.dc.multiply.8_0, bw_in0_layernorm_266_combine_add_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in1_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [6, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.0, bw_in1_layernorm_266_layernorm_bw_0.dc.multiply.0], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    layernorm_266.dc.reciprocal.7_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [2, 1], inputs: [e2e_layernorm_266.dc.reciprocal.7_0, lc.input_tensor.layernorm_266.dc.reciprocal.7_s_brcst_m1_0_0.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layer.0.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.layer.0.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0, layer.0.attention.output.LayerNorm.weight],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.0: {type: multiply, grid_loc: [2, 7], grid_size: [2, 1], inputs: [bw_in0_layernorm_266_combine_add_0, layer.0.attention.output.LayerNorm.weight_s_brcst_m2_2_0.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [3, 0], grid_size: [2, 1], inputs: [bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.2: {type: multiply, grid_loc: [3, 1], grid_size: [2, 1], inputs: [bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.0, e2e_layernorm_266.dc.multiply.8_0],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.3.lc1: {type: matmul, grid_loc: [3, 6], grid_size: [2, 1], inputs: [bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.2, lc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.3.0],
         t: 1, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}],
         attributes: {m_k: 1, u_kt: 32}}
    bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.4: {type: multiply, grid_loc: [4, 4], grid_size: [2, 1], inputs: [e2e_layernorm_266.dc.multiply.8_0, bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.3.lc1],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_266_layernorm_bw_0.dc.add.5: {type: add, grid_loc: [4, 5], grid_size: [2, 1], inputs: [bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.lc1, bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.4],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.7: {type: multiply, grid_loc: [4, 7], grid_size: [2, 1], inputs: [dc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.6, bw_in0_layernorm_266_layernorm_bw_0.dc.add.5],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_266_layernorm_bw_0.dc.subtract.8: {type: subtract, grid_loc: [5, 0], grid_size: [2, 1], inputs: [bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.0, bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.7],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [104, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.9: {type: multiply, grid_loc: [5, 1], grid_size: [2, 1], inputs: [layernorm_266.dc.reciprocal.7_s_brcst_m1_0_0.lc1, bw_in0_layernorm_266_layernorm_bw_0.dc.subtract.8],
         t: 1, mblock: [3, 8], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    bw_in1_add_263_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_263_brcst_reduce_sum_0.0, bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in0_matmul_261_matmul_1: {type: matmul, grid_loc: [7, 0], grid_size: [2, 2], inputs: [bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.9, layer.0.attention.output.dense.weight],
         t: 1, mblock: [3, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose],
         attributes: {m_k: 32, u_kt: 1}}
    bw_in1_matmul_261_transpose_0: {type: nop, grid_loc: [7, 4], grid_size: [1, 2], inputs: [e2e_matmul_257_0],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose, vstack: 16]}
    bw_in1_matmul_261_matmul_1: {type: matmul, grid_loc: [8, 4], grid_size: [1, 4], inputs: [bw_in1_matmul_261_transpose_0, bw_in0_layernorm_266_layernorm_bw_0.dc.multiply.9], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 4, u_kt: 3}}

  bwd_21:
    target_device: 0
    input_count: 2
    bw_in0_matmul_257_matmul_1: {type: matmul, grid_loc: [0, 0], grid_size: [2, 1], inputs: [e2e_bw_in0_matmul_261_matmul_1_0, e2e_add_252_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16, transpose], input_0_tms: [hslice: 16],
         attributes: {m_k: 1, u_kt: 2}}
    bw_in1_matmul_257_transpose_0: {type: nop, grid_loc: [0, 1], grid_size: [2, 1], inputs: [e2e_softmax_246.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_257_matmul_1: {type: matmul, grid_loc: [0, 2], grid_size: [2, 1], inputs: [bw_in1_matmul_257_transpose_0, e2e_bw_in0_matmul_261_matmul_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_252_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [0, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_252_brcst_reduce_sum_0.0, bw_in1_matmul_257_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_matmul_250_transpose_0: {type: nop, grid_loc: [3, 3], grid_size: [1, 2], inputs: [hidden_states],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_250_matmul_1: {type: matmul, grid_loc: [4, 0], grid_size: [1, 4], inputs: [bw_in1_matmul_250_transpose_0, bw_in1_matmul_257_matmul_1], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16],
         attributes: {m_k: 4, u_kt: 3}}
    bw_in0_softmax_246_softmax_bw_0.dc.multiply.0: {type: multiply, grid_loc: [0, 4], grid_size: [2, 1], inputs: [bw_in0_matmul_257_matmul_1, e2e_softmax_246.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    lc.input_tensor.bw_in0_softmax_246_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0: {type: nop, grid_loc: [0, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in0_softmax_246_softmax_bw_0.dc.reduce_sum.1.0],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    bw_in0_softmax_246_softmax_bw_0.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [2, 1], inputs: [bw_in0_softmax_246_softmax_bw_0.dc.multiply.0, lc.input_tensor.bw_in0_softmax_246_softmax_bw_0.dc.reduce_sum.1.0_splt_brcst_1_0],
         t: 16, mblock: [3, 1], ublock: [2, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}],
         attributes: {m_k: 1, u_kt: 12}}
    bw_in0_softmax_246_softmax_bw_0.dc.subtract.2: {type: subtract, grid_loc: [0, 7], grid_size: [2, 1], inputs: [bw_in0_matmul_257_matmul_1, bw_in0_softmax_246_softmax_bw_0.dc.reduce_sum.1.lc1],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, input_buf_min_size_tiles: [232, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 12}]}
    bw_in0_softmax_246_softmax_bw_0.dc.multiply.3: {type: multiply, grid_loc: [1, 3], grid_size: [2, 1], inputs: [bw_in0_softmax_246_softmax_bw_0.dc.subtract.2, e2e_softmax_246.dc.multiply.3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_1_multiply_244_tile_bcast_tile_bcast_splt_brcst_1_0: {type: nop, grid_loc: [1, 5], grid_size: [1, 1], inputs: [input_1_multiply_244_tile_bcast_tile_bcast],
         t: 16, mblock: [1, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {z: 16}]}
    input_1_multiply_244_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0: {type: nop, grid_loc: [2, 0], grid_size: [1, 1], inputs: [input_1_multiply_244_tile_bcast_tile_bcast_splt_brcst_1_0],
         t: 16, mblock: [1, 3], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 12}]}
    bw_in0_multiply_244_multiply_0: {type: multiply, grid_loc: [2, 1], grid_size: [2, 1], inputs: [bw_in0_softmax_246_softmax_bw_0.dc.multiply.3, input_1_multiply_244_tile_bcast_tile_bcast_splt_brcst_1_0_splt_brcst_3_0],
         t: 16, mblock: [3, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 12}]}
    bw_in0_matmul_242_matmul_1: {type: matmul, grid_loc: [2, 2], grid_size: [2, 1], inputs: [bw_in0_multiply_244_multiply_0, e2e_add_238_0],
         t: 16, mblock: [3, 1], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 16],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_matmul_242_transpose_0: {type: nop, grid_loc: [2, 4], grid_size: [1, 1], inputs: [e2e_add_232_0],
         t: 16, mblock: [1, 3], ublock: [2, 4], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hslice: 16, transpose]}
    bw_in1_matmul_242_matmul_1: {type: matmul, grid_loc: [2, 5], grid_size: [1, 2], inputs: [bw_in1_matmul_242_transpose_0, bw_in0_multiply_244_multiply_0],
         t: 16, mblock: [1, 3], ublock: [2, 2], buf_size_mb: 32, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_add_238_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_238_brcst_reduce_sum_0.0, bw_in1_matmul_242_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose, hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_matmul_236_transpose_0: {type: nop, grid_loc: [3, 5], grid_size: [1, 2], inputs: [hidden_states],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_236_matmul_1: {type: matmul, grid_loc: [4, 4], grid_size: [1, 4], inputs: [bw_in1_matmul_236_transpose_0, bw_in1_matmul_242_matmul_1], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [transpose, hstack: 16],
         attributes: {m_k: 4, u_kt: 3}}
    bw_in1_add_232_brcst_reduce_sum_0.lc1: {type: matmul, grid_loc: [3, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bw_in1_add_232_brcst_reduce_sum_0.0, bw_in0_matmul_242_matmul_1], gradient_op: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16], input_0_tms: [broadcast: {c: 12}],
         attributes: {m_k: 2, u_kt: 6}}
    bw_in1_matmul_230_transpose_0: {type: nop, grid_loc: [5, 0], grid_size: [1, 2], inputs: [hidden_states],
         t: 1, mblock: [16, 3], ublock: [2, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [transpose]}
    bw_in1_matmul_230_matmul_1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 4], inputs: [bw_in1_matmul_230_transpose_0, bw_in0_matmul_242_matmul_1], gradient_op: true,
         t: 1, mblock: [16, 2], ublock: [2, 4], buf_size_mb: 1, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hstack: 16],
         attributes: {m_k: 4, u_kt: 3}}

  opt_22:
    target_device: 0
    input_count: 1
    input_opt_layer.0.attention.self.query.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [0, 0], grid_size: [1, 1], inputs: [input_opt_layer.0.attention.self.query.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.self.query.weight_multiply_1: {type: multiply, grid_loc: [1, 0], grid_size: [1, 8], inputs: [grad_acc_layer.0.attention.self.query.weight, input_opt_layer.0.attention.self.query.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in1_layer.0.attention.self.query.weight_subtract_2: {type: subtract, grid_loc: [2, 0], grid_size: [1, 8], inputs: [layer.0.attention.self.query.weight, opt_in1_layer.0.attention.self.query.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.attention.self.query.bias_multiply_1: {type: multiply, grid_loc: [0, 3], grid_size: [1, 1], inputs: [grad_acc_layer.0.attention.self.query.bias, input_opt_layer.0.attention.self.query.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.self.query.bias_subtract_2: {type: subtract, grid_loc: [0, 4], grid_size: [1, 1], inputs: [layer.0.attention.self.query.bias, opt_in1_layer.0.attention.self.query.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.0.attention.self.key.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [0, 1], grid_size: [1, 1], inputs: [input_opt_layer.0.attention.self.key.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.self.key.weight_multiply_1: {type: multiply, grid_loc: [3, 0], grid_size: [1, 8], inputs: [grad_acc_layer.0.attention.self.key.weight, input_opt_layer.0.attention.self.key.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in1_layer.0.attention.self.key.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [1, 8], inputs: [layer.0.attention.self.key.weight, opt_in1_layer.0.attention.self.key.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.attention.self.key.bias_multiply_1: {type: multiply, grid_loc: [0, 5], grid_size: [1, 1], inputs: [grad_acc_layer.0.attention.self.key.bias, input_opt_layer.0.attention.self.key.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.self.key.bias_subtract_2: {type: subtract, grid_loc: [0, 6], grid_size: [1, 1], inputs: [layer.0.attention.self.key.bias, opt_in1_layer.0.attention.self.key.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.0.attention.self.value.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [0, 2], grid_size: [1, 1], inputs: [input_opt_layer.0.attention.self.value.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.self.value.weight_multiply_1: {type: multiply, grid_loc: [5, 0], grid_size: [1, 8], inputs: [grad_acc_layer.0.attention.self.value.weight, input_opt_layer.0.attention.self.value.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in1_layer.0.attention.self.value.weight_subtract_2: {type: subtract, grid_loc: [6, 0], grid_size: [1, 8], inputs: [layer.0.attention.self.value.weight, opt_in1_layer.0.attention.self.value.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.attention.self.value.bias_multiply_1: {type: multiply, grid_loc: [0, 7], grid_size: [1, 1], inputs: [grad_acc_layer.0.attention.self.value.bias, input_opt_layer.0.attention.self.value.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.self.value.bias_subtract_2: {type: subtract, grid_loc: [7, 0], grid_size: [1, 1], inputs: [layer.0.attention.self.value.bias, opt_in1_layer.0.attention.self.value.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.0.attention.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [7, 1], grid_size: [1, 1], inputs: [input_opt_layer.0.attention.output.dense.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.0.attention.output.dense.weight_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 8], inputs: [grad_acc_layer.0.attention.output.dense.weight, input_opt_layer.0.attention.output.dense.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.0.attention.output.dense.weight_subtract_2: {type: subtract, grid_loc: [9, 0], grid_size: [1, 8], inputs: [layer.0.attention.output.dense.weight, opt_in0_layer.0.attention.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.attention.output.dense.bias_multiply_1: {type: multiply, grid_loc: [7, 2], grid_size: [1, 1], inputs: [grad_acc_layer.0.attention.output.dense.bias, input_opt_layer.0.attention.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.output.dense.bias_subtract_2: {type: subtract, grid_loc: [7, 3], grid_size: [1, 1], inputs: [layer.0.attention.output.dense.bias, opt_in1_layer.0.attention.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.attention.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [7, 4], grid_size: [1, 1], inputs: [grad_acc_layer.0.attention.output.LayerNorm.weight, input_opt_layer.0.attention.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.attention.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [7, 5], grid_size: [1, 1], inputs: [layer.0.attention.output.LayerNorm.weight, opt_in1_layer.0.attention.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.0.attention.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [7, 6], grid_size: [1, 1], inputs: [grad_acc_layer.0.attention.output.LayerNorm.bias, input_opt_layer.0.attention.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.0.attention.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [7, 7], grid_size: [1, 1], inputs: [layer.0.attention.output.LayerNorm.bias, opt_in2_layer.0.attention.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  opt_23:
    target_device: 0
    input_count: 1
    input_opt_layer.0.intermediate.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [0, 0], grid_size: [1, 2], inputs: [input_opt_layer.0.intermediate.dense.weight_0.lr],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 128}]}
    opt_in0_layer.0.intermediate.dense.weight_multiply_1: {type: multiply, grid_loc: [1, 0], grid_size: [4, 8], inputs: [grad_acc_layer.0.intermediate.dense.weight, input_opt_layer.0.intermediate.dense.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.0.intermediate.dense.weight_subtract_2: {type: subtract, grid_loc: [5, 0], grid_size: [4, 8], inputs: [layer.0.intermediate.dense.weight, opt_in0_layer.0.intermediate.dense.weight_multiply_1],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.intermediate.dense.bias_multiply_1: {type: multiply, grid_loc: [0, 2], grid_size: [1, 1], inputs: [grad_acc_layer.0.intermediate.dense.bias, input_opt_layer.0.intermediate.dense.bias_0.lr],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 128}]}
    opt_in1_layer.0.intermediate.dense.bias_subtract_2: {type: subtract, grid_loc: [0, 3], grid_size: [1, 1], inputs: [layer.0.intermediate.dense.bias, opt_in1_layer.0.intermediate.dense.bias_multiply_1],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.0.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [0, 4], grid_size: [1, 2], inputs: [input_opt_layer.0.output.dense.weight_0.lr],
         t: 1, mblock: [1, 4], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}

  opt_24:
    target_device: 0
    input_count: 1
    opt_in0_layer.0.output.dense.weight_multiply_1: {type: multiply, grid_loc: [0, 0], grid_size: [4, 8], inputs: [grad_acc_layer.0.output.dense.weight, e2e_input_opt_layer.0.output.dense.weight_0.lr_splt_brcst_3_0_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 128}]}
    opt_in0_layer.0.output.dense.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [4, 8], inputs: [layer.0.output.dense.weight, opt_in0_layer.0.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.output.dense.bias_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [grad_acc_layer.0.output.dense.bias, input_opt_layer.0.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.output.dense.bias_subtract_2: {type: subtract, grid_loc: [8, 1], grid_size: [1, 1], inputs: [layer.0.output.dense.bias, opt_in1_layer.0.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.0.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [8, 2], grid_size: [1, 1], inputs: [grad_acc_layer.0.output.LayerNorm.weight, input_opt_layer.0.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.0.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [8, 3], grid_size: [1, 1], inputs: [layer.0.output.LayerNorm.weight, opt_in1_layer.0.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.0.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [8, 4], grid_size: [1, 1], inputs: [grad_acc_layer.0.output.LayerNorm.bias, input_opt_layer.0.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.0.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [8, 5], grid_size: [1, 1], inputs: [layer.0.output.LayerNorm.bias, opt_in2_layer.0.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.1.attention.self.query.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [8, 6], grid_size: [1, 1], inputs: [input_opt_layer.1.attention.self.query.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.1.attention.self.query.weight_multiply_1: {type: multiply, grid_loc: [9, 0], grid_size: [1, 8], inputs: [grad_acc_layer.1.attention.self.query.weight, input_opt_layer.1.attention.self.query.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}

  opt_25:
    target_device: 0
    input_count: 1
    opt_in0_layer.1.attention.self.query.weight_subtract_2: {type: subtract, grid_loc: [0, 0], grid_size: [1, 8], inputs: [layer.1.attention.self.query.weight, e2e_opt_in0_layer.1.attention.self.query.weight_multiply_1_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.attention.self.query.bias_multiply_1: {type: multiply, grid_loc: [1, 0], grid_size: [1, 1], inputs: [grad_acc_layer.1.attention.self.query.bias, input_opt_layer.1.attention.self.query.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.1.attention.self.query.bias_subtract_2: {type: subtract, grid_loc: [1, 1], grid_size: [1, 1], inputs: [layer.1.attention.self.query.bias, opt_in1_layer.1.attention.self.query.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.1.attention.self.key.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [1, 2], grid_size: [1, 1], inputs: [input_opt_layer.1.attention.self.key.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.1.attention.self.key.weight_multiply_1: {type: multiply, grid_loc: [2, 0], grid_size: [1, 8], inputs: [grad_acc_layer.1.attention.self.key.weight, input_opt_layer.1.attention.self.key.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.1.attention.self.key.weight_subtract_2: {type: subtract, grid_loc: [3, 0], grid_size: [1, 8], inputs: [layer.1.attention.self.key.weight, opt_in0_layer.1.attention.self.key.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.attention.self.key.bias_multiply_1: {type: multiply, grid_loc: [1, 3], grid_size: [1, 1], inputs: [grad_acc_layer.1.attention.self.key.bias, input_opt_layer.1.attention.self.key.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.1.attention.self.key.bias_subtract_2: {type: subtract, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layer.1.attention.self.key.bias, opt_in1_layer.1.attention.self.key.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.1.attention.self.value.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [1, 5], grid_size: [1, 1], inputs: [input_opt_layer.1.attention.self.value.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.1.attention.self.value.weight_multiply_1: {type: multiply, grid_loc: [4, 0], grid_size: [1, 8], inputs: [grad_acc_layer.1.attention.self.value.weight, input_opt_layer.1.attention.self.value.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.1.attention.self.value.weight_subtract_2: {type: subtract, grid_loc: [5, 0], grid_size: [1, 8], inputs: [layer.1.attention.self.value.weight, opt_in0_layer.1.attention.self.value.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.attention.self.value.bias_multiply_1: {type: multiply, grid_loc: [1, 6], grid_size: [1, 1], inputs: [grad_acc_layer.1.attention.self.value.bias, input_opt_layer.1.attention.self.value.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.1.attention.self.value.bias_subtract_2: {type: subtract, grid_loc: [1, 7], grid_size: [1, 1], inputs: [layer.1.attention.self.value.bias, opt_in1_layer.1.attention.self.value.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.1.attention.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [6, 0], grid_size: [1, 1], inputs: [input_opt_layer.1.attention.output.dense.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.1.attention.output.dense.weight_multiply_1: {type: multiply, grid_loc: [7, 0], grid_size: [1, 8], inputs: [grad_acc_layer.1.attention.output.dense.weight, input_opt_layer.1.attention.output.dense.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.1.attention.output.dense.weight_subtract_2: {type: subtract, grid_loc: [8, 0], grid_size: [1, 8], inputs: [layer.1.attention.output.dense.weight, opt_in0_layer.1.attention.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.attention.output.dense.bias_multiply_1: {type: multiply, grid_loc: [6, 1], grid_size: [1, 1], inputs: [grad_acc_layer.1.attention.output.dense.bias, input_opt_layer.1.attention.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.1.attention.output.dense.bias_subtract_2: {type: subtract, grid_loc: [6, 2], grid_size: [1, 1], inputs: [layer.1.attention.output.dense.bias, opt_in1_layer.1.attention.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.attention.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [6, 3], grid_size: [1, 1], inputs: [grad_acc_layer.1.attention.output.LayerNorm.weight, input_opt_layer.1.attention.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.1.attention.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [6, 4], grid_size: [1, 1], inputs: [layer.1.attention.output.LayerNorm.weight, opt_in1_layer.1.attention.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.1.attention.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [6, 5], grid_size: [1, 1], inputs: [grad_acc_layer.1.attention.output.LayerNorm.bias, input_opt_layer.1.attention.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.1.attention.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [6, 6], grid_size: [1, 1], inputs: [layer.1.attention.output.LayerNorm.bias, opt_in2_layer.1.attention.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.1.intermediate.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [9, 0], grid_size: [1, 2], inputs: [input_opt_layer.1.intermediate.dense.weight_0.lr],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 128}]}

  opt_26:
    target_device: 0
    input_count: 1
    opt_in0_layer.1.intermediate.dense.weight_multiply_1: {type: multiply, grid_loc: [0, 0], grid_size: [4, 8], inputs: [grad_acc_layer.1.intermediate.dense.weight, e2e_input_opt_layer.1.intermediate.dense.weight_0.lr_splt_brcst_3_0_0],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.1.intermediate.dense.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [4, 8], inputs: [layer.1.intermediate.dense.weight, opt_in0_layer.1.intermediate.dense.weight_multiply_1],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.intermediate.dense.bias_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [grad_acc_layer.1.intermediate.dense.bias, input_opt_layer.1.intermediate.dense.bias_0.lr],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 128}]}
    opt_in1_layer.1.intermediate.dense.bias_subtract_2: {type: subtract, grid_loc: [8, 1], grid_size: [1, 1], inputs: [layer.1.intermediate.dense.bias, opt_in1_layer.1.intermediate.dense.bias_multiply_1],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.1.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [8, 2], grid_size: [1, 2], inputs: [input_opt_layer.1.output.dense.weight_0.lr],
         t: 1, mblock: [1, 4], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}

  opt_27:
    target_device: 0
    input_count: 1
    opt_in0_layer.1.output.dense.weight_multiply_1: {type: multiply, grid_loc: [0, 0], grid_size: [4, 8], inputs: [grad_acc_layer.1.output.dense.weight, e2e_input_opt_layer.1.output.dense.weight_0.lr_splt_brcst_3_0_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 128}]}
    opt_in0_layer.1.output.dense.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [4, 8], inputs: [layer.1.output.dense.weight, opt_in0_layer.1.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.output.dense.bias_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [grad_acc_layer.1.output.dense.bias, input_opt_layer.1.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.1.output.dense.bias_subtract_2: {type: subtract, grid_loc: [8, 1], grid_size: [1, 1], inputs: [layer.1.output.dense.bias, opt_in1_layer.1.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.1.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [8, 2], grid_size: [1, 1], inputs: [grad_acc_layer.1.output.LayerNorm.weight, input_opt_layer.1.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.1.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [8, 3], grid_size: [1, 1], inputs: [layer.1.output.LayerNorm.weight, opt_in1_layer.1.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.1.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [8, 4], grid_size: [1, 1], inputs: [grad_acc_layer.1.output.LayerNorm.bias, input_opt_layer.1.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.1.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [8, 5], grid_size: [1, 1], inputs: [layer.1.output.LayerNorm.bias, opt_in2_layer.1.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.2.attention.self.query.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [8, 6], grid_size: [1, 1], inputs: [input_opt_layer.2.attention.self.query.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.2.attention.self.query.weight_multiply_1: {type: multiply, grid_loc: [9, 0], grid_size: [1, 8], inputs: [grad_acc_layer.2.attention.self.query.weight, input_opt_layer.2.attention.self.query.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}

  opt_28:
    target_device: 0
    input_count: 1
    opt_in0_layer.2.attention.self.query.weight_subtract_2: {type: subtract, grid_loc: [0, 0], grid_size: [1, 8], inputs: [layer.2.attention.self.query.weight, e2e_opt_in0_layer.2.attention.self.query.weight_multiply_1_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.attention.self.query.bias_multiply_1: {type: multiply, grid_loc: [1, 0], grid_size: [1, 1], inputs: [grad_acc_layer.2.attention.self.query.bias, input_opt_layer.2.attention.self.query.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.2.attention.self.query.bias_subtract_2: {type: subtract, grid_loc: [1, 1], grid_size: [1, 1], inputs: [layer.2.attention.self.query.bias, opt_in1_layer.2.attention.self.query.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.2.attention.self.key.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [1, 2], grid_size: [1, 1], inputs: [input_opt_layer.2.attention.self.key.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.2.attention.self.key.weight_multiply_1: {type: multiply, grid_loc: [2, 0], grid_size: [1, 8], inputs: [grad_acc_layer.2.attention.self.key.weight, input_opt_layer.2.attention.self.key.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.2.attention.self.key.weight_subtract_2: {type: subtract, grid_loc: [3, 0], grid_size: [1, 8], inputs: [layer.2.attention.self.key.weight, opt_in0_layer.2.attention.self.key.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.attention.self.key.bias_multiply_1: {type: multiply, grid_loc: [1, 3], grid_size: [1, 1], inputs: [grad_acc_layer.2.attention.self.key.bias, input_opt_layer.2.attention.self.key.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.2.attention.self.key.bias_subtract_2: {type: subtract, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layer.2.attention.self.key.bias, opt_in1_layer.2.attention.self.key.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.2.attention.self.value.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [1, 5], grid_size: [1, 1], inputs: [input_opt_layer.2.attention.self.value.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.2.attention.self.value.weight_multiply_1: {type: multiply, grid_loc: [4, 0], grid_size: [1, 8], inputs: [grad_acc_layer.2.attention.self.value.weight, input_opt_layer.2.attention.self.value.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.2.attention.self.value.weight_subtract_2: {type: subtract, grid_loc: [5, 0], grid_size: [1, 8], inputs: [layer.2.attention.self.value.weight, opt_in0_layer.2.attention.self.value.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.attention.self.value.bias_multiply_1: {type: multiply, grid_loc: [1, 6], grid_size: [1, 1], inputs: [grad_acc_layer.2.attention.self.value.bias, input_opt_layer.2.attention.self.value.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.2.attention.self.value.bias_subtract_2: {type: subtract, grid_loc: [1, 7], grid_size: [1, 1], inputs: [layer.2.attention.self.value.bias, opt_in1_layer.2.attention.self.value.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.2.attention.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [6, 0], grid_size: [1, 1], inputs: [input_opt_layer.2.attention.output.dense.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.2.attention.output.dense.weight_multiply_1: {type: multiply, grid_loc: [7, 0], grid_size: [1, 8], inputs: [grad_acc_layer.2.attention.output.dense.weight, input_opt_layer.2.attention.output.dense.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.2.attention.output.dense.weight_subtract_2: {type: subtract, grid_loc: [8, 0], grid_size: [1, 8], inputs: [layer.2.attention.output.dense.weight, opt_in0_layer.2.attention.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.attention.output.dense.bias_multiply_1: {type: multiply, grid_loc: [6, 1], grid_size: [1, 1], inputs: [grad_acc_layer.2.attention.output.dense.bias, input_opt_layer.2.attention.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.2.attention.output.dense.bias_subtract_2: {type: subtract, grid_loc: [6, 2], grid_size: [1, 1], inputs: [layer.2.attention.output.dense.bias, opt_in1_layer.2.attention.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.attention.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [6, 3], grid_size: [1, 1], inputs: [grad_acc_layer.2.attention.output.LayerNorm.weight, input_opt_layer.2.attention.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.2.attention.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [6, 4], grid_size: [1, 1], inputs: [layer.2.attention.output.LayerNorm.weight, opt_in1_layer.2.attention.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.2.attention.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [6, 5], grid_size: [1, 1], inputs: [grad_acc_layer.2.attention.output.LayerNorm.bias, input_opt_layer.2.attention.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.2.attention.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [6, 6], grid_size: [1, 1], inputs: [layer.2.attention.output.LayerNorm.bias, opt_in2_layer.2.attention.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.2.intermediate.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [9, 0], grid_size: [1, 2], inputs: [input_opt_layer.2.intermediate.dense.weight_0.lr],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 128}]}

  opt_29:
    target_device: 0
    input_count: 1
    opt_in0_layer.2.intermediate.dense.weight_multiply_1: {type: multiply, grid_loc: [0, 0], grid_size: [4, 8], inputs: [grad_acc_layer.2.intermediate.dense.weight, e2e_input_opt_layer.2.intermediate.dense.weight_0.lr_splt_brcst_3_0_0],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.2.intermediate.dense.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [4, 8], inputs: [layer.2.intermediate.dense.weight, opt_in0_layer.2.intermediate.dense.weight_multiply_1],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.intermediate.dense.bias_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [grad_acc_layer.2.intermediate.dense.bias, input_opt_layer.2.intermediate.dense.bias_0.lr],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 128}]}
    opt_in1_layer.2.intermediate.dense.bias_subtract_2: {type: subtract, grid_loc: [8, 1], grid_size: [1, 1], inputs: [layer.2.intermediate.dense.bias, opt_in1_layer.2.intermediate.dense.bias_multiply_1],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.2.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [8, 2], grid_size: [1, 2], inputs: [input_opt_layer.2.output.dense.weight_0.lr],
         t: 1, mblock: [1, 4], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}

  opt_30:
    target_device: 0
    input_count: 1
    opt_in0_layer.2.output.dense.weight_multiply_1: {type: multiply, grid_loc: [0, 0], grid_size: [4, 8], inputs: [grad_acc_layer.2.output.dense.weight, e2e_input_opt_layer.2.output.dense.weight_0.lr_splt_brcst_3_0_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 128}]}
    opt_in0_layer.2.output.dense.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [4, 8], inputs: [layer.2.output.dense.weight, opt_in0_layer.2.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.output.dense.bias_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [grad_acc_layer.2.output.dense.bias, input_opt_layer.2.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.2.output.dense.bias_subtract_2: {type: subtract, grid_loc: [8, 1], grid_size: [1, 1], inputs: [layer.2.output.dense.bias, opt_in1_layer.2.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.2.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [8, 2], grid_size: [1, 1], inputs: [grad_acc_layer.2.output.LayerNorm.weight, input_opt_layer.2.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.2.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [8, 3], grid_size: [1, 1], inputs: [layer.2.output.LayerNorm.weight, opt_in1_layer.2.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.2.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [8, 4], grid_size: [1, 1], inputs: [grad_acc_layer.2.output.LayerNorm.bias, input_opt_layer.2.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.2.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [8, 5], grid_size: [1, 1], inputs: [layer.2.output.LayerNorm.bias, opt_in2_layer.2.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.3.attention.self.query.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [8, 6], grid_size: [1, 1], inputs: [input_opt_layer.3.attention.self.query.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.3.attention.self.query.weight_multiply_1: {type: multiply, grid_loc: [9, 0], grid_size: [1, 8], inputs: [grad_acc_layer.3.attention.self.query.weight, input_opt_layer.3.attention.self.query.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}

  opt_31:
    target_device: 0
    input_count: 1
    opt_in0_layer.3.attention.self.query.weight_subtract_2: {type: subtract, grid_loc: [0, 0], grid_size: [1, 8], inputs: [layer.3.attention.self.query.weight, e2e_opt_in0_layer.3.attention.self.query.weight_multiply_1_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.attention.self.query.bias_multiply_1: {type: multiply, grid_loc: [1, 0], grid_size: [1, 1], inputs: [grad_acc_layer.3.attention.self.query.bias, input_opt_layer.3.attention.self.query.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.3.attention.self.query.bias_subtract_2: {type: subtract, grid_loc: [1, 1], grid_size: [1, 1], inputs: [layer.3.attention.self.query.bias, opt_in1_layer.3.attention.self.query.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.3.attention.self.key.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [1, 2], grid_size: [1, 1], inputs: [input_opt_layer.3.attention.self.key.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.3.attention.self.key.weight_multiply_1: {type: multiply, grid_loc: [2, 0], grid_size: [1, 8], inputs: [grad_acc_layer.3.attention.self.key.weight, input_opt_layer.3.attention.self.key.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.3.attention.self.key.weight_subtract_2: {type: subtract, grid_loc: [3, 0], grid_size: [1, 8], inputs: [layer.3.attention.self.key.weight, opt_in0_layer.3.attention.self.key.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.attention.self.key.bias_multiply_1: {type: multiply, grid_loc: [1, 3], grid_size: [1, 1], inputs: [grad_acc_layer.3.attention.self.key.bias, input_opt_layer.3.attention.self.key.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.3.attention.self.key.bias_subtract_2: {type: subtract, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layer.3.attention.self.key.bias, opt_in1_layer.3.attention.self.key.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.3.attention.self.value.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [1, 5], grid_size: [1, 1], inputs: [input_opt_layer.3.attention.self.value.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.3.attention.self.value.weight_multiply_1: {type: multiply, grid_loc: [4, 0], grid_size: [1, 8], inputs: [grad_acc_layer.3.attention.self.value.weight, input_opt_layer.3.attention.self.value.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.3.attention.self.value.weight_subtract_2: {type: subtract, grid_loc: [5, 0], grid_size: [1, 8], inputs: [layer.3.attention.self.value.weight, opt_in0_layer.3.attention.self.value.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.attention.self.value.bias_multiply_1: {type: multiply, grid_loc: [1, 6], grid_size: [1, 1], inputs: [grad_acc_layer.3.attention.self.value.bias, input_opt_layer.3.attention.self.value.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.3.attention.self.value.bias_subtract_2: {type: subtract, grid_loc: [1, 7], grid_size: [1, 1], inputs: [layer.3.attention.self.value.bias, opt_in1_layer.3.attention.self.value.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.3.attention.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [6, 0], grid_size: [1, 1], inputs: [input_opt_layer.3.attention.output.dense.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}
    opt_in0_layer.3.attention.output.dense.weight_multiply_1: {type: multiply, grid_loc: [7, 0], grid_size: [1, 8], inputs: [grad_acc_layer.3.attention.output.dense.weight, input_opt_layer.3.attention.output.dense.weight_0.lr_splt_brcst_3_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.3.attention.output.dense.weight_subtract_2: {type: subtract, grid_loc: [8, 0], grid_size: [1, 8], inputs: [layer.3.attention.output.dense.weight, opt_in0_layer.3.attention.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.attention.output.dense.bias_multiply_1: {type: multiply, grid_loc: [6, 1], grid_size: [1, 1], inputs: [grad_acc_layer.3.attention.output.dense.bias, input_opt_layer.3.attention.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.3.attention.output.dense.bias_subtract_2: {type: subtract, grid_loc: [6, 2], grid_size: [1, 1], inputs: [layer.3.attention.output.dense.bias, opt_in1_layer.3.attention.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.attention.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [6, 3], grid_size: [1, 1], inputs: [grad_acc_layer.3.attention.output.LayerNorm.weight, input_opt_layer.3.attention.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.3.attention.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [6, 4], grid_size: [1, 1], inputs: [layer.3.attention.output.LayerNorm.weight, opt_in1_layer.3.attention.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.3.attention.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [6, 5], grid_size: [1, 1], inputs: [grad_acc_layer.3.attention.output.LayerNorm.bias, input_opt_layer.3.attention.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.3.attention.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [6, 6], grid_size: [1, 1], inputs: [layer.3.attention.output.LayerNorm.bias, opt_in2_layer.3.attention.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.3.intermediate.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [9, 0], grid_size: [1, 2], inputs: [input_opt_layer.3.intermediate.dense.weight_0.lr],
         t: 1, mblock: [1, 16], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 128}]}

  opt_32:
    target_device: 0
    input_count: 1
    opt_in0_layer.3.intermediate.dense.weight_multiply_1: {type: multiply, grid_loc: [0, 0], grid_size: [4, 8], inputs: [grad_acc_layer.3.intermediate.dense.weight, e2e_input_opt_layer.3.intermediate.dense.weight_0.lr_splt_brcst_3_0_0],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 32}]}
    opt_in0_layer.3.intermediate.dense.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [4, 8], inputs: [layer.3.intermediate.dense.weight, opt_in0_layer.3.intermediate.dense.weight_multiply_1],
         t: 1, mblock: [4, 4], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.intermediate.dense.bias_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [grad_acc_layer.3.intermediate.dense.bias, input_opt_layer.3.intermediate.dense.bias_0.lr],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 128}]}
    opt_in1_layer.3.intermediate.dense.bias_subtract_2: {type: subtract, grid_loc: [8, 1], grid_size: [1, 1], inputs: [layer.3.intermediate.dense.bias, opt_in1_layer.3.intermediate.dense.bias_multiply_1],
         t: 1, mblock: [1, 32], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    input_opt_layer.3.output.dense.weight_0.lr_splt_brcst_3_0: {type: nop, grid_loc: [8, 2], grid_size: [1, 2], inputs: [input_opt_layer.3.output.dense.weight_0.lr],
         t: 1, mblock: [1, 4], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [broadcast: {c: 32}]}

  opt_33:
    target_device: 0
    input_count: 1
    opt_in0_layer.3.output.dense.weight_multiply_1: {type: multiply, grid_loc: [0, 0], grid_size: [4, 8], inputs: [grad_acc_layer.3.output.dense.weight, e2e_input_opt_layer.3.output.dense.weight_0.lr_splt_brcst_3_0_0],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 128}]}
    opt_in0_layer.3.output.dense.weight_subtract_2: {type: subtract, grid_loc: [4, 0], grid_size: [4, 8], inputs: [layer.3.output.dense.weight, opt_in0_layer.3.output.dense.weight_multiply_1],
         t: 1, mblock: [16, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.output.dense.bias_multiply_1: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [grad_acc_layer.3.output.dense.bias, input_opt_layer.3.output.dense.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.3.output.dense.bias_subtract_2: {type: subtract, grid_loc: [8, 1], grid_size: [1, 1], inputs: [layer.3.output.dense.bias, opt_in1_layer.3.output.dense.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in1_layer.3.output.LayerNorm.weight_multiply_1: {type: multiply, grid_loc: [8, 2], grid_size: [1, 1], inputs: [grad_acc_layer.3.output.LayerNorm.weight, input_opt_layer.3.output.LayerNorm.weight_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in1_layer.3.output.LayerNorm.weight_subtract_2: {type: subtract, grid_loc: [8, 3], grid_size: [1, 1], inputs: [layer.3.output.LayerNorm.weight, opt_in1_layer.3.output.LayerNorm.weight_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    opt_in2_layer.3.output.LayerNorm.bias_multiply_1: {type: multiply, grid_loc: [8, 4], grid_size: [1, 1], inputs: [grad_acc_layer.3.output.LayerNorm.bias, input_opt_layer.3.output.LayerNorm.bias_0.lr],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 32}]}
    opt_in2_layer.3.output.LayerNorm.bias_subtract_2: {type: subtract, grid_loc: [8, 5], grid_size: [1, 1], inputs: [layer.3.output.LayerNorm.bias, opt_in2_layer.3.output.LayerNorm.bias_multiply_1],
         t: 1, mblock: [1, 8], ublock: [1, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}


programs:
  - run_fwd:
    - param: [$p_loop_count]
    - var: {$c_microbatch_size: 2, $lptr_q14: 0, $gptr_q12: 0, $lptr_q4: 0, $lptr_q3: 0, $gptr_q1: 0, $lptr_q8: 0, $gptr_q8: 0, $lptr_q6: 0, $c_one: 1, $c_zero: 0, $lptr_q1: 0, $lptr_q12: 0, $gptr_q6: 0, $gptr_q4: 0, $gptr_q14: 0, $gptr_q3: 0}
    - staticvar: {$gptr_q0_shadow: 0, $gptr_q0: 0, $lptr_q0: 0, $gptr_q2_shadow: 0, $gptr_q2: 0, $gptr_q5_shadow: 0, $gptr_q5: 0, $gptr_q7_shadow: 0, $lptr_q2: 0, $lptr_q13: 0, $gptr_q13: 0, $gptr_q9: 0, $gptr_q13_shadow: 0, $lptr_q11: 0, $lptr_q9: 0, $lptr_q7: 0, $gptr_q11: 0, $gptr_q10: 0, $gptr_q11_shadow: 0, $lptr_q10: 0, $lptr_q5: 0, $gptr_q10_shadow: 0, $gptr_q7: 0}
    - varinst: [$gptr_q13, set, $gptr_q13_shadow]
    - varinst: [$gptr_q11, set, $gptr_q11_shadow]
    - varinst: [$gptr_q10, set, $gptr_q10_shadow]
    - varinst: [$gptr_q7, set, $gptr_q7_shadow]
    - varinst: [$gptr_q5, set, $gptr_q5_shadow]
    - varinst: [$gptr_q2, set, $gptr_q2_shadow]
    - varinst: [$gptr_q0, set, $gptr_q0_shadow]
    - loop: $p_loop_count
    -   allocate_queue: [e2e_layernorm_266.dc.multiply.9_0, e2e_layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1_0]
    -   execute: {graph_name: fwd_0, queue_settings: {
               hidden_states: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
               attention_mask: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
               layer.0.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.attention.self.query.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.attention.self.query.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.0.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.attention.self.key.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.attention.self.key.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_multiply_244_fork_clone1647_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_246.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.attention.self.value.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.attention.self.value.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.0.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.attention.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.attention.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_266.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_266.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_266.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_266.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.0.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.attention.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q0_shadow, incwrap, $c_microbatch_size, 8]
    -   varinst: [$lptr_q0, incwrap, $c_microbatch_size, 8]
    -   allocate_queue: [e2e_layernorm_280.dc.sqrt.6_0, e2e_buffer_0_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8_0]
    -   execute: {graph_name: fwd_1, queue_settings: {
               e2e_layernorm_266.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               e2e_layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               layer.0.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.intermediate.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.intermediate.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.0.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_280.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_280.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_280.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_layernorm_266.dc.multiply.9_0, e2e_layer.0.attention.output.LayerNorm.bias_s_brcst_m2_1_0.lc1_0]
    -   varinst: [$gptr_q1, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q1, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_layernorm_319.dc.multiply.2_0, e2e_buffer_0_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8_0]
    -   execute: {graph_name: fwd_2, queue_settings: {
               attention_mask: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               e2e_layernorm_280.dc.sqrt.6_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_buffer_0_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               lc.input_tensor.layernorm_280.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.0.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.0.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.0.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.attention.self.query.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.attention.self.query.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.attention.self.key.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.attention.self.key.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_multiply_297_fork_clone1670_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_299.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.attention.self.value.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.attention.self.value.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.attention.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.attention.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_319.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_layernorm_280.dc.sqrt.6_0, e2e_buffer_0_layernorm_280.dc.subtract.1_layernorm_280.dc.multiply.8_0]
    -   varinst: [$gptr_q2_shadow, incwrap, $c_microbatch_size, 8]
    -   varinst: [$gptr_q3, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q2, incwrap, $c_microbatch_size, 8]
    -   varinst: [$lptr_q3, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_add_332_0]
    -   execute: {graph_name: fwd_3, queue_settings: {
               e2e_layernorm_319.dc.multiply.2_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               e2e_buffer_0_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               lc.input_tensor.layernorm_319.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_319.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_319.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.1.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.attention.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.intermediate.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.intermediate.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_layernorm_319.dc.multiply.2_0, e2e_buffer_0_layernorm_319.dc.subtract.1_layernorm_319.dc.multiply.8_0]
    -   varinst: [$gptr_q4, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q4, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_add_369_0]
    -   execute: {graph_name: fwd_4, queue_settings: {
               attention_mask: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_add_332_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               lc.input_tensor.layernorm_333.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_333.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_333.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_333.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.1.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.1.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.1.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.attention.self.query.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.attention.self.query.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.attention.self.key.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.attention.self.key.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_multiply_350_fork_clone1693_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_352.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.attention.self.value.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.attention.self.value.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.attention.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.attention.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_add_332_0]
    -   varinst: [$gptr_q5_shadow, incwrap, $c_microbatch_size, 8]
    -   varinst: [$gptr_q6, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q5, incwrap, $c_microbatch_size, 8]
    -   varinst: [$lptr_q6, incwrap, $c_microbatch_size, 4]
    -   execute: {graph_name: fwd_5, queue_settings: {
               e2e_layernorm_333.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_add_369_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               lc.input_tensor.layernorm_372.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_372.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_372.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_372.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.2.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.attention.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.intermediate.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.intermediate.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_add_369_0]
    -   varinst: [$gptr_q7_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q8, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q7, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q8, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_softmax_405.dc.exp.0_0, e2e_lc.input_tensor.softmax_405.dc.reduce_sum.1.0_splt_brcst_1_0_0]
    -   execute: {graph_name: fwd_6, queue_settings: {
               attention_mask: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_layernorm_372.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q10, rd_ptr_global: $gptr_q10},
               e2e_gelu_378_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q10, rd_ptr_global: $gptr_q10},
               layer.2.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_386.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_386.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_386.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_386.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.2.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.2.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.2.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.attention.self.query.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.attention.self.query.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.attention.self.key.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.attention.self.key.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_multiply_403_fork_clone1716_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_405.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q10_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q9, incwrap, $c_microbatch_size, 8]
    -   varinst: [$lptr_q10, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q9, incwrap, $c_microbatch_size, 8]
    -   allocate_queue: [e2e_matmul_428_0, e2e_layer.3.intermediate.dense.bias_s_brcst_m2_1_0.lc1_0]
    -   execute: {graph_name: fwd_7, queue_settings: {
               e2e_layernorm_386.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_softmax_405.dc.exp.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12},
               e2e_lc.input_tensor.softmax_405.dc.reduce_sum.1.0_splt_brcst_1_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12},
               layer.3.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.attention.self.value.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.attention.self.value.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.attention.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.attention.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_425.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_425.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_425.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_425.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.3.attention.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.attention.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.attention.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.intermediate.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.intermediate.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_softmax_405.dc.exp.0_0, e2e_lc.input_tensor.softmax_405.dc.reduce_sum.1.0_splt_brcst_1_0_0]
    -   varinst: [$gptr_q11_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q12, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q11, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q12, incwrap, $c_microbatch_size, 4]
    -   execute: {graph_name: fwd_8, queue_settings: {
               e2e_layernorm_425.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_matmul_428_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               e2e_layer.3.intermediate.dense.bias_s_brcst_m2_1_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               layer.3.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.output.dense.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.output.dense.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_439.dc.reduce_avg.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_439.dc.reduce_avg.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.layernorm_439.4: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_439.dc.reciprocal.7_s_brcst_m1_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.3.output.LayerNorm.weight_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layer.3.output.LayerNorm.bias_s_brcst_m2_1_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               layer.3.output.LayerNorm.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_matmul_428_0, e2e_layer.3.intermediate.dense.bias_s_brcst_m2_1_0.lc1_0]
    -   varinst: [$gptr_q13_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q14, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q13, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q14, incwrap, $c_microbatch_size, 4]
    - endloop

  - run_bwd:
    - param: [$p_zero_grad, $p_loop_count]
    - var: {$c_microbatch_size: 2, $lptr_q3: 0, $gptr_q8: 0, $lptr_q8: 0, $gptr_q10_shadow: 0, $gptr_q10: 0, $lptr_q10: 0, $gptr_q12: 0, $gptr_q6: 0, $lptr_q12: 0, $gptr_q15: 0, $lptr_q6: 0, $gptr_q29: 0, $c_one: 1, $c_zero: 0, $gptr_q26: 0, $gptr_q24: 0, $lptr_q24: 0, $lptr_q29: 0, $lptr_q22: 0, $v_zero_grad: 0, $gptr_q22: 0, $lptr_q17: 0, $lptr_q19: 0, $lptr_q26: 0, $gptr_q19: 0, $gptr_q3: 0, $gptr_q17: 0, $lptr_q15: 0}
    - staticvar: {$gptr_q0: 0, $lptr_q0: 0, $lptr_q1: 0, $gptr_q2: 0, $lptr_q2: 0, $gptr_q4: 0, $lptr_q4: 0, $gptr_q4_shadow: 0, $gptr_q5: 0, $gptr_q20: 0, $gptr_q21: 0, $lptr_q5: 0, $gptr_q23: 0, $gptr_q21_shadow: 0, $lptr_q23: 0, $gptr_q9: 0, $lptr_q20: 0, $gptr_q11: 0, $gptr_q1: 0, $gptr_q25: 0, $lptr_q9: 0, $lptr_q21: 0, $gptr_q27: 0, $lptr_q16: 0, $lptr_q27: 0, $lptr_q11: 0, $gptr_q28: 0, $lptr_q25: 0, $lptr_q28: 0, $gptr_q14_shadow: 0, $lptr_q18: 0, $gptr_q18: 0, $lptr_q14: 0, $gptr_q14: 0, $gptr_q16: 0, $lptr_q13: 0, $gptr_q13: 0, $lptr_q7: 0, $gptr_q7: 0}
    - varinst: [$gptr_q21, set, $gptr_q21_shadow]
    - varinst: [$gptr_q14, set, $gptr_q14_shadow]
    - varinst: [$gptr_q10, set, $gptr_q10_shadow]
    - varinst: [$gptr_q4, set, $gptr_q4_shadow]
    - varinst: [$v_zero_grad, set, $p_zero_grad]
    - loop: $p_loop_count
    -   allocate_queue: [e2e_bw_in0_matmul_434_matmul_1_0, e2e_bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9_0]
    -   execute: {graph_name: bwd_9, queue_settings: {
               loss_bert_encoder.output_layernorm_439: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
               e2e_gelu_431_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               e2e_layernorm_439.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               e2e_layernorm_439.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               layer.3.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_439_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_439.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.3.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_439_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_436_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.3.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q0, incwrap, $c_microbatch_size, 8]
    -   varinst: [$gptr_q1, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q0, incwrap, $c_microbatch_size, 8]
    -   varinst: [$lptr_q1, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_gelu_431_multiply_1_0, e2e_bw_in0_matmul_428_matmul_1_0, e2e_bw_in1_matmul_428_transpose_0_0]
    -   execute: {graph_name: bwd_10, queue_settings: {
               e2e_layernorm_425.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               e2e_add_430_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               e2e_bw_in0_matmul_434_matmul_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               layer.3.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_430_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.3.intermediate.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_matmul_434_matmul_1_0]
    -   varinst: [$gptr_q2, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q3, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q2, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q3, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_matmul_416_matmul_1_0, e2e_bw_in0_matmul_409_matmul_1_0, e2e_bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.lc1_0]
    -   execute: {graph_name: bwd_11, queue_settings: {
               e2e_layernorm_386.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               e2e_softmax_405.dc.multiply.3_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               e2e_add_411_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_matmul_416_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_layernorm_425.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_layernorm_425.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e_bw_in0_gelu_431_multiply_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e_bw_in0_matmul_428_matmul_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e_bw_in1_matmul_428_transpose_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               layer.3.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_425_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_425.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.3.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_425_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_422_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_411_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.3.intermediate.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.self.value.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.self.value.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_439_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_gelu_431_multiply_1_0, e2e_bw_in0_matmul_428_matmul_1_0, e2e_bw_in1_matmul_428_transpose_0_0]
    -   varinst: [$gptr_q4_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q5, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q6, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q4, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q5, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q6, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0]
    -   execute: {graph_name: bwd_12, queue_settings: {
               e2e_layernorm_386.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_layernorm_386.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_layernorm_386.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_add_391_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_add_397_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_softmax_405.dc.multiply.3_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bw_in0_matmul_416_matmul_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bw_in0_matmul_409_matmul_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               layer.2.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.3.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_multiply_403_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_397_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_391_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_386_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_386.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.2.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_386_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_383_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.3.attention.self.key.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.self.key.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.self.query.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.3.attention.self.query.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_425_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_matmul_416_matmul_1_0, e2e_bw_in0_matmul_409_matmul_1_0, e2e_bw_in0_softmax_405_softmax_bw_0.dc.reduce_sum.1.lc1_0]
    -   varinst: [$gptr_q7, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q8, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q7, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q8, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_gelu_378_multiply_1_0]
    -   execute: {graph_name: bwd_13, queue_settings: {
               e2e_add_377_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_gelu_378_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q10, rd_ptr_global: $gptr_q10},
               layer.2.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_377_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.2.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.intermediate.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q10_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q9, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q10, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q9, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_matmul_367_matmul_1_0]
    -   execute: {graph_name: bwd_14, queue_settings: {
               e2e_matmul_363_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_layernorm_372.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_layernorm_372.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_layernorm_372.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12},
               e2e_bw_in0_gelu_378_multiply_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12},
               layer.2.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_372_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_372.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.2.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_372_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_369_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.2.intermediate.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_386_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_gelu_378_multiply_1_0]
    -   varinst: [$gptr_q11, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q12, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q11, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q12, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_333_combine_add_0_0, e2e_layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0, e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0_0, e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1_0, e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.lc1_0]
    -   execute: {graph_name: bwd_15, queue_settings: {
               e2e_layernorm_333.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_layernorm_333.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               e2e_layernorm_333.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_add_338_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_add_344_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_softmax_352.dc.multiply.3_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_add_358_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q15, rd_ptr_global: $gptr_q15},
               e2e_bw_in0_matmul_367_matmul_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q15, rd_ptr_global: $gptr_q15},
               layer.1.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.2.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_358_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_softmax_352_softmax_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_350_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_344_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_338_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.1.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.2.attention.self.value.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.self.value.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.self.key.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.self.key.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.self.query.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.2.attention.self.query.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_372_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_matmul_367_matmul_1_0]
    -   varinst: [$gptr_q13, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q14_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q15, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q13, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q14, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q15, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_gelu_325_multiply_1_0]
    -   execute: {graph_name: bwd_16, queue_settings: {
               e2e_add_324_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q16, rd_ptr_global: $gptr_q16},
               e2e_gelu_325_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q16, rd_ptr_global: $gptr_q16},
               e2e_layernorm_333.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q16, rd_ptr_global: $gptr_q16},
               e2e_bw_in0_layernorm_333_combine_add_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               layer.1.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_333_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_333_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_330_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_324_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.1.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.intermediate.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_333_combine_add_0_0, e2e_layernorm_333.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0, e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.0_0, e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.1.lc1_0, e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.reduce_sum.3.lc1_0]
    -   varinst: [$gptr_q16, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q17, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q16, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q17, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_matmul_314_matmul_1_0]
    -   execute: {graph_name: bwd_17, queue_settings: {
               e2e_matmul_310_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q18, rd_ptr_global: $gptr_q18},
               e2e_layernorm_319.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q18, rd_ptr_global: $gptr_q18},
               e2e_layernorm_319.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q18, rd_ptr_global: $gptr_q18},
               e2e_layernorm_319.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q18, rd_ptr_global: $gptr_q18},
               e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q19, rd_ptr_global: $gptr_q19},
               e2e_bw_in0_gelu_325_multiply_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q19, rd_ptr_global: $gptr_q19},
               layer.1.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_319_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_319.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.1.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_319_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_316_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.1.intermediate.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_333_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_gelu_325_multiply_1_0]
    -   varinst: [$gptr_q18, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q19, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q18, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q19, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_280_combine_add_0_0, e2e_layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0, e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0_0, e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1_0, e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.lc1_0]
    -   execute: {graph_name: bwd_18, queue_settings: {
               e2e_layernorm_280.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_layernorm_280.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q21, rd_ptr_global: $gptr_q21},
               e2e_layernorm_280.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_add_285_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_add_291_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_softmax_299.dc.multiply.3_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_add_305_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q22, rd_ptr_global: $gptr_q22},
               e2e_bw_in0_matmul_314_matmul_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q22, rd_ptr_global: $gptr_q22},
               layer.0.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.1.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_305_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_softmax_299_softmax_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_297_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_291_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_285_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.0.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.1.attention.self.value.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.self.value.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.self.key.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.self.key.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.self.query.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.1.attention.self.query.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_319_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_matmul_314_matmul_1_0]
    -   varinst: [$gptr_q20, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q21_shadow, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q22, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q20, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q21, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q22, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_gelu_272_multiply_1_0]
    -   execute: {graph_name: bwd_19, queue_settings: {
               e2e_add_271_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q23, rd_ptr_global: $gptr_q23},
               e2e_gelu_272_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q23, rd_ptr_global: $gptr_q23},
               e2e_layernorm_280.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q23, rd_ptr_global: $gptr_q23},
               e2e_bw_in0_layernorm_280_combine_add_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               e2e_layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               layer.0.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_280_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_280_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_277_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_271_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.0.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.intermediate.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_280_combine_add_0_0, e2e_layernorm_280.dc.reciprocal.7_s_brcst_m1_0_0.lc1_0, e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.0_0, e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.1.lc1_0, e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.reduce_sum.3.lc1_0]
    -   varinst: [$gptr_q23, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q24, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q23, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q24, incwrap, $c_microbatch_size, 4]
    -   allocate_queue: [e2e_bw_in0_matmul_261_matmul_1_0]
    -   execute: {graph_name: bwd_20, queue_settings: {
               e2e_matmul_257_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q25, rd_ptr_global: $gptr_q25},
               e2e_layernorm_266.dc.reciprocal.7_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q25, rd_ptr_global: $gptr_q25},
               e2e_layernorm_266.dc.multiply.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q25, rd_ptr_global: $gptr_q25},
               e2e_layernorm_266.dc.add.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q25, rd_ptr_global: $gptr_q25},
               e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q26, rd_ptr_global: $gptr_q26},
               e2e_bw_in0_gelu_272_multiply_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q26, rd_ptr_global: $gptr_q26},
               layer.0.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.0.attention.output.LayerNorm.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               layer.0.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bw_in2_layernorm_266_layernorm_bw_0.dc.reduce_sum.0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_266.dc.reciprocal.7_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layer.0.attention.output.LayerNorm.weight_s_brcst_m2_2_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.dc.reduce_sum.3.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               dc.input_tensor.bw_in0_layernorm_266_layernorm_bw_0.6: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_263_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.0.intermediate.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.output.LayerNorm.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.output.LayerNorm.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.output.dense.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.output.dense.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_layernorm_280_layernorm_bw_0.dc.multiply.9_0, e2e_bw_in0_gelu_272_multiply_1_0]
    -   varinst: [$gptr_q25, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q26, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q25, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q26, incwrap, $c_microbatch_size, 4]
    -   execute: {graph_name: bwd_21, queue_settings: {
               hidden_states: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q27, rd_ptr_global: $gptr_q27},
               e2e_add_232_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q28, rd_ptr_global: $gptr_q28},
               e2e_add_238_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q28, rd_ptr_global: $gptr_q28},
               e2e_softmax_246.dc.multiply.3_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q28, rd_ptr_global: $gptr_q28},
               e2e_add_252_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q28, rd_ptr_global: $gptr_q28},
               e2e_bw_in0_matmul_261_matmul_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q29, rd_ptr_global: $gptr_q29},
               lc.input_tensor.bw_in1_add_252_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in0_softmax_246_softmax_bw_0.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_multiply_244_tile_bcast_tile_bcast: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_238_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bw_in1_add_232_brcst_reduce_sum_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               grad_acc_layer.0.attention.self.value.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.self.value.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.self.key.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.self.key.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.self.query.bias: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               grad_acc_layer.0.attention.self.query.weight: {prologue: true, epilogue: true, zero: $v_zero_grad, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_bw_in0_matmul_261_matmul_1_0]
    -   varinst: [$gptr_q27, incwrap, $c_microbatch_size, 8]
    -   varinst: [$gptr_q28, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q29, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q27, incwrap, $c_microbatch_size, 8]
    -   varinst: [$lptr_q28, incwrap, $c_microbatch_size, 4]
    -   varinst: [$lptr_q29, incwrap, $c_microbatch_size, 4]
    -   varinst: [$v_zero_grad, set, 0]
    - endloop

  - run_opt:
    - var: {$c_microbatch_size: 2, $gptr_q0: 0, $c_one: 1, $c_zero: 0, $lptr_q0: 0, $lptr_q1: 0, $lptr_q2: 0, $gptr_q2: 0, $gptr_q3: 0, $gptr_q8: 0, $lptr_q5: 0, $gptr_q9: 0, $gptr_q1: 0, $lptr_q8: 0, $lptr_q9: 0, $lptr_q7: 0, $lptr_q6: 0, $gptr_q6: 0, $gptr_q5: 0, $lptr_q4: 0, $lptr_q3: 0, $gptr_q7: 0, $gptr_q4: 0}
    - execute: {graph_name: opt_22, queue_settings: {
             layer.0.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - allocate_queue: [e2e_input_opt_layer.0.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - execute: {graph_name: opt_23, queue_settings: {
             layer.0.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - allocate_queue: [e2e_opt_in0_layer.1.attention.self.query.weight_multiply_1_0]
    - execute: {graph_name: opt_24, queue_settings: {
             e2e_input_opt_layer.0.output.dense.weight_0.lr_splt_brcst_3_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
             layer.0.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.0.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.0.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_input_opt_layer.0.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - varinst: [$gptr_q0, incwrap, $c_one, 2]
    - varinst: [$lptr_q0, incwrap, $c_one, 2]
    - allocate_queue: [e2e_input_opt_layer.1.intermediate.dense.weight_0.lr_splt_brcst_3_0_0]
    - execute: {graph_name: opt_25, queue_settings: {
             e2e_opt_in0_layer.1.attention.self.query.weight_multiply_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
             layer.1.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_opt_in0_layer.1.attention.self.query.weight_multiply_1_0]
    - varinst: [$gptr_q1, incwrap, $c_one, 2]
    - varinst: [$lptr_q1, incwrap, $c_one, 2]
    - allocate_queue: [e2e_input_opt_layer.1.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - execute: {graph_name: opt_26, queue_settings: {
             e2e_input_opt_layer.1.intermediate.dense.weight_0.lr_splt_brcst_3_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
             layer.1.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_input_opt_layer.1.intermediate.dense.weight_0.lr_splt_brcst_3_0_0]
    - varinst: [$gptr_q2, incwrap, $c_one, 2]
    - varinst: [$lptr_q2, incwrap, $c_one, 2]
    - allocate_queue: [e2e_opt_in0_layer.2.attention.self.query.weight_multiply_1_0]
    - execute: {graph_name: opt_27, queue_settings: {
             e2e_input_opt_layer.1.output.dense.weight_0.lr_splt_brcst_3_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
             layer.1.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.1.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.1.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_input_opt_layer.1.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - varinst: [$gptr_q3, incwrap, $c_one, 2]
    - varinst: [$lptr_q3, incwrap, $c_one, 2]
    - allocate_queue: [e2e_input_opt_layer.2.intermediate.dense.weight_0.lr_splt_brcst_3_0_0]
    - execute: {graph_name: opt_28, queue_settings: {
             e2e_opt_in0_layer.2.attention.self.query.weight_multiply_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
             layer.2.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_opt_in0_layer.2.attention.self.query.weight_multiply_1_0]
    - varinst: [$gptr_q4, incwrap, $c_one, 2]
    - varinst: [$lptr_q4, incwrap, $c_one, 2]
    - allocate_queue: [e2e_input_opt_layer.2.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - execute: {graph_name: opt_29, queue_settings: {
             e2e_input_opt_layer.2.intermediate.dense.weight_0.lr_splt_brcst_3_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
             layer.2.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_input_opt_layer.2.intermediate.dense.weight_0.lr_splt_brcst_3_0_0]
    - varinst: [$gptr_q5, incwrap, $c_one, 2]
    - varinst: [$lptr_q5, incwrap, $c_one, 2]
    - allocate_queue: [e2e_opt_in0_layer.3.attention.self.query.weight_multiply_1_0]
    - execute: {graph_name: opt_30, queue_settings: {
             e2e_input_opt_layer.2.output.dense.weight_0.lr_splt_brcst_3_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
             layer.2.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.2.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.2.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_input_opt_layer.2.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - varinst: [$gptr_q6, incwrap, $c_one, 2]
    - varinst: [$lptr_q6, incwrap, $c_one, 2]
    - allocate_queue: [e2e_input_opt_layer.3.intermediate.dense.weight_0.lr_splt_brcst_3_0_0]
    - execute: {graph_name: opt_31, queue_settings: {
             e2e_opt_in0_layer.3.attention.self.query.weight_multiply_1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
             layer.3.attention.self.query.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.self.value.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.self.value.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.self.key.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.self.key.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.attention.self.query.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_opt_in0_layer.3.attention.self.query.weight_multiply_1_0]
    - varinst: [$gptr_q7, incwrap, $c_one, 2]
    - varinst: [$lptr_q7, incwrap, $c_one, 2]
    - allocate_queue: [e2e_input_opt_layer.3.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - execute: {graph_name: opt_32, queue_settings: {
             e2e_input_opt_layer.3.intermediate.dense.weight_0.lr_splt_brcst_3_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
             layer.3.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.intermediate.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.intermediate.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_input_opt_layer.3.intermediate.dense.weight_0.lr_splt_brcst_3_0_0]
    - varinst: [$gptr_q8, incwrap, $c_one, 2]
    - varinst: [$lptr_q8, incwrap, $c_one, 2]
    - execute: {graph_name: opt_33, queue_settings: {
             e2e_input_opt_layer.3.output.dense.weight_0.lr_splt_brcst_3_0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
             layer.3.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             layer.3.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.output.LayerNorm.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.output.LayerNorm.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.output.dense.bias: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
             grad_acc_layer.3.output.dense.weight: {prologue: false, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    - deallocate_queue: [e2e_input_opt_layer.3.output.dense.weight_0.lr_splt_brcst_3_0_0]
    - varinst: [$gptr_q9, incwrap, $c_one, 2]
    - varinst: [$lptr_q9, incwrap, $c_one, 2]

test-config:
  comparison-config:
    type: AllCloseHw
    atol: 0.01
    rtol: 0.15
    check_pct: 0.0
    check_pcc: 0.98
    verbosity: Concise
  stimulus-config:
    type: Uniform
    uniform_lower_bound: 0.001
    uniform_upper_bound: 2.0
  io-config:
    inputs: [hidden_states, attention_mask, loss_bert_encoder.output_layernorm_439]
    outputs: [bert_encoder.output_layernorm_439]

