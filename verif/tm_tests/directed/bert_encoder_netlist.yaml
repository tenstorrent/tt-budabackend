devices:
  arch: grayskull

queues:

  # input
  input_1_add_36:                                                                            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3027b8c0]]}
  input_1_add_799:                                                                           {input: HOST, type: queue, entries: 9, grid_size: [1, 1], t: 1, mblock: [1, 4], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x303d1580]]}

  # output
  bert_encoder.output_layernorm_841_bias:                                                    {input: layernorm_841_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 3], ublock: [1, 8], df: Float16_b, target_device: 0, loc: host, host: [0x0]}

  # parameter
  bert_encoder.layer_11_output_LayerNorm_bias:                                               {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30000840]]}
  bert_encoder.layer_11_output_LayerNorm_weight:                                             {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3000d3a0]]}
  bert_encoder.layer_11_attention_output_LayerNorm_bias:                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30019f00]]}
  bert_encoder.layer_11_attention_output_LayerNorm_weight:                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30026a60]]}
  bert_encoder.layer_10_output_LayerNorm_bias:                                               {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300335c0]]}
  bert_encoder.layer_10_output_LayerNorm_weight:                                             {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30040120]]}
  bert_encoder.layer_10_attention_output_LayerNorm_bias:                                     {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3004cc80]]}
  bert_encoder.layer_10_attention_output_LayerNorm_weight:                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300597e0]]}
  bert_encoder.layer_9_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30066340]]}
  bert_encoder.layer_9_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30072ea0]]}
  bert_encoder.layer_9_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3007fa00]]}
  bert_encoder.layer_9_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3008c560]]}
  bert_encoder.layer_8_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300990c0]]}
  bert_encoder.layer_8_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300a5c20]]}
  bert_encoder.layer_8_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300b2780]]}
  bert_encoder.layer_8_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300bf2e0]]}
  bert_encoder.layer_7_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300cbe40]]}
  bert_encoder.layer_7_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300d89a0]]}
  bert_encoder.layer_7_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300e5500]]}
  bert_encoder.layer_7_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300f2060]]}
  bert_encoder.layer_6_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300febc0]]}
  bert_encoder.layer_6_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3010b720]]}
  bert_encoder.layer_6_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30118280]]}
  bert_encoder.layer_6_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30124de0]]}
  bert_encoder.layer_5_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30131940]]}
  bert_encoder.layer_5_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3013e4a0]]}
  bert_encoder.layer_5_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3014b000]]}
  bert_encoder.layer_5_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30157b60]]}
  bert_encoder.layer_4_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301646c0]]}
  bert_encoder.layer_4_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30171220]]}
  bert_encoder.layer_4_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3017dd80]]}
  bert_encoder.layer_4_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3018a8e0]]}
  bert_encoder.layer_3_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30197440]]}
  bert_encoder.layer_3_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301a3fa0]]}
  bert_encoder.layer_3_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301b0b00]]}
  bert_encoder.layer_3_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301bd660]]}
  bert_encoder.layer_2_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301ca1c0]]}
  bert_encoder.layer_2_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301d6d20]]}
  bert_encoder.layer_2_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301e3880]]}
  bert_encoder.layer_2_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301f03e0]]}
  bert_encoder.layer_1_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301fcf40]]}
  bert_encoder.layer_1_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30209aa0]]}
  bert_encoder.layer_1_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30216600]]}
  bert_encoder.layer_1_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30223160]]}
  bert_encoder.layer_0_output_LayerNorm_bias:                                                {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3022fcc0]]}
  bert_encoder.layer_0_output_LayerNorm_weight:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3023c820]]}
  bert_encoder.layer_0_attention_output_LayerNorm_bias:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30249380]]}
  bert_encoder.layer_0_attention_output_LayerNorm_weight:                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30255ee0]]}
  bert_encoder.layer_0_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30262a40]]}
  bert_encoder.layer_0_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3026f5a0]]}
  bert_encoder.layer_0_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x302ac4e0], [0, 0x3030dd00], [0, 0x3036f520]]}
  bert_encoder.layer_0_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x303e4260]]}
  bert_encoder.layer_0_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x303f0580], [0, 0x30451da0], [0, 0x304b35c0]]}
  bert_encoder.layer_0_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30515620]]}
  bert_encoder.layer_0_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30521940], [0, 0x30583160], [0, 0x305e4980]]}
  bert_encoder.layer_0_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3064cb80], [0, 0x306ae3a0], [0, 0x3070fbc0]]}
  bert_encoder.layer_0_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30773d20]]}
  bert_encoder.layer_0_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30780880], [0, 0x30798ea0]]}
  bert_encoder.layer_0_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x307b14c0], [0, 0x30812ce0], [0, 0x30874500], [0, 0x308d5d20], [0, 0x30937540], [0, 0x30998d60], [0, 0x309fa580], [0, 0x30a5bda0], [0, 0x30abd5c0], [0, 0x30b1ede0], [0, 0x30b80600], [0, 0x30be1e20]]}
  bert_encoder.layer_0_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30c43640], [0, 0x30ca4e60], [0, 0x30d06680], [0, 0x30d67ea0], [0, 0x30dc96c0], [0, 0x30e2aee0], [0, 0x30e8c700], [0, 0x30eedf20], [0, 0x30f4f740], [0, 0x30fb0f60], [0, 0x31012780], [0, 0x31073fa0]]}
  bert_encoder.layer_1_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310d8100]]}
  bert_encoder.layer_1_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310e4c60]]}
  bert_encoder.layer_1_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310f0f80], [0, 0x311527a0], [0, 0x311b3fc0]]}
  bert_encoder.layer_1_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31216860]]}
  bert_encoder.layer_1_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31222b80], [0, 0x312843a0], [0, 0x312e5bc0]]}
  bert_encoder.layer_1_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31347c20]]}
  bert_encoder.layer_1_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31353f40], [0, 0x313b5760], [0, 0x31416f80]]}
  bert_encoder.layer_1_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3147f180], [0, 0x314e09a0], [0, 0x315421c0]]}
  bert_encoder.layer_1_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315a6320]]}
  bert_encoder.layer_1_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315b2e80], [0, 0x315cb4a0]]}
  bert_encoder.layer_1_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315e3ac0], [0, 0x316452e0], [0, 0x316a6b00], [0, 0x31708320], [0, 0x31769b40], [0, 0x317cb360], [0, 0x3182cb80], [0, 0x3188e3a0], [0, 0x318efbc0], [0, 0x319513e0], [0, 0x319b2c00], [0, 0x31a14420]]}
  bert_encoder.layer_1_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31a75c40], [0, 0x31ad7460], [0, 0x31b38c80], [0, 0x31b9a4a0], [0, 0x31bfbcc0], [0, 0x31c5d4e0], [0, 0x31cbed00], [0, 0x31d20520], [0, 0x31d81d40], [0, 0x31de3560], [0, 0x31e44d80], [0, 0x31ea65a0]]}
  bert_encoder.layer_2_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f0a700]]}
  bert_encoder.layer_2_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f17260]]}
  bert_encoder.layer_2_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f23580], [0, 0x31f84da0], [0, 0x31fe65c0]]}
  bert_encoder.layer_2_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32048e60]]}
  bert_encoder.layer_2_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32055180], [0, 0x320b69a0], [0, 0x321181c0]]}
  bert_encoder.layer_2_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3217a220]]}
  bert_encoder.layer_2_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32186540], [0, 0x321e7d60], [0, 0x32249580]]}
  bert_encoder.layer_2_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x322b1780], [0, 0x32312fa0], [0, 0x323747c0]]}
  bert_encoder.layer_2_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323d8920]]}
  bert_encoder.layer_2_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323e5480], [0, 0x323fdaa0]]}
  bert_encoder.layer_2_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x324160c0], [0, 0x324778e0], [0, 0x324d9100], [0, 0x3253a920], [0, 0x3259c140], [0, 0x325fd960], [0, 0x3265f180], [0, 0x326c09a0], [0, 0x327221c0], [0, 0x327839e0], [0, 0x327e5200], [0, 0x32846a20]]}
  bert_encoder.layer_2_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x328a8240], [0, 0x32909a60], [0, 0x3296b280], [0, 0x329ccaa0], [0, 0x32a2e2c0], [0, 0x32a8fae0], [0, 0x32af1300], [0, 0x32b52b20], [0, 0x32bb4340], [0, 0x32c15b60], [0, 0x32c77380], [0, 0x32cd8ba0]]}
  bert_encoder.layer_3_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d3cd00]]}
  bert_encoder.layer_3_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d49860]]}
  bert_encoder.layer_3_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d55b80], [0, 0x32db73a0], [0, 0x32e18bc0]]}
  bert_encoder.layer_3_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32e7b460]]}
  bert_encoder.layer_3_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32e87780], [0, 0x32ee8fa0], [0, 0x32f4a7c0]]}
  bert_encoder.layer_3_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32fac820]]}
  bert_encoder.layer_3_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32fb8b40], [0, 0x3301a360], [0, 0x3307bb80]]}
  bert_encoder.layer_3_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x330e3d80], [0, 0x331455a0], [0, 0x331a6dc0]]}
  bert_encoder.layer_3_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3320af20]]}
  bert_encoder.layer_3_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33217a80], [0, 0x332300a0]]}
  bert_encoder.layer_3_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x332486c0], [0, 0x332a9ee0], [0, 0x3330b700], [0, 0x3336cf20], [0, 0x333ce740], [0, 0x3342ff60], [0, 0x33491780], [0, 0x334f2fa0], [0, 0x335547c0], [0, 0x335b5fe0], [0, 0x33617800], [0, 0x33679020]]}
  bert_encoder.layer_3_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x336da840], [0, 0x3373c060], [0, 0x3379d880], [0, 0x337ff0a0], [0, 0x338608c0], [0, 0x338c20e0], [0, 0x33923900], [0, 0x33985120], [0, 0x339e6940], [0, 0x33a48160], [0, 0x33aa9980], [0, 0x33b0b1a0]]}
  bert_encoder.layer_4_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b6f300]]}
  bert_encoder.layer_4_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b7be60]]}
  bert_encoder.layer_4_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b88180], [0, 0x33be99a0], [0, 0x33c4b1c0]]}
  bert_encoder.layer_4_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33cada60]]}
  bert_encoder.layer_4_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33cb9d80], [0, 0x33d1b5a0], [0, 0x33d7cdc0]]}
  bert_encoder.layer_4_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33ddee20]]}
  bert_encoder.layer_4_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33deb140], [0, 0x33e4c960], [0, 0x33eae180]]}
  bert_encoder.layer_4_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33f16380], [0, 0x33f77ba0], [0, 0x33fd93c0]]}
  bert_encoder.layer_4_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3403d520]]}
  bert_encoder.layer_4_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3404a080], [0, 0x340626a0]]}
  bert_encoder.layer_4_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3407acc0], [0, 0x340dc4e0], [0, 0x3413dd00], [0, 0x3419f520], [0, 0x34200d40], [0, 0x34262560], [0, 0x342c3d80], [0, 0x343255a0], [0, 0x34386dc0], [0, 0x343e85e0], [0, 0x34449e00], [0, 0x344ab620]]}
  bert_encoder.layer_4_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3450ce40], [0, 0x3456e660], [0, 0x345cfe80], [0, 0x346316a0], [0, 0x34692ec0], [0, 0x346f46e0], [0, 0x34755f00], [0, 0x347b7720], [0, 0x34818f40], [0, 0x3487a760], [0, 0x348dbf80], [0, 0x3493d7a0]]}
  bert_encoder.layer_5_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x349a1900]]}
  bert_encoder.layer_5_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x349ae460]]}
  bert_encoder.layer_5_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x349ba780], [0, 0x34a1bfa0], [0, 0x34a7d7c0]]}
  bert_encoder.layer_5_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34ae0060]]}
  bert_encoder.layer_5_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34aec380], [0, 0x34b4dba0], [0, 0x34baf3c0]]}
  bert_encoder.layer_5_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34c11420]]}
  bert_encoder.layer_5_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34c1d740], [0, 0x34c7ef60], [0, 0x34ce0780]]}
  bert_encoder.layer_5_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34d48980], [0, 0x34daa1a0], [0, 0x34e0b9c0]]}
  bert_encoder.layer_5_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e6fb20]]}
  bert_encoder.layer_5_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e7c680], [0, 0x34e94ca0]]}
  bert_encoder.layer_5_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34ead2c0], [0, 0x34f0eae0], [0, 0x34f70300], [0, 0x34fd1b20], [0, 0x35033340], [0, 0x35094b60], [0, 0x350f6380], [0, 0x35157ba0], [0, 0x351b93c0], [0, 0x3521abe0], [0, 0x3527c400], [0, 0x352ddc20]]}
  bert_encoder.layer_5_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3533f440], [0, 0x353a0c60], [0, 0x35402480], [0, 0x35463ca0], [0, 0x354c54c0], [0, 0x35526ce0], [0, 0x35588500], [0, 0x355e9d20], [0, 0x3564b540], [0, 0x356acd60], [0, 0x3570e580], [0, 0x3576fda0]]}
  bert_encoder.layer_6_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357d3f00]]}
  bert_encoder.layer_6_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357e0a60]]}
  bert_encoder.layer_6_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357ecd80], [0, 0x3584e5a0], [0, 0x358afdc0]]}
  bert_encoder.layer_6_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35912660]]}
  bert_encoder.layer_6_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3591e980], [0, 0x359801a0], [0, 0x359e19c0]]}
  bert_encoder.layer_6_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35a43a20]]}
  bert_encoder.layer_6_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35a4fd40], [0, 0x35ab1560], [0, 0x35b12d80]]}
  bert_encoder.layer_6_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35b7af80], [0, 0x35bdc7a0], [0, 0x35c3dfc0]]}
  bert_encoder.layer_6_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35ca2120]]}
  bert_encoder.layer_6_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35caec80], [0, 0x35cc72a0]]}
  bert_encoder.layer_6_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35cdf8c0], [0, 0x35d410e0], [0, 0x35da2900], [0, 0x35e04120], [0, 0x35e65940], [0, 0x35ec7160], [0, 0x35f28980], [0, 0x35f8a1a0], [0, 0x35feb9c0], [0, 0x3604d1e0], [0, 0x360aea00], [0, 0x36110220]]}
  bert_encoder.layer_6_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36171a40], [0, 0x361d3260], [0, 0x36234a80], [0, 0x362962a0], [0, 0x362f7ac0], [0, 0x363592e0], [0, 0x363bab00], [0, 0x3641c320], [0, 0x3647db40], [0, 0x364df360], [0, 0x36540b80], [0, 0x365a23a0]]}
  bert_encoder.layer_7_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36606500]]}
  bert_encoder.layer_7_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36613060]]}
  bert_encoder.layer_7_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3661f380], [0, 0x36680ba0], [0, 0x366e23c0]]}
  bert_encoder.layer_7_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36744c60]]}
  bert_encoder.layer_7_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36750f80], [0, 0x367b27a0], [0, 0x36813fc0]]}
  bert_encoder.layer_7_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36876020]]}
  bert_encoder.layer_7_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36882340], [0, 0x368e3b60], [0, 0x36945380]]}
  bert_encoder.layer_7_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x369ad580], [0, 0x36a0eda0], [0, 0x36a705c0]]}
  bert_encoder.layer_7_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ad4720]]}
  bert_encoder.layer_7_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ae1280], [0, 0x36af98a0]]}
  bert_encoder.layer_7_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36b11ec0], [0, 0x36b736e0], [0, 0x36bd4f00], [0, 0x36c36720], [0, 0x36c97f40], [0, 0x36cf9760], [0, 0x36d5af80], [0, 0x36dbc7a0], [0, 0x36e1dfc0], [0, 0x36e7f7e0], [0, 0x36ee1000], [0, 0x36f42820]]}
  bert_encoder.layer_7_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36fa4040], [0, 0x37005860], [0, 0x37067080], [0, 0x370c88a0], [0, 0x3712a0c0], [0, 0x3718b8e0], [0, 0x371ed100], [0, 0x3724e920], [0, 0x372b0140], [0, 0x37311960], [0, 0x37373180], [0, 0x373d49a0]]}
  bert_encoder.layer_8_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37438b00]]}
  bert_encoder.layer_8_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37445660]]}
  bert_encoder.layer_8_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37451980], [0, 0x374b31a0], [0, 0x375149c0]]}
  bert_encoder.layer_8_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37577260]]}
  bert_encoder.layer_8_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37583580], [0, 0x375e4da0], [0, 0x376465c0]]}
  bert_encoder.layer_8_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x376a8620]]}
  bert_encoder.layer_8_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x376b4940], [0, 0x37716160], [0, 0x37777980]]}
  bert_encoder.layer_8_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x377dfb80], [0, 0x378413a0], [0, 0x378a2bc0]]}
  bert_encoder.layer_8_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37906d20]]}
  bert_encoder.layer_8_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37913880], [0, 0x3792bea0]]}
  bert_encoder.layer_8_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x379444c0], [0, 0x379a5ce0], [0, 0x37a07500], [0, 0x37a68d20], [0, 0x37aca540], [0, 0x37b2bd60], [0, 0x37b8d580], [0, 0x37beeda0], [0, 0x37c505c0], [0, 0x37cb1de0], [0, 0x37d13600], [0, 0x37d74e20]]}
  bert_encoder.layer_8_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37dd6640], [0, 0x37e37e60], [0, 0x37e99680], [0, 0x37efaea0], [0, 0x37f5c6c0], [0, 0x37fbdee0], [0, 0x3801f700], [0, 0x38080f20], [0, 0x380e2740], [0, 0x38143f60], [0, 0x381a5780], [0, 0x38206fa0]]}
  bert_encoder.layer_9_attention_output_dense_bias:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3826b100]]}
  bert_encoder.layer_9_attention_self_value_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38277c60]]}
  bert_encoder.layer_9_attention_self_value_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38283f80], [0, 0x382e57a0], [0, 0x38346fc0]]}
  bert_encoder.layer_9_attention_self_key_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x383a9860]]}
  bert_encoder.layer_9_attention_self_key_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x383b5b80], [0, 0x384173a0], [0, 0x38478bc0]]}
  bert_encoder.layer_9_attention_self_query_bias:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x384dac20]]}
  bert_encoder.layer_9_attention_self_query_weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x384e6f40], [0, 0x38548760], [0, 0x385a9f80]]}
  bert_encoder.layer_9_attention_output_dense_weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38612180], [0, 0x386739a0], [0, 0x386d51c0]]}
  bert_encoder.layer_9_output_dense_bias:                                                    {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38739320]]}
  bert_encoder.layer_9_intermediate_dense_bias:                                              {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38745e80], [0, 0x3875e4a0]]}
  bert_encoder.layer_9_intermediate_dense_weight:                                            {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38776ac0], [0, 0x387d82e0], [0, 0x38839b00], [0, 0x3889b320], [0, 0x388fcb40], [0, 0x3895e360], [0, 0x389bfb80], [0, 0x38a213a0], [0, 0x38a82bc0], [0, 0x38ae43e0], [0, 0x38b45c00], [0, 0x38ba7420]]}
  bert_encoder.layer_9_output_dense_weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38c08c40], [0, 0x38c6a460], [0, 0x38ccbc80], [0, 0x38d2d4a0], [0, 0x38d8ecc0], [0, 0x38df04e0], [0, 0x38e51d00], [0, 0x38eb3520], [0, 0x38f14d40], [0, 0x38f76560], [0, 0x38fd7d80], [0, 0x390395a0]]}
  bert_encoder.layer_10_attention_output_dense_bias:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3909d700]]}
  bert_encoder.layer_10_attention_self_value_bias:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x390aa260]]}
  bert_encoder.layer_10_attention_self_value_weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x390b6580], [0, 0x39117da0], [0, 0x391795c0]]}
  bert_encoder.layer_10_attention_self_key_bias:                                             {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x391dbe60]]}
  bert_encoder.layer_10_attention_self_key_weight:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x391e8180], [0, 0x392499a0], [0, 0x392ab1c0]]}
  bert_encoder.layer_10_attention_self_query_bias:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3930d220]]}
  bert_encoder.layer_10_attention_self_query_weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39319540], [0, 0x3937ad60], [0, 0x393dc580]]}
  bert_encoder.layer_10_attention_output_dense_weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39444780], [0, 0x394a5fa0], [0, 0x395077c0]]}
  bert_encoder.layer_10_output_dense_bias:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3956b920]]}
  bert_encoder.layer_10_intermediate_dense_bias:                                             {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39578480], [0, 0x39590aa0]]}
  bert_encoder.layer_10_intermediate_dense_weight:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x395a90c0], [0, 0x3960a8e0], [0, 0x3966c100], [0, 0x396cd920], [0, 0x3972f140], [0, 0x39790960], [0, 0x397f2180], [0, 0x398539a0], [0, 0x398b51c0], [0, 0x399169e0], [0, 0x39978200], [0, 0x399d9a20]]}
  bert_encoder.layer_10_output_dense_weight:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39a3b240], [0, 0x39a9ca60], [0, 0x39afe280], [0, 0x39b5faa0], [0, 0x39bc12c0], [0, 0x39c22ae0], [0, 0x39c84300], [0, 0x39ce5b20], [0, 0x39d47340], [0, 0x39da8b60], [0, 0x39e0a380], [0, 0x39e6bba0]]}
  bert_encoder.layer_11_attention_output_dense_bias:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39ecfd00]]}
  bert_encoder.layer_11_attention_self_value_bias:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39edc860]]}
  bert_encoder.layer_11_attention_self_value_weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39ee8b80], [0, 0x39f4a3a0], [0, 0x39fabbc0]]}
  bert_encoder.layer_11_attention_self_key_bias:                                             {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a00e460]]}
  bert_encoder.layer_11_attention_self_key_weight:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a01a780], [0, 0x3a07bfa0], [0, 0x3a0dd7c0]]}
  bert_encoder.layer_11_attention_self_query_bias:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a13f820]]}
  bert_encoder.layer_11_attention_self_query_weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a14bb40], [0, 0x3a1ad360], [0, 0x3a20eb80]]}
  bert_encoder.layer_11_attention_output_dense_weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a276d80], [0, 0x3a2d85a0], [0, 0x3a339dc0]]}
  bert_encoder.layer_11_output_dense_bias:                                                   {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 24], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a39df20]]}
  bert_encoder.layer_11_intermediate_dense_bias:                                             {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 48], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a3aaa80], [0, 0x3a3c30a0]]}
  bert_encoder.layer_11_intermediate_dense_weight:                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [24, 8], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a3db6c0], [0, 0x3a43cee0], [0, 0x3a49e700], [0, 0x3a4fff20], [0, 0x3a561740], [0, 0x3a5c2f60], [0, 0x3a624780], [0, 0x3a685fa0], [0, 0x3a6e77c0], [0, 0x3a748fe0], [0, 0x3a7aa800], [0, 0x3a80c020]]}
  bert_encoder.layer_11_output_dense_weight:                                                 {input: HOST, type: ram, entries: 1, grid_size: [1, 12], t: 1, mblock: [96, 2], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a86d840], [0, 0x3a8cf060], [0, 0x3a930880], [0, 0x3a9920a0], [0, 0x3a9f38c0], [0, 0x3aa550e0], [0, 0x3aab6900], [0, 0x3ab18120], [0, 0x3ab79940], [0, 0x3abdb160], [0, 0x3ac3c980], [0, 0x3ac9e1a0]]}

  # constant
  lc.input_tensor.bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30000000]]}
  lc.input_tensor.bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3000cb60]]}
  lc.input_tensor.bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300196c0]]}
  lc.input_tensor.bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30026220]]}
  lc.input_tensor.bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.0:              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30032d80]]}
  lc.input_tensor.bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3003f8e0]]}
  lc.input_tensor.bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3004c440]]}
  lc.input_tensor.bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30058fa0]]}
  lc.input_tensor.bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30065b00]]}
  lc.input_tensor.bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30072660]]}
  lc.input_tensor.bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3007f1c0]]}
  lc.input_tensor.bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3008bd20]]}
  lc.input_tensor.bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30098880]]}
  lc.input_tensor.bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300a53e0]]}
  lc.input_tensor.bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300b1f40]]}
  lc.input_tensor.bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300beaa0]]}
  lc.input_tensor.bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300cb600]]}
  lc.input_tensor.bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300d8160]]}
  lc.input_tensor.bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300e4cc0]]}
  lc.input_tensor.bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300f1820]]}
  lc.input_tensor.bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x300fe380]]}
  lc.input_tensor.bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3010aee0]]}
  lc.input_tensor.bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30117a40]]}
  lc.input_tensor.bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301245a0]]}
  lc.input_tensor.bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30131100]]}
  lc.input_tensor.bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3013dc60]]}
  lc.input_tensor.bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3014a7c0]]}
  lc.input_tensor.bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30157320]]}
  lc.input_tensor.bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30163e80]]}
  lc.input_tensor.bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301709e0]]}
  lc.input_tensor.bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3017d540]]}
  lc.input_tensor.bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3018a0a0]]}
  lc.input_tensor.bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30196c00]]}
  lc.input_tensor.bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301a3760]]}
  lc.input_tensor.bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301b02c0]]}
  lc.input_tensor.bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301bce20]]}
  lc.input_tensor.bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301c9980]]}
  lc.input_tensor.bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301d64e0]]}
  lc.input_tensor.bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301e3040]]}
  lc.input_tensor.bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301efba0]]}
  lc.input_tensor.bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x301fc700]]}
  lc.input_tensor.bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30209260]]}
  lc.input_tensor.bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30215dc0]]}
  lc.input_tensor.bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30222920]]}
  lc.input_tensor.bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.0:               {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3022f480]]}
  lc.input_tensor.bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3023bfe0]]}
  lc.input_tensor.bert_encoder.layer_0_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0:     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30248b40]]}
  lc.input_tensor.bert_encoder.layer_0_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0:   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x302556a0]]}
  lc.input_tensor.bert_encoder.layer_0_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30262200]]}
  lc.input_tensor.bert_encoder.layer_0_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3026ed60]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_11_1.0:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x303d0d40]]}
  lc.input_tensor.bert_encoder.layer_0_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x303e3a20]]}
  lc.input_tensor.bert_encoder.layer_0_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30514de0]]}
  constant_1_multiply_17:                                                                    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x306461a0]]}
  lc.input_tensor.softmax_19.dc.reduce_sum.1.0:                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x306469e0]]}
  lc.input_tensor.layernorm_37_mean.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x307713e0]]}
  lc.input_tensor.layernorm_37_var.0:                                                        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30771c20]]}
  constant_1_layernorm_37_var_plus_eps:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30772460]]}
  lc.input_tensor.layernorm_37_recip_s_brcst_m1_0_0.0:                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30772ca0]]}
  lc.input_tensor.bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x307734e0]]}
  lc.input_tensor.bert_encoder.layer_0_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30780040]]}
  lc.input_tensor.layernorm_60_mean.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310d57c0]]}
  lc.input_tensor.layernorm_60_var.0:                                                        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310d6000]]}
  constant_1_layernorm_60_var_plus_eps:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310d6840]]}
  lc.input_tensor.layernorm_60_recip_s_brcst_m1_0_0.0:                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310d7080]]}
  lc.input_tensor.bert_encoder.layer_1_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310d78c0]]}
  lc.input_tensor.bert_encoder.layer_1_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x310e4420]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_10_1.0:                                         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x312157e0]]}
  lc.input_tensor.bert_encoder.layer_1_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31216020]]}
  lc.input_tensor.bert_encoder.layer_1_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x313473e0]]}
  constant_1_multiply_88:                                                                    {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x314787a0]]}
  lc.input_tensor.softmax_90.dc.reduce_sum.1.0:                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31478fe0]]}
  lc.input_tensor.layernorm_108_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315a39e0]]}
  lc.input_tensor.layernorm_108_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315a4220]]}
  constant_1_layernorm_108_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315a4a60]]}
  lc.input_tensor.layernorm_108_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315a52a0]]}
  lc.input_tensor.bert_encoder.layer_1_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315a5ae0]]}
  lc.input_tensor.bert_encoder.layer_1_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x315b2640]]}
  lc.input_tensor.layernorm_131_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f07dc0]]}
  lc.input_tensor.layernorm_131_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f08600]]}
  constant_1_layernorm_131_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f08e40]]}
  lc.input_tensor.layernorm_131_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f09680]]}
  lc.input_tensor.bert_encoder.layer_2_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f09ec0]]}
  lc.input_tensor.bert_encoder.layer_2_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x31f16a20]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_9_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32047de0]]}
  lc.input_tensor.bert_encoder.layer_2_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32048620]]}
  lc.input_tensor.bert_encoder.layer_2_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x321799e0]]}
  constant_1_multiply_159:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x322aada0]]}
  lc.input_tensor.softmax_161.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x322ab5e0]]}
  lc.input_tensor.layernorm_179_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323d5fe0]]}
  lc.input_tensor.layernorm_179_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323d6820]]}
  constant_1_layernorm_179_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323d7060]]}
  lc.input_tensor.layernorm_179_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323d78a0]]}
  lc.input_tensor.bert_encoder.layer_2_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323d80e0]]}
  lc.input_tensor.bert_encoder.layer_2_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x323e4c40]]}
  lc.input_tensor.layernorm_202_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d3a3c0]]}
  lc.input_tensor.layernorm_202_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d3ac00]]}
  constant_1_layernorm_202_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d3b440]]}
  lc.input_tensor.layernorm_202_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d3bc80]]}
  lc.input_tensor.bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d3c4c0]]}
  lc.input_tensor.bert_encoder.layer_3_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32d49020]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_8_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32e7a3e0]]}
  lc.input_tensor.bert_encoder.layer_3_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32e7ac20]]}
  lc.input_tensor.bert_encoder.layer_3_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x32fabfe0]]}
  constant_1_multiply_230:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x330dd3a0]]}
  lc.input_tensor.softmax_232.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x330ddbe0]]}
  lc.input_tensor.layernorm_250_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x332085e0]]}
  lc.input_tensor.layernorm_250_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33208e20]]}
  constant_1_layernorm_250_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33209660]]}
  lc.input_tensor.layernorm_250_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33209ea0]]}
  lc.input_tensor.bert_encoder.layer_3_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3320a6e0]]}
  lc.input_tensor.bert_encoder.layer_3_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33217240]]}
  lc.input_tensor.layernorm_273_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b6c9c0]]}
  lc.input_tensor.layernorm_273_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b6d200]]}
  constant_1_layernorm_273_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b6da40]]}
  lc.input_tensor.layernorm_273_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b6e280]]}
  lc.input_tensor.bert_encoder.layer_4_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b6eac0]]}
  lc.input_tensor.bert_encoder.layer_4_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33b7b620]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_7_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33cac9e0]]}
  lc.input_tensor.bert_encoder.layer_4_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33cad220]]}
  lc.input_tensor.bert_encoder.layer_4_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33dde5e0]]}
  constant_1_multiply_301:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33f0f9a0]]}
  lc.input_tensor.softmax_303.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x33f101e0]]}
  lc.input_tensor.layernorm_321_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3403abe0]]}
  lc.input_tensor.layernorm_321_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3403b420]]}
  constant_1_layernorm_321_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3403bc60]]}
  lc.input_tensor.layernorm_321_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3403c4a0]]}
  lc.input_tensor.bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3403cce0]]}
  lc.input_tensor.bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34049840]]}
  lc.input_tensor.layernorm_344_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3499efc0]]}
  lc.input_tensor.layernorm_344_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3499f800]]}
  constant_1_layernorm_344_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x349a0040]]}
  lc.input_tensor.layernorm_344_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x349a0880]]}
  lc.input_tensor.bert_encoder.layer_5_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x349a10c0]]}
  lc.input_tensor.bert_encoder.layer_5_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x349adc20]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_6_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34adefe0]]}
  lc.input_tensor.bert_encoder.layer_5_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34adf820]]}
  lc.input_tensor.bert_encoder.layer_5_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34c10be0]]}
  constant_1_multiply_372:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34d41fa0]]}
  lc.input_tensor.softmax_374.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34d427e0]]}
  lc.input_tensor.layernorm_392_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e6d1e0]]}
  lc.input_tensor.layernorm_392_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e6da20]]}
  constant_1_layernorm_392_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e6e260]]}
  lc.input_tensor.layernorm_392_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e6eaa0]]}
  lc.input_tensor.bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e6f2e0]]}
  lc.input_tensor.bert_encoder.layer_5_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x34e7be40]]}
  lc.input_tensor.layernorm_415_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357d15c0]]}
  lc.input_tensor.layernorm_415_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357d1e00]]}
  constant_1_layernorm_415_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357d2640]]}
  lc.input_tensor.layernorm_415_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357d2e80]]}
  lc.input_tensor.bert_encoder.layer_6_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357d36c0]]}
  lc.input_tensor.bert_encoder.layer_6_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x357e0220]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_5_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x359115e0]]}
  lc.input_tensor.bert_encoder.layer_6_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35911e20]]}
  lc.input_tensor.bert_encoder.layer_6_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35a431e0]]}
  constant_1_multiply_443:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35b745a0]]}
  lc.input_tensor.softmax_445.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35b74de0]]}
  lc.input_tensor.layernorm_463_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35c9f7e0]]}
  lc.input_tensor.layernorm_463_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35ca0020]]}
  constant_1_layernorm_463_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35ca0860]]}
  lc.input_tensor.layernorm_463_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35ca10a0]]}
  lc.input_tensor.bert_encoder.layer_6_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35ca18e0]]}
  lc.input_tensor.bert_encoder.layer_6_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x35cae440]]}
  lc.input_tensor.layernorm_486_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36603bc0]]}
  lc.input_tensor.layernorm_486_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36604400]]}
  constant_1_layernorm_486_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36604c40]]}
  lc.input_tensor.layernorm_486_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36605480]]}
  lc.input_tensor.bert_encoder.layer_7_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36605cc0]]}
  lc.input_tensor.bert_encoder.layer_7_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36612820]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_4_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36743be0]]}
  lc.input_tensor.bert_encoder.layer_7_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36744420]]}
  lc.input_tensor.bert_encoder.layer_7_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x368757e0]]}
  constant_1_multiply_514:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x369a6ba0]]}
  lc.input_tensor.softmax_516.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x369a73e0]]}
  lc.input_tensor.layernorm_534_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ad1de0]]}
  lc.input_tensor.layernorm_534_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ad2620]]}
  constant_1_layernorm_534_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ad2e60]]}
  lc.input_tensor.layernorm_534_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ad36a0]]}
  lc.input_tensor.bert_encoder.layer_7_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ad3ee0]]}
  lc.input_tensor.bert_encoder.layer_7_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x36ae0a40]]}
  lc.input_tensor.layernorm_557_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x374361c0]]}
  lc.input_tensor.layernorm_557_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37436a00]]}
  constant_1_layernorm_557_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37437240]]}
  lc.input_tensor.layernorm_557_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37437a80]]}
  lc.input_tensor.bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x374382c0]]}
  lc.input_tensor.bert_encoder.layer_8_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37444e20]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_3_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x375761e0]]}
  lc.input_tensor.bert_encoder.layer_8_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37576a20]]}
  lc.input_tensor.bert_encoder.layer_8_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x376a7de0]]}
  constant_1_multiply_585:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x377d91a0]]}
  lc.input_tensor.softmax_587.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x377d99e0]]}
  lc.input_tensor.layernorm_605_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x379043e0]]}
  lc.input_tensor.layernorm_605_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37904c20]]}
  constant_1_layernorm_605_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37905460]]}
  lc.input_tensor.layernorm_605_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37905ca0]]}
  lc.input_tensor.bert_encoder.layer_8_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x379064e0]]}
  lc.input_tensor.bert_encoder.layer_8_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x37913040]]}
  lc.input_tensor.layernorm_628_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x382687c0]]}
  lc.input_tensor.layernorm_628_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38269000]]}
  constant_1_layernorm_628_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38269840]]}
  lc.input_tensor.layernorm_628_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3826a080]]}
  lc.input_tensor.bert_encoder.layer_9_attention_output_dense_bias_s_brcst_m2_0_0.0:         {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3826a8c0]]}
  lc.input_tensor.bert_encoder.layer_9_attention_self_value_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38277420]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_2_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x383a87e0]]}
  lc.input_tensor.bert_encoder.layer_9_attention_self_key_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x383a9020]]}
  lc.input_tensor.bert_encoder.layer_9_attention_self_query_bias_s_brcst_m2_0_0.0:           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x384da3e0]]}
  constant_1_multiply_656:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3860b7a0]]}
  lc.input_tensor.softmax_658.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3860bfe0]]}
  lc.input_tensor.layernorm_676_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x387369e0]]}
  lc.input_tensor.layernorm_676_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38737220]]}
  constant_1_layernorm_676_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38737a60]]}
  lc.input_tensor.layernorm_676_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x387382a0]]}
  lc.input_tensor.bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.0:                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38738ae0]]}
  lc.input_tensor.bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x38745640]]}
  lc.input_tensor.layernorm_699_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3909adc0]]}
  lc.input_tensor.layernorm_699_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3909b600]]}
  constant_1_layernorm_699_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3909be40]]}
  lc.input_tensor.layernorm_699_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3909c680]]}
  lc.input_tensor.bert_encoder.layer_10_attention_output_dense_bias_s_brcst_m2_0_0.0:        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3909cec0]]}
  lc.input_tensor.bert_encoder.layer_10_attention_self_value_bias_s_brcst_m2_0_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x390a9a20]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_1_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x391dade0]]}
  lc.input_tensor.bert_encoder.layer_10_attention_self_key_bias_s_brcst_m2_0_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x391db620]]}
  lc.input_tensor.bert_encoder.layer_10_attention_self_query_bias_s_brcst_m2_0_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3930c9e0]]}
  constant_1_multiply_727:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3943dda0]]}
  lc.input_tensor.softmax_729.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3943e5e0]]}
  lc.input_tensor.layernorm_747_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39568fe0]]}
  lc.input_tensor.layernorm_747_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39569820]]}
  constant_1_layernorm_747_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3956a060]]}
  lc.input_tensor.layernorm_747_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3956a8a0]]}
  lc.input_tensor.bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.0:                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3956b0e0]]}
  lc.input_tensor.bert_encoder.layer_10_intermediate_dense_bias_s_brcst_m2_0_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39577c40]]}
  lc.input_tensor.layernorm_770_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39ecd3c0]]}
  lc.input_tensor.layernorm_770_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39ecdc00]]}
  constant_1_layernorm_770_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39ece440]]}
  lc.input_tensor.layernorm_770_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39ecec80]]}
  lc.input_tensor.bert_encoder.layer_11_attention_output_dense_bias_s_brcst_m2_0_0.0:        {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39ecf4c0]]}
  lc.input_tensor.bert_encoder.layer_11_attention_self_value_bias_s_brcst_m2_0_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x39edc020]]}
  lc.input_tensor.input_1_add_799_s_brcst_m2_0_1.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a00d3e0]]}
  lc.input_tensor.bert_encoder.layer_11_attention_self_key_bias_s_brcst_m2_0_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a00dc20]]}
  lc.input_tensor.bert_encoder.layer_11_attention_self_query_bias_s_brcst_m2_0_0.0:          {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a13efe0]]}
  constant_1_multiply_798:                                                                   {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a2703a0]]}
  lc.input_tensor.softmax_800.dc.reduce_sum.1.0:                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a270be0]]}
  lc.input_tensor.layernorm_818_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a39b5e0]]}
  lc.input_tensor.layernorm_818_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a39be20]]}
  constant_1_layernorm_818_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a39c660]]}
  lc.input_tensor.layernorm_818_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a39cea0]]}
  lc.input_tensor.bert_encoder.layer_11_output_dense_bias_s_brcst_m2_0_0.0:                  {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a39d6e0]]}
  lc.input_tensor.bert_encoder.layer_11_intermediate_dense_bias_s_brcst_m2_0_0.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3a3aa240]]}
  lc.input_tensor.layernorm_841_mean.0:                                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3acff9c0]]}
  lc.input_tensor.layernorm_841_var.0:                                                       {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ad00200]]}
  constant_1_layernorm_841_var_plus_eps:                                                     {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ad00a40]]}
  lc.input_tensor.layernorm_841_recip_s_brcst_m1_0_0.0:                                      {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ad01280]]}

  # epoch_to_epoch
  e2e_gelu_53_0:                                                                             {input: gelu_53, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 16], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x3019e6c0], [3, 0x301860c0], [4, 0x3016dac0]]}
  e2e_bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.lc1_0:                           {input: bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x30130ba0]]}
  e2e_layernorm_37_bias_0:                                                                   {input: layernorm_37_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ae32660]]}
  e2e_bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x301491a0]]}
  e2e_bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x301554a0]]}
  e2e_bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x301617a0]]}
  e2e_bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x301617a0]]}
  e2e_bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x30179da0]]}
  e2e_layernorm_131_weights_0:                                                               {input: layernorm_131_weights, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3016dac0]]}
  e2e_bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x301860a0]]}
  e2e_bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x30118580]]}
  e2e_bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ae1a040]]}
  e2e_bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x30130b80]]}
  e2e_bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 2, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x3013ce80]]}
  e2e_softmax_232.dc.reciprocal.2_0:                                                         {input: softmax_232.dc.reciprocal.2, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [4, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x301df6e0]]}
  e2e_softmax_232.dc.exp.0_0:                                                                {input: softmax_232.dc.exp.0, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 4], ublock: [4, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3013cec0]]}
  e2e_add_237_0:                                                                             {input: add_237, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ae63280]]}
  e2e_bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.lc1_0:                 {input: bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x301554c0]]}
  e2e_layernorm_202_bias_0:                                                                  {input: layernorm_202_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x301617c0]]}
  e2e_bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 3, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3013ce80]]}
  e2e_bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 3, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x3013ce80]]}
  e2e_bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 3, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x30155480]]}
  e2e_bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 3, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x30161780]]}
  e2e_bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 3, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x300f3c60]]}
  e2e_bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 3, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3adf5720]]}
  e2e_layernorm_321_bias_0:                                                                  {input: layernorm_321_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x301c70e0]]}
  e2e_bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 24], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x301923e0], [7, 0x301617e0]]}
  e2e_bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.lc1_0:                           {input: bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3019e6e0]]}
  e2e_layernorm_321_bias_1:                                                                  {input: layernorm_321_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x301aeae0]]}
  e2e_bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x300fff60]]}
  e2e_bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x3010c260]]}
  e2e_bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3010c260]]}
  e2e_bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 4, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x3010c260]]}
  e2e_gelu_408_0:                                                                            {input: gelu_408, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 16], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x301f7d00], [3, 0x301f7d00], [4, 0x301df700]]}
  e2e_bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.lc1_0:                           {input: bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3019e6e0]]}
  e2e_layernorm_392_bias_0:                                                                  {input: layernorm_392_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ae93ea0]]}
  e2e_bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 5, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x30118560]]}
  e2e_bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 5, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x30124860]]}
  e2e_bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 5, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x300b6d40]]}
  e2e_bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 5, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3adb8800]]}
  e2e_bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 5, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x300c3040]]}
  e2e_layernorm_486_weights_0:                                                               {input: layernorm_486_weights, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x301aaa00]]}
  e2e_bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 6, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x300c3040]]}
  e2e_bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 6, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x300c3040]]}
  e2e_bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 6, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x300c3040]]}
  e2e_bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 6, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x300cf340]]}
  e2e_bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 6, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x300db640]]}
  e2e_softmax_587.dc.reciprocal.2_0:                                                         {input: softmax_587.dc.reciprocal.2, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 1], ublock: [4, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x30238d20]]}
  e2e_softmax_587.dc.exp.0_0:                                                                {input: softmax_587.dc.exp.0, type: queue, entries: 1, grid_size: [1, 1], t: 12, mblock: [1, 4], ublock: [4, 1], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x301aaa00]]}
  e2e_add_592_0:                                                                             {input: add_592, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3aec4ac0]]}
  e2e_bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.lc1_0:                 {input: bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x30179e00]]}
  e2e_layernorm_557_bias_0:                                                                  {input: layernorm_557_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x301aaa00]]}
  e2e_bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 7, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x30061820]]}
  e2e_bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 7, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ad632e0]]}
  e2e_bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 7, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x3006db20]]}
  e2e_bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 7, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x3006db20]]}
  e2e_bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:           {input: bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 7, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x3006db20]]}
  e2e_bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:             {input: bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 7, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x3006db20]]}
  e2e_layernorm_676_bias_0:                                                                  {input: layernorm_676_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x30238d20]]}
  e2e_bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 24], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x301db620], [7, 0x30186120]]}
  e2e_bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.lc1_0:                           {input: bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x301db620]]}
  e2e_layernorm_676_bias_1:                                                                  {input: layernorm_676_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x30220720]]}
  e2e_bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                     {input: bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 8, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x3006db20]]}
  e2e_bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                       {input: bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 8, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x30079e20]]}
  e2e_bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:          {input: bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 8, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x30000000]]}
  e2e_bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:            {input: bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 8, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3ad01ac0]]}
  e2e_gelu_763_0:                                                                            {input: gelu_763, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 16], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x30251340], [3, 0x30269940], [4, 0x30251340]]}
  e2e_bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.lc1_0:                          {input: bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x3020c220]]}
  e2e_layernorm_747_bias_0:                                                                  {input: layernorm_747_bias, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [4, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x3aef56e0]]}
  e2e_bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                    {input: bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 9, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[7, 0x30000000]]}
  e2e_bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                      {input: bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 9, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[6, 0x30000000]]}
  e2e_bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:          {input: bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 9, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x30000000]]}
  e2e_bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:            {input: bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 9, grid_size: [1, 1], t: 1, mblock: [1, 12], ublock: [1, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x30000000]]}
  e2e_bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0:                    {input: bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.lc1, type: queue, entries: 9, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 8], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x30000000]]}
  e2e_layernorm_841_weights_0:                                                               {input: layernorm_841_weights, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [4, 3], ublock: [1, 8], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x301e7940]]}
  e2e_bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0:                      {input: bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.lc1, type: queue, entries: 10, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 8], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x30000000]]}

graphs:
  fwd_0:
    target_device: 0
    input_count: 1
    bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_output_LayerNorm_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_11_output_LayerNorm_weight],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_11_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_10_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_10_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 9], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_9_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 10], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 11], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_9_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_8_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_8_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_7_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_7_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 9], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_6_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 10], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 11], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_6_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_5_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_5_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_4_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_4_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 9], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_3_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 10], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 11], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_3_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_2_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 3], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_2_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 4], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_1_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_1_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 9], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_0_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 10], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_attention_output_LayerNorm_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 11], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0, bert_encoder.layer_0_attention_output_LayerNorm_weight],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_22: {type: matmul, grid_loc: [4, 2], grid_size: [1, 3], inputs: [input_1_add_36, bert_encoder.layer_0_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_24: {type: add, grid_loc: [4, 5], grid_size: [1, 1], inputs: [matmul_22, bert_encoder.layer_0_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_11_1.lc1: {type: matmul, grid_loc: [4, 6], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_11_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_8: {type: matmul, grid_loc: [4, 8], grid_size: [1, 3], inputs: [input_1_add_36, bert_encoder.layer_0_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_10: {type: add, grid_loc: [4, 11], grid_size: [1, 1], inputs: [matmul_8, bert_encoder.layer_0_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_0_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 0], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_2: {type: matmul, grid_loc: [5, 1], grid_size: [1, 3], inputs: [input_1_add_36, bert_encoder.layer_0_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_4: {type: add, grid_loc: [5, 4], grid_size: [1, 1], inputs: [matmul_2, bert_encoder.layer_0_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_14: {type: matmul, grid_loc: [5, 5], grid_size: [1, 1], inputs: [add_4, add_10],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_17: {type: multiply, grid_loc: [5, 6], grid_size: [1, 1], inputs: [matmul_14, constant_1_multiply_17],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_18: {type: add, grid_loc: [5, 7], grid_size: [1, 1], inputs: [multiply_17, input_1_add_799_s_brcst_m2_11_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_19.dc.exp.0: {type: exp, grid_loc: [5, 8], grid_size: [1, 1], inputs: [add_18],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_19.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [5, 9], grid_size: [1, 1], inputs: [softmax_19.dc.exp.0, lc.input_tensor.softmax_19.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_19.dc.reciprocal.2: {type: reciprocal, grid_loc: [5, 10], grid_size: [1, 1], inputs: [softmax_19.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_19.dc.multiply.3: {type: multiply, grid_loc: [5, 11], grid_size: [1, 1], inputs: [softmax_19.dc.exp.0, softmax_19.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_29: {type: matmul, grid_loc: [6, 0], grid_size: [1, 1], inputs: [softmax_19.dc.multiply.3, add_24],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_33: {type: matmul, grid_loc: [6, 1], grid_size: [1, 3], inputs: [matmul_29, bert_encoder.layer_0_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_35: {type: add, grid_loc: [6, 4], grid_size: [1, 1], inputs: [matmul_33, bert_encoder.layer_0_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_36: {type: add, grid_loc: [6, 5], grid_size: [1, 1], inputs: [add_35, input_1_add_36],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_37_mean.lc1: {type: matmul, grid_loc: [6, 6], grid_size: [1, 1], inputs: [add_36, lc.input_tensor.layernorm_37_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_37_sub: {type: subtract, grid_loc: [6, 7], grid_size: [1, 1], inputs: [add_36, layernorm_37_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_37_sq: {type: multiply, grid_loc: [6, 8], grid_size: [1, 1], inputs: [layernorm_37_sub, layernorm_37_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_37_var.lc1: {type: matmul, grid_loc: [6, 9], grid_size: [1, 1], inputs: [layernorm_37_sq, lc.input_tensor.layernorm_37_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_37_var_plus_eps: {type: add, grid_loc: [6, 10], grid_size: [1, 1], inputs: [layernorm_37_var.lc1, constant_1_layernorm_37_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_37_sqrt: {type: sqrt, grid_loc: [6, 11], grid_size: [1, 1], inputs: [layernorm_37_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_37_recip: {type: reciprocal, grid_loc: [7, 0], grid_size: [1, 1], inputs: [layernorm_37_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_37_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [7, 1], grid_size: [1, 1], inputs: [layernorm_37_recip, lc.input_tensor.layernorm_37_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_37_output: {type: multiply, grid_loc: [7, 2], grid_size: [1, 1], inputs: [layernorm_37_sub, layernorm_37_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_37_weights: {type: multiply, grid_loc: [7, 3], grid_size: [1, 1], inputs: [layernorm_37_output, bert_encoder.layer_0_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_37_bias: {type: add, grid_loc: [7, 4], grid_size: [1, 1], inputs: [layernorm_37_weights, bert_encoder.layer_0_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 5], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_0_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 6], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_0_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_0_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_50: {type: matmul, grid_loc: [8, 0], grid_size: [1, 12], inputs: [layernorm_37_bias, bert_encoder.layer_0_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_52: {type: add, grid_loc: [9, 0], grid_size: [1, 3], inputs: [matmul_50, bert_encoder.layer_0_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_53: {type: gelu, grid_loc: [9, 3], grid_size: [1, 3], inputs: [add_52],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_1:
    target_device: 0
    input_count: 1
    matmul_56: {type: matmul, grid_loc: [0, 0], grid_size: [1, 12], inputs: [e2e_gelu_53_0, bert_encoder.layer_0_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_58: {type: add, grid_loc: [1, 0], grid_size: [1, 1], inputs: [matmul_56, e2e_bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_59: {type: add, grid_loc: [1, 1], grid_size: [1, 1], inputs: [add_58, e2e_layernorm_37_bias_0],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_60_mean.lc1: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [add_59, lc.input_tensor.layernorm_60_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_60_sub: {type: subtract, grid_loc: [1, 3], grid_size: [1, 1], inputs: [add_59, layernorm_60_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_60_sq: {type: multiply, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layernorm_60_sub, layernorm_60_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_60_var.lc1: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [layernorm_60_sq, lc.input_tensor.layernorm_60_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_60_var_plus_eps: {type: add, grid_loc: [1, 6], grid_size: [1, 1], inputs: [layernorm_60_var.lc1, constant_1_layernorm_60_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_60_sqrt: {type: sqrt, grid_loc: [1, 7], grid_size: [1, 1], inputs: [layernorm_60_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_60_recip: {type: reciprocal, grid_loc: [1, 8], grid_size: [1, 1], inputs: [layernorm_60_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_60_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [1, 9], grid_size: [1, 1], inputs: [layernorm_60_recip, lc.input_tensor.layernorm_60_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_60_output: {type: multiply, grid_loc: [1, 10], grid_size: [1, 1], inputs: [layernorm_60_sub, layernorm_60_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_60_weights: {type: multiply, grid_loc: [1, 11], grid_size: [1, 1], inputs: [layernorm_60_output, e2e_bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_60_bias: {type: add, grid_loc: [2, 0], grid_size: [1, 1], inputs: [layernorm_60_weights, e2e_bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_1_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_1_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_93: {type: matmul, grid_loc: [2, 3], grid_size: [1, 3], inputs: [layernorm_60_bias, bert_encoder.layer_1_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_95: {type: add, grid_loc: [2, 6], grid_size: [1, 1], inputs: [matmul_93, bert_encoder.layer_1_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_10_1.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_10_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_1_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_79: {type: matmul, grid_loc: [2, 9], grid_size: [1, 3], inputs: [layernorm_60_bias, bert_encoder.layer_1_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_81: {type: add, grid_loc: [3, 0], grid_size: [1, 1], inputs: [matmul_79, bert_encoder.layer_1_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_1_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_73: {type: matmul, grid_loc: [3, 2], grid_size: [1, 3], inputs: [layernorm_60_bias, bert_encoder.layer_1_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_75: {type: add, grid_loc: [3, 5], grid_size: [1, 1], inputs: [matmul_73, bert_encoder.layer_1_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_85: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [add_75, add_81],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_88: {type: multiply, grid_loc: [3, 7], grid_size: [1, 1], inputs: [matmul_85, constant_1_multiply_88],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_89: {type: add, grid_loc: [3, 8], grid_size: [1, 1], inputs: [multiply_88, input_1_add_799_s_brcst_m2_10_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_90.dc.exp.0: {type: exp, grid_loc: [3, 9], grid_size: [1, 1], inputs: [add_89],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_90.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [3, 10], grid_size: [1, 1], inputs: [softmax_90.dc.exp.0, lc.input_tensor.softmax_90.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_90.dc.reciprocal.2: {type: reciprocal, grid_loc: [3, 11], grid_size: [1, 1], inputs: [softmax_90.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_90.dc.multiply.3: {type: multiply, grid_loc: [4, 0], grid_size: [1, 1], inputs: [softmax_90.dc.exp.0, softmax_90.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_100: {type: matmul, grid_loc: [4, 1], grid_size: [1, 1], inputs: [softmax_90.dc.multiply.3, add_95],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_104: {type: matmul, grid_loc: [4, 2], grid_size: [1, 3], inputs: [matmul_100, bert_encoder.layer_1_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_106: {type: add, grid_loc: [4, 5], grid_size: [1, 1], inputs: [matmul_104, bert_encoder.layer_1_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_107: {type: add, grid_loc: [4, 6], grid_size: [1, 1], inputs: [add_106, layernorm_60_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_108_mean.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [add_107, lc.input_tensor.layernorm_108_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_108_sub: {type: subtract, grid_loc: [4, 8], grid_size: [1, 1], inputs: [add_107, layernorm_108_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_108_sq: {type: multiply, grid_loc: [4, 9], grid_size: [1, 1], inputs: [layernorm_108_sub, layernorm_108_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_108_var.lc1: {type: matmul, grid_loc: [4, 10], grid_size: [1, 1], inputs: [layernorm_108_sq, lc.input_tensor.layernorm_108_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_108_var_plus_eps: {type: add, grid_loc: [4, 11], grid_size: [1, 1], inputs: [layernorm_108_var.lc1, constant_1_layernorm_108_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_108_sqrt: {type: sqrt, grid_loc: [5, 0], grid_size: [1, 1], inputs: [layernorm_108_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_108_recip: {type: reciprocal, grid_loc: [5, 1], grid_size: [1, 1], inputs: [layernorm_108_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_108_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [layernorm_108_recip, lc.input_tensor.layernorm_108_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_108_output: {type: multiply, grid_loc: [5, 3], grid_size: [1, 1], inputs: [layernorm_108_sub, layernorm_108_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_108_weights: {type: multiply, grid_loc: [5, 4], grid_size: [1, 1], inputs: [layernorm_108_output, e2e_bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_108_bias: {type: add, grid_loc: [5, 5], grid_size: [1, 1], inputs: [layernorm_108_weights, e2e_bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_1_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_1_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_1_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_1_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_1_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_121: {type: matmul, grid_loc: [6, 0], grid_size: [1, 12], inputs: [layernorm_108_bias, bert_encoder.layer_1_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_123: {type: add, grid_loc: [7, 0], grid_size: [1, 3], inputs: [matmul_121, bert_encoder.layer_1_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_124: {type: gelu, grid_loc: [7, 3], grid_size: [1, 3], inputs: [add_123],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_127: {type: matmul, grid_loc: [8, 0], grid_size: [1, 12], inputs: [gelu_124, bert_encoder.layer_1_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_129: {type: add, grid_loc: [9, 0], grid_size: [1, 1], inputs: [matmul_127, bert_encoder.layer_1_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_130: {type: add, grid_loc: [9, 1], grid_size: [1, 1], inputs: [add_129, layernorm_108_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_131_mean.lc1: {type: matmul, grid_loc: [9, 2], grid_size: [1, 1], inputs: [add_130, lc.input_tensor.layernorm_131_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_131_sub: {type: subtract, grid_loc: [9, 3], grid_size: [1, 1], inputs: [add_130, layernorm_131_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_131_sq: {type: multiply, grid_loc: [9, 4], grid_size: [1, 1], inputs: [layernorm_131_sub, layernorm_131_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_131_var.lc1: {type: matmul, grid_loc: [9, 5], grid_size: [1, 1], inputs: [layernorm_131_sq, lc.input_tensor.layernorm_131_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_131_var_plus_eps: {type: add, grid_loc: [9, 6], grid_size: [1, 1], inputs: [layernorm_131_var.lc1, constant_1_layernorm_131_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_131_sqrt: {type: sqrt, grid_loc: [9, 7], grid_size: [1, 1], inputs: [layernorm_131_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_131_recip: {type: reciprocal, grid_loc: [9, 8], grid_size: [1, 1], inputs: [layernorm_131_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_131_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [9, 9], grid_size: [1, 1], inputs: [layernorm_131_recip, lc.input_tensor.layernorm_131_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_131_output: {type: multiply, grid_loc: [9, 10], grid_size: [1, 1], inputs: [layernorm_131_sub, layernorm_131_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_131_weights: {type: multiply, grid_loc: [9, 11], grid_size: [1, 1], inputs: [layernorm_131_output, e2e_bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}

  fwd_2:
    target_device: 0
    input_count: 1
    layernorm_131_bias: {type: add, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e_layernorm_131_weights_0, e2e_bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_2_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_2_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_164: {type: matmul, grid_loc: [0, 3], grid_size: [1, 3], inputs: [layernorm_131_bias, bert_encoder.layer_2_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_166: {type: add, grid_loc: [0, 6], grid_size: [1, 1], inputs: [matmul_164, bert_encoder.layer_2_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_9_1.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_9_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_2_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_150: {type: matmul, grid_loc: [0, 9], grid_size: [1, 3], inputs: [layernorm_131_bias, bert_encoder.layer_2_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_152: {type: add, grid_loc: [1, 0], grid_size: [1, 1], inputs: [matmul_150, bert_encoder.layer_2_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_2_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_144: {type: matmul, grid_loc: [1, 2], grid_size: [1, 3], inputs: [layernorm_131_bias, bert_encoder.layer_2_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_146: {type: add, grid_loc: [1, 5], grid_size: [1, 1], inputs: [matmul_144, bert_encoder.layer_2_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_156: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [add_146, add_152],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_159: {type: multiply, grid_loc: [1, 7], grid_size: [1, 1], inputs: [matmul_156, constant_1_multiply_159],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_160: {type: add, grid_loc: [1, 8], grid_size: [1, 1], inputs: [multiply_159, input_1_add_799_s_brcst_m2_9_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_161.dc.exp.0: {type: exp, grid_loc: [1, 9], grid_size: [1, 1], inputs: [add_160],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_161.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [1, 10], grid_size: [1, 1], inputs: [softmax_161.dc.exp.0, lc.input_tensor.softmax_161.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_161.dc.reciprocal.2: {type: reciprocal, grid_loc: [1, 11], grid_size: [1, 1], inputs: [softmax_161.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_161.dc.multiply.3: {type: multiply, grid_loc: [2, 0], grid_size: [1, 1], inputs: [softmax_161.dc.exp.0, softmax_161.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_171: {type: matmul, grid_loc: [2, 1], grid_size: [1, 1], inputs: [softmax_161.dc.multiply.3, add_166],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_175: {type: matmul, grid_loc: [2, 2], grid_size: [1, 3], inputs: [matmul_171, bert_encoder.layer_2_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_177: {type: add, grid_loc: [2, 5], grid_size: [1, 1], inputs: [matmul_175, bert_encoder.layer_2_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_178: {type: add, grid_loc: [2, 6], grid_size: [1, 1], inputs: [add_177, layernorm_131_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_179_mean.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [add_178, lc.input_tensor.layernorm_179_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_179_sub: {type: subtract, grid_loc: [2, 8], grid_size: [1, 1], inputs: [add_178, layernorm_179_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_179_sq: {type: multiply, grid_loc: [2, 9], grid_size: [1, 1], inputs: [layernorm_179_sub, layernorm_179_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_179_var.lc1: {type: matmul, grid_loc: [2, 10], grid_size: [1, 1], inputs: [layernorm_179_sq, lc.input_tensor.layernorm_179_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_179_var_plus_eps: {type: add, grid_loc: [2, 11], grid_size: [1, 1], inputs: [layernorm_179_var.lc1, constant_1_layernorm_179_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_179_sqrt: {type: sqrt, grid_loc: [3, 0], grid_size: [1, 1], inputs: [layernorm_179_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_179_recip: {type: reciprocal, grid_loc: [3, 1], grid_size: [1, 1], inputs: [layernorm_179_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_179_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [3, 2], grid_size: [1, 1], inputs: [layernorm_179_recip, lc.input_tensor.layernorm_179_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_179_output: {type: multiply, grid_loc: [3, 3], grid_size: [1, 1], inputs: [layernorm_179_sub, layernorm_179_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_179_weights: {type: multiply, grid_loc: [3, 4], grid_size: [1, 1], inputs: [layernorm_179_output, e2e_bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_179_bias: {type: add, grid_loc: [3, 5], grid_size: [1, 1], inputs: [layernorm_179_weights, e2e_bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_2_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_2_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_2_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_2_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_2_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_192: {type: matmul, grid_loc: [4, 0], grid_size: [1, 12], inputs: [layernorm_179_bias, bert_encoder.layer_2_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_194: {type: add, grid_loc: [5, 0], grid_size: [1, 3], inputs: [matmul_192, bert_encoder.layer_2_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_195: {type: gelu, grid_loc: [5, 3], grid_size: [1, 3], inputs: [add_194],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_198: {type: matmul, grid_loc: [6, 0], grid_size: [1, 12], inputs: [gelu_195, bert_encoder.layer_2_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_200: {type: add, grid_loc: [7, 0], grid_size: [1, 1], inputs: [matmul_198, bert_encoder.layer_2_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_201: {type: add, grid_loc: [7, 1], grid_size: [1, 1], inputs: [add_200, layernorm_179_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_202_mean.lc1: {type: matmul, grid_loc: [7, 2], grid_size: [1, 1], inputs: [add_201, lc.input_tensor.layernorm_202_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_202_sub: {type: subtract, grid_loc: [7, 3], grid_size: [1, 1], inputs: [add_201, layernorm_202_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_202_sq: {type: multiply, grid_loc: [7, 4], grid_size: [1, 1], inputs: [layernorm_202_sub, layernorm_202_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_202_var.lc1: {type: matmul, grid_loc: [7, 5], grid_size: [1, 1], inputs: [layernorm_202_sq, lc.input_tensor.layernorm_202_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_202_var_plus_eps: {type: add, grid_loc: [7, 6], grid_size: [1, 1], inputs: [layernorm_202_var.lc1, constant_1_layernorm_202_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_202_sqrt: {type: sqrt, grid_loc: [7, 7], grid_size: [1, 1], inputs: [layernorm_202_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_202_recip: {type: reciprocal, grid_loc: [7, 8], grid_size: [1, 1], inputs: [layernorm_202_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_202_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [7, 9], grid_size: [1, 1], inputs: [layernorm_202_recip, lc.input_tensor.layernorm_202_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_202_output: {type: multiply, grid_loc: [7, 10], grid_size: [1, 1], inputs: [layernorm_202_sub, layernorm_202_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_202_weights: {type: multiply, grid_loc: [7, 11], grid_size: [1, 1], inputs: [layernorm_202_output, e2e_bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_202_bias: {type: add, grid_loc: [8, 0], grid_size: [1, 1], inputs: [layernorm_202_weights, e2e_bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [8, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_3_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [8, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_235: {type: matmul, grid_loc: [8, 3], grid_size: [1, 3], inputs: [layernorm_202_bias, bert_encoder.layer_3_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_237: {type: add, grid_loc: [8, 6], grid_size: [1, 1], inputs: [matmul_235, bert_encoder.layer_3_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_8_1.lc1: {type: matmul, grid_loc: [8, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_8_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_3_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [8, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_221: {type: matmul, grid_loc: [8, 9], grid_size: [1, 3], inputs: [layernorm_202_bias, bert_encoder.layer_3_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_223: {type: add, grid_loc: [9, 0], grid_size: [1, 1], inputs: [matmul_221, bert_encoder.layer_3_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_3_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [9, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_215: {type: matmul, grid_loc: [9, 2], grid_size: [1, 3], inputs: [layernorm_202_bias, bert_encoder.layer_3_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_217: {type: add, grid_loc: [9, 5], grid_size: [1, 1], inputs: [matmul_215, bert_encoder.layer_3_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_227: {type: matmul, grid_loc: [9, 6], grid_size: [1, 1], inputs: [add_217, add_223],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_230: {type: multiply, grid_loc: [9, 7], grid_size: [1, 1], inputs: [matmul_227, constant_1_multiply_230],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_231: {type: add, grid_loc: [9, 8], grid_size: [1, 1], inputs: [multiply_230, input_1_add_799_s_brcst_m2_8_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_232.dc.exp.0: {type: exp, grid_loc: [9, 9], grid_size: [1, 1], inputs: [add_231],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_232.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [9, 10], grid_size: [1, 1], inputs: [softmax_232.dc.exp.0, lc.input_tensor.softmax_232.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_232.dc.reciprocal.2: {type: reciprocal, grid_loc: [9, 11], grid_size: [1, 1], inputs: [softmax_232.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_3:
    target_device: 0
    input_count: 1
    softmax_232.dc.multiply.3: {type: multiply, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e_softmax_232.dc.exp.0_0, e2e_softmax_232.dc.reciprocal.2_0],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_242: {type: matmul, grid_loc: [0, 1], grid_size: [1, 1], inputs: [softmax_232.dc.multiply.3, e2e_add_237_0],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_246: {type: matmul, grid_loc: [0, 2], grid_size: [1, 3], inputs: [matmul_242, bert_encoder.layer_3_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_248: {type: add, grid_loc: [0, 5], grid_size: [1, 1], inputs: [matmul_246, e2e_bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_249: {type: add, grid_loc: [0, 6], grid_size: [1, 1], inputs: [add_248, e2e_layernorm_202_bias_0],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_250_mean.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [add_249, lc.input_tensor.layernorm_250_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_250_sub: {type: subtract, grid_loc: [0, 8], grid_size: [1, 1], inputs: [add_249, layernorm_250_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_250_sq: {type: multiply, grid_loc: [0, 9], grid_size: [1, 1], inputs: [layernorm_250_sub, layernorm_250_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_250_var.lc1: {type: matmul, grid_loc: [0, 10], grid_size: [1, 1], inputs: [layernorm_250_sq, lc.input_tensor.layernorm_250_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_250_var_plus_eps: {type: add, grid_loc: [0, 11], grid_size: [1, 1], inputs: [layernorm_250_var.lc1, constant_1_layernorm_250_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_250_sqrt: {type: sqrt, grid_loc: [1, 0], grid_size: [1, 1], inputs: [layernorm_250_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_250_recip: {type: reciprocal, grid_loc: [1, 1], grid_size: [1, 1], inputs: [layernorm_250_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_250_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [layernorm_250_recip, lc.input_tensor.layernorm_250_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_250_output: {type: multiply, grid_loc: [1, 3], grid_size: [1, 1], inputs: [layernorm_250_sub, layernorm_250_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_250_weights: {type: multiply, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layernorm_250_output, e2e_bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_250_bias: {type: add, grid_loc: [1, 5], grid_size: [1, 1], inputs: [layernorm_250_weights, e2e_bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_3_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_3_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_3_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_3_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_3_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_263: {type: matmul, grid_loc: [2, 0], grid_size: [1, 12], inputs: [layernorm_250_bias, bert_encoder.layer_3_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_265: {type: add, grid_loc: [3, 0], grid_size: [1, 3], inputs: [matmul_263, bert_encoder.layer_3_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_266: {type: gelu, grid_loc: [3, 3], grid_size: [1, 3], inputs: [add_265],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_269: {type: matmul, grid_loc: [4, 0], grid_size: [1, 12], inputs: [gelu_266, bert_encoder.layer_3_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_271: {type: add, grid_loc: [5, 0], grid_size: [1, 1], inputs: [matmul_269, bert_encoder.layer_3_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_272: {type: add, grid_loc: [5, 1], grid_size: [1, 1], inputs: [add_271, layernorm_250_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_273_mean.lc1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [add_272, lc.input_tensor.layernorm_273_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_273_sub: {type: subtract, grid_loc: [5, 3], grid_size: [1, 1], inputs: [add_272, layernorm_273_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_273_sq: {type: multiply, grid_loc: [5, 4], grid_size: [1, 1], inputs: [layernorm_273_sub, layernorm_273_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_273_var.lc1: {type: matmul, grid_loc: [5, 5], grid_size: [1, 1], inputs: [layernorm_273_sq, lc.input_tensor.layernorm_273_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_273_var_plus_eps: {type: add, grid_loc: [5, 6], grid_size: [1, 1], inputs: [layernorm_273_var.lc1, constant_1_layernorm_273_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_273_sqrt: {type: sqrt, grid_loc: [5, 7], grid_size: [1, 1], inputs: [layernorm_273_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_273_recip: {type: reciprocal, grid_loc: [5, 8], grid_size: [1, 1], inputs: [layernorm_273_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_273_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [5, 9], grid_size: [1, 1], inputs: [layernorm_273_recip, lc.input_tensor.layernorm_273_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_273_output: {type: multiply, grid_loc: [5, 10], grid_size: [1, 1], inputs: [layernorm_273_sub, layernorm_273_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_273_weights: {type: multiply, grid_loc: [5, 11], grid_size: [1, 1], inputs: [layernorm_273_output, e2e_bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_273_bias: {type: add, grid_loc: [6, 0], grid_size: [1, 1], inputs: [layernorm_273_weights, e2e_bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_4_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [6, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_4_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [6, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_306: {type: matmul, grid_loc: [6, 3], grid_size: [1, 3], inputs: [layernorm_273_bias, bert_encoder.layer_4_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_308: {type: add, grid_loc: [6, 6], grid_size: [1, 1], inputs: [matmul_306, bert_encoder.layer_4_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_7_1.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_7_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_4_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [6, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_292: {type: matmul, grid_loc: [6, 9], grid_size: [1, 3], inputs: [layernorm_273_bias, bert_encoder.layer_4_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_294: {type: add, grid_loc: [7, 0], grid_size: [1, 1], inputs: [matmul_292, bert_encoder.layer_4_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_4_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_286: {type: matmul, grid_loc: [7, 2], grid_size: [1, 3], inputs: [layernorm_273_bias, bert_encoder.layer_4_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_288: {type: add, grid_loc: [7, 5], grid_size: [1, 1], inputs: [matmul_286, bert_encoder.layer_4_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_298: {type: matmul, grid_loc: [7, 6], grid_size: [1, 1], inputs: [add_288, add_294],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_301: {type: multiply, grid_loc: [7, 7], grid_size: [1, 1], inputs: [matmul_298, constant_1_multiply_301],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_302: {type: add, grid_loc: [7, 8], grid_size: [1, 1], inputs: [multiply_301, input_1_add_799_s_brcst_m2_7_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_303.dc.exp.0: {type: exp, grid_loc: [7, 9], grid_size: [1, 1], inputs: [add_302],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_303.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [7, 10], grid_size: [1, 1], inputs: [softmax_303.dc.exp.0, lc.input_tensor.softmax_303.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_303.dc.reciprocal.2: {type: reciprocal, grid_loc: [7, 11], grid_size: [1, 1], inputs: [softmax_303.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_303.dc.multiply.3: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [softmax_303.dc.exp.0, softmax_303.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_313: {type: matmul, grid_loc: [8, 1], grid_size: [1, 1], inputs: [softmax_303.dc.multiply.3, add_308],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_317: {type: matmul, grid_loc: [8, 2], grid_size: [1, 3], inputs: [matmul_313, bert_encoder.layer_4_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_319: {type: add, grid_loc: [8, 5], grid_size: [1, 1], inputs: [matmul_317, bert_encoder.layer_4_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_320: {type: add, grid_loc: [8, 6], grid_size: [1, 1], inputs: [add_319, layernorm_273_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_321_mean.lc1: {type: matmul, grid_loc: [8, 7], grid_size: [1, 1], inputs: [add_320, lc.input_tensor.layernorm_321_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_321_sub: {type: subtract, grid_loc: [8, 8], grid_size: [1, 1], inputs: [add_320, layernorm_321_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_321_sq: {type: multiply, grid_loc: [8, 9], grid_size: [1, 1], inputs: [layernorm_321_sub, layernorm_321_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_321_var.lc1: {type: matmul, grid_loc: [8, 10], grid_size: [1, 1], inputs: [layernorm_321_sq, lc.input_tensor.layernorm_321_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_321_var_plus_eps: {type: add, grid_loc: [8, 11], grid_size: [1, 1], inputs: [layernorm_321_var.lc1, constant_1_layernorm_321_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_321_sqrt: {type: sqrt, grid_loc: [9, 0], grid_size: [1, 1], inputs: [layernorm_321_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_321_recip: {type: reciprocal, grid_loc: [9, 1], grid_size: [1, 1], inputs: [layernorm_321_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_321_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [9, 2], grid_size: [1, 1], inputs: [layernorm_321_recip, lc.input_tensor.layernorm_321_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_321_output: {type: multiply, grid_loc: [9, 3], grid_size: [1, 1], inputs: [layernorm_321_sub, layernorm_321_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_321_weights: {type: multiply, grid_loc: [9, 4], grid_size: [1, 1], inputs: [layernorm_321_output, e2e_bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_321_bias: {type: add, grid_loc: [9, 5], grid_size: [1, 1], inputs: [layernorm_321_weights, e2e_bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [9, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [9, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_4_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}

  fwd_4:
    target_device: 0
    input_count: 1
    matmul_334: {type: matmul, grid_loc: [0, 0], grid_size: [1, 12], inputs: [e2e_layernorm_321_bias_0, bert_encoder.layer_4_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_336: {type: add, grid_loc: [1, 0], grid_size: [1, 3], inputs: [matmul_334, e2e_bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_337: {type: gelu, grid_loc: [1, 3], grid_size: [1, 3], inputs: [add_336],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_340: {type: matmul, grid_loc: [2, 0], grid_size: [1, 12], inputs: [gelu_337, bert_encoder.layer_4_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_342: {type: add, grid_loc: [3, 0], grid_size: [1, 1], inputs: [matmul_340, e2e_bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_343: {type: add, grid_loc: [3, 1], grid_size: [1, 1], inputs: [add_342, e2e_layernorm_321_bias_1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_344_mean.lc1: {type: matmul, grid_loc: [3, 2], grid_size: [1, 1], inputs: [add_343, lc.input_tensor.layernorm_344_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_344_sub: {type: subtract, grid_loc: [3, 3], grid_size: [1, 1], inputs: [add_343, layernorm_344_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_344_sq: {type: multiply, grid_loc: [3, 4], grid_size: [1, 1], inputs: [layernorm_344_sub, layernorm_344_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_344_var.lc1: {type: matmul, grid_loc: [3, 5], grid_size: [1, 1], inputs: [layernorm_344_sq, lc.input_tensor.layernorm_344_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_344_var_plus_eps: {type: add, grid_loc: [3, 6], grid_size: [1, 1], inputs: [layernorm_344_var.lc1, constant_1_layernorm_344_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_344_sqrt: {type: sqrt, grid_loc: [3, 7], grid_size: [1, 1], inputs: [layernorm_344_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_344_recip: {type: reciprocal, grid_loc: [3, 8], grid_size: [1, 1], inputs: [layernorm_344_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_344_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [3, 9], grid_size: [1, 1], inputs: [layernorm_344_recip, lc.input_tensor.layernorm_344_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_344_output: {type: multiply, grid_loc: [3, 10], grid_size: [1, 1], inputs: [layernorm_344_sub, layernorm_344_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_344_weights: {type: multiply, grid_loc: [3, 11], grid_size: [1, 1], inputs: [layernorm_344_output, e2e_bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_344_bias: {type: add, grid_loc: [4, 0], grid_size: [1, 1], inputs: [layernorm_344_weights, e2e_bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_5_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_5_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_377: {type: matmul, grid_loc: [4, 3], grid_size: [1, 3], inputs: [layernorm_344_bias, bert_encoder.layer_5_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_379: {type: add, grid_loc: [4, 6], grid_size: [1, 1], inputs: [matmul_377, bert_encoder.layer_5_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_6_1.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_6_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_5_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_363: {type: matmul, grid_loc: [4, 9], grid_size: [1, 3], inputs: [layernorm_344_bias, bert_encoder.layer_5_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_365: {type: add, grid_loc: [5, 0], grid_size: [1, 1], inputs: [matmul_363, bert_encoder.layer_5_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_5_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_357: {type: matmul, grid_loc: [5, 2], grid_size: [1, 3], inputs: [layernorm_344_bias, bert_encoder.layer_5_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_359: {type: add, grid_loc: [5, 5], grid_size: [1, 1], inputs: [matmul_357, bert_encoder.layer_5_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_369: {type: matmul, grid_loc: [5, 6], grid_size: [1, 1], inputs: [add_359, add_365],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_372: {type: multiply, grid_loc: [5, 7], grid_size: [1, 1], inputs: [matmul_369, constant_1_multiply_372],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_373: {type: add, grid_loc: [5, 8], grid_size: [1, 1], inputs: [multiply_372, input_1_add_799_s_brcst_m2_6_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_374.dc.exp.0: {type: exp, grid_loc: [5, 9], grid_size: [1, 1], inputs: [add_373],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_374.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [5, 10], grid_size: [1, 1], inputs: [softmax_374.dc.exp.0, lc.input_tensor.softmax_374.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_374.dc.reciprocal.2: {type: reciprocal, grid_loc: [5, 11], grid_size: [1, 1], inputs: [softmax_374.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_374.dc.multiply.3: {type: multiply, grid_loc: [6, 0], grid_size: [1, 1], inputs: [softmax_374.dc.exp.0, softmax_374.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_384: {type: matmul, grid_loc: [6, 1], grid_size: [1, 1], inputs: [softmax_374.dc.multiply.3, add_379],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_388: {type: matmul, grid_loc: [6, 2], grid_size: [1, 3], inputs: [matmul_384, bert_encoder.layer_5_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_390: {type: add, grid_loc: [6, 5], grid_size: [1, 1], inputs: [matmul_388, bert_encoder.layer_5_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_391: {type: add, grid_loc: [6, 6], grid_size: [1, 1], inputs: [add_390, layernorm_344_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_392_mean.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [add_391, lc.input_tensor.layernorm_392_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_392_sub: {type: subtract, grid_loc: [6, 8], grid_size: [1, 1], inputs: [add_391, layernorm_392_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_392_sq: {type: multiply, grid_loc: [6, 9], grid_size: [1, 1], inputs: [layernorm_392_sub, layernorm_392_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_392_var.lc1: {type: matmul, grid_loc: [6, 10], grid_size: [1, 1], inputs: [layernorm_392_sq, lc.input_tensor.layernorm_392_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_392_var_plus_eps: {type: add, grid_loc: [6, 11], grid_size: [1, 1], inputs: [layernorm_392_var.lc1, constant_1_layernorm_392_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_392_sqrt: {type: sqrt, grid_loc: [7, 0], grid_size: [1, 1], inputs: [layernorm_392_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_392_recip: {type: reciprocal, grid_loc: [7, 1], grid_size: [1, 1], inputs: [layernorm_392_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_392_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [7, 2], grid_size: [1, 1], inputs: [layernorm_392_recip, lc.input_tensor.layernorm_392_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_392_output: {type: multiply, grid_loc: [7, 3], grid_size: [1, 1], inputs: [layernorm_392_sub, layernorm_392_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_392_weights: {type: multiply, grid_loc: [7, 4], grid_size: [1, 1], inputs: [layernorm_392_output, e2e_bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_392_bias: {type: add, grid_loc: [7, 5], grid_size: [1, 1], inputs: [layernorm_392_weights, e2e_bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_5_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_5_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_5_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_405: {type: matmul, grid_loc: [8, 0], grid_size: [1, 12], inputs: [layernorm_392_bias, bert_encoder.layer_5_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_407: {type: add, grid_loc: [9, 0], grid_size: [1, 3], inputs: [matmul_405, bert_encoder.layer_5_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_408: {type: gelu, grid_loc: [9, 3], grid_size: [1, 3], inputs: [add_407],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_5:
    target_device: 0
    input_count: 1
    matmul_411: {type: matmul, grid_loc: [0, 0], grid_size: [1, 12], inputs: [e2e_gelu_408_0, bert_encoder.layer_5_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_413: {type: add, grid_loc: [1, 0], grid_size: [1, 1], inputs: [matmul_411, e2e_bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_414: {type: add, grid_loc: [1, 1], grid_size: [1, 1], inputs: [add_413, e2e_layernorm_392_bias_0],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_415_mean.lc1: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [add_414, lc.input_tensor.layernorm_415_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_415_sub: {type: subtract, grid_loc: [1, 3], grid_size: [1, 1], inputs: [add_414, layernorm_415_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_415_sq: {type: multiply, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layernorm_415_sub, layernorm_415_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_415_var.lc1: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [layernorm_415_sq, lc.input_tensor.layernorm_415_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_415_var_plus_eps: {type: add, grid_loc: [1, 6], grid_size: [1, 1], inputs: [layernorm_415_var.lc1, constant_1_layernorm_415_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_415_sqrt: {type: sqrt, grid_loc: [1, 7], grid_size: [1, 1], inputs: [layernorm_415_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_415_recip: {type: reciprocal, grid_loc: [1, 8], grid_size: [1, 1], inputs: [layernorm_415_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_415_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [1, 9], grid_size: [1, 1], inputs: [layernorm_415_recip, lc.input_tensor.layernorm_415_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_415_output: {type: multiply, grid_loc: [1, 10], grid_size: [1, 1], inputs: [layernorm_415_sub, layernorm_415_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_415_weights: {type: multiply, grid_loc: [1, 11], grid_size: [1, 1], inputs: [layernorm_415_output, e2e_bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_415_bias: {type: add, grid_loc: [2, 0], grid_size: [1, 1], inputs: [layernorm_415_weights, e2e_bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_6_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_6_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_448: {type: matmul, grid_loc: [2, 3], grid_size: [1, 3], inputs: [layernorm_415_bias, bert_encoder.layer_6_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_450: {type: add, grid_loc: [2, 6], grid_size: [1, 1], inputs: [matmul_448, bert_encoder.layer_6_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_5_1.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_5_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_6_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_434: {type: matmul, grid_loc: [2, 9], grid_size: [1, 3], inputs: [layernorm_415_bias, bert_encoder.layer_6_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_436: {type: add, grid_loc: [3, 0], grid_size: [1, 1], inputs: [matmul_434, bert_encoder.layer_6_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_6_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_428: {type: matmul, grid_loc: [3, 2], grid_size: [1, 3], inputs: [layernorm_415_bias, bert_encoder.layer_6_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_430: {type: add, grid_loc: [3, 5], grid_size: [1, 1], inputs: [matmul_428, bert_encoder.layer_6_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_440: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [add_430, add_436],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_443: {type: multiply, grid_loc: [3, 7], grid_size: [1, 1], inputs: [matmul_440, constant_1_multiply_443],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_444: {type: add, grid_loc: [3, 8], grid_size: [1, 1], inputs: [multiply_443, input_1_add_799_s_brcst_m2_5_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_445.dc.exp.0: {type: exp, grid_loc: [3, 9], grid_size: [1, 1], inputs: [add_444],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_445.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [3, 10], grid_size: [1, 1], inputs: [softmax_445.dc.exp.0, lc.input_tensor.softmax_445.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_445.dc.reciprocal.2: {type: reciprocal, grid_loc: [3, 11], grid_size: [1, 1], inputs: [softmax_445.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_445.dc.multiply.3: {type: multiply, grid_loc: [4, 0], grid_size: [1, 1], inputs: [softmax_445.dc.exp.0, softmax_445.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_455: {type: matmul, grid_loc: [4, 1], grid_size: [1, 1], inputs: [softmax_445.dc.multiply.3, add_450],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_459: {type: matmul, grid_loc: [4, 2], grid_size: [1, 3], inputs: [matmul_455, bert_encoder.layer_6_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_461: {type: add, grid_loc: [4, 5], grid_size: [1, 1], inputs: [matmul_459, bert_encoder.layer_6_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_462: {type: add, grid_loc: [4, 6], grid_size: [1, 1], inputs: [add_461, layernorm_415_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_463_mean.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [add_462, lc.input_tensor.layernorm_463_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_463_sub: {type: subtract, grid_loc: [4, 8], grid_size: [1, 1], inputs: [add_462, layernorm_463_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_463_sq: {type: multiply, grid_loc: [4, 9], grid_size: [1, 1], inputs: [layernorm_463_sub, layernorm_463_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_463_var.lc1: {type: matmul, grid_loc: [4, 10], grid_size: [1, 1], inputs: [layernorm_463_sq, lc.input_tensor.layernorm_463_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_463_var_plus_eps: {type: add, grid_loc: [4, 11], grid_size: [1, 1], inputs: [layernorm_463_var.lc1, constant_1_layernorm_463_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_463_sqrt: {type: sqrt, grid_loc: [5, 0], grid_size: [1, 1], inputs: [layernorm_463_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_463_recip: {type: reciprocal, grid_loc: [5, 1], grid_size: [1, 1], inputs: [layernorm_463_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_463_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [layernorm_463_recip, lc.input_tensor.layernorm_463_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_463_output: {type: multiply, grid_loc: [5, 3], grid_size: [1, 1], inputs: [layernorm_463_sub, layernorm_463_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_463_weights: {type: multiply, grid_loc: [5, 4], grid_size: [1, 1], inputs: [layernorm_463_output, e2e_bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_463_bias: {type: add, grid_loc: [5, 5], grid_size: [1, 1], inputs: [layernorm_463_weights, e2e_bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_6_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_6_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_6_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_6_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_6_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_476: {type: matmul, grid_loc: [6, 0], grid_size: [1, 12], inputs: [layernorm_463_bias, bert_encoder.layer_6_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_478: {type: add, grid_loc: [7, 0], grid_size: [1, 3], inputs: [matmul_476, bert_encoder.layer_6_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_479: {type: gelu, grid_loc: [7, 3], grid_size: [1, 3], inputs: [add_478],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_482: {type: matmul, grid_loc: [8, 0], grid_size: [1, 12], inputs: [gelu_479, bert_encoder.layer_6_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_484: {type: add, grid_loc: [9, 0], grid_size: [1, 1], inputs: [matmul_482, bert_encoder.layer_6_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_485: {type: add, grid_loc: [9, 1], grid_size: [1, 1], inputs: [add_484, layernorm_463_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_486_mean.lc1: {type: matmul, grid_loc: [9, 2], grid_size: [1, 1], inputs: [add_485, lc.input_tensor.layernorm_486_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_486_sub: {type: subtract, grid_loc: [9, 3], grid_size: [1, 1], inputs: [add_485, layernorm_486_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_486_sq: {type: multiply, grid_loc: [9, 4], grid_size: [1, 1], inputs: [layernorm_486_sub, layernorm_486_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_486_var.lc1: {type: matmul, grid_loc: [9, 5], grid_size: [1, 1], inputs: [layernorm_486_sq, lc.input_tensor.layernorm_486_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_486_var_plus_eps: {type: add, grid_loc: [9, 6], grid_size: [1, 1], inputs: [layernorm_486_var.lc1, constant_1_layernorm_486_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_486_sqrt: {type: sqrt, grid_loc: [9, 7], grid_size: [1, 1], inputs: [layernorm_486_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_486_recip: {type: reciprocal, grid_loc: [9, 8], grid_size: [1, 1], inputs: [layernorm_486_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_486_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [9, 9], grid_size: [1, 1], inputs: [layernorm_486_recip, lc.input_tensor.layernorm_486_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_486_output: {type: multiply, grid_loc: [9, 10], grid_size: [1, 1], inputs: [layernorm_486_sub, layernorm_486_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_486_weights: {type: multiply, grid_loc: [9, 11], grid_size: [1, 1], inputs: [layernorm_486_output, e2e_bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}

  fwd_6:
    target_device: 0
    input_count: 1
    layernorm_486_bias: {type: add, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e_layernorm_486_weights_0, e2e_bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_7_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_7_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_519: {type: matmul, grid_loc: [0, 3], grid_size: [1, 3], inputs: [layernorm_486_bias, bert_encoder.layer_7_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_521: {type: add, grid_loc: [0, 6], grid_size: [1, 1], inputs: [matmul_519, bert_encoder.layer_7_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_4_1.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_4_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_7_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [0, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_505: {type: matmul, grid_loc: [0, 9], grid_size: [1, 3], inputs: [layernorm_486_bias, bert_encoder.layer_7_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_507: {type: add, grid_loc: [1, 0], grid_size: [1, 1], inputs: [matmul_505, bert_encoder.layer_7_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_7_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_499: {type: matmul, grid_loc: [1, 2], grid_size: [1, 3], inputs: [layernorm_486_bias, bert_encoder.layer_7_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_501: {type: add, grid_loc: [1, 5], grid_size: [1, 1], inputs: [matmul_499, bert_encoder.layer_7_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_511: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [add_501, add_507],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_514: {type: multiply, grid_loc: [1, 7], grid_size: [1, 1], inputs: [matmul_511, constant_1_multiply_514],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_515: {type: add, grid_loc: [1, 8], grid_size: [1, 1], inputs: [multiply_514, input_1_add_799_s_brcst_m2_4_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_516.dc.exp.0: {type: exp, grid_loc: [1, 9], grid_size: [1, 1], inputs: [add_515],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_516.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [1, 10], grid_size: [1, 1], inputs: [softmax_516.dc.exp.0, lc.input_tensor.softmax_516.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_516.dc.reciprocal.2: {type: reciprocal, grid_loc: [1, 11], grid_size: [1, 1], inputs: [softmax_516.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_516.dc.multiply.3: {type: multiply, grid_loc: [2, 0], grid_size: [1, 1], inputs: [softmax_516.dc.exp.0, softmax_516.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_526: {type: matmul, grid_loc: [2, 1], grid_size: [1, 1], inputs: [softmax_516.dc.multiply.3, add_521],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_530: {type: matmul, grid_loc: [2, 2], grid_size: [1, 3], inputs: [matmul_526, bert_encoder.layer_7_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_532: {type: add, grid_loc: [2, 5], grid_size: [1, 1], inputs: [matmul_530, bert_encoder.layer_7_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_533: {type: add, grid_loc: [2, 6], grid_size: [1, 1], inputs: [add_532, layernorm_486_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_534_mean.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [add_533, lc.input_tensor.layernorm_534_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_534_sub: {type: subtract, grid_loc: [2, 8], grid_size: [1, 1], inputs: [add_533, layernorm_534_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_534_sq: {type: multiply, grid_loc: [2, 9], grid_size: [1, 1], inputs: [layernorm_534_sub, layernorm_534_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_534_var.lc1: {type: matmul, grid_loc: [2, 10], grid_size: [1, 1], inputs: [layernorm_534_sq, lc.input_tensor.layernorm_534_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_534_var_plus_eps: {type: add, grid_loc: [2, 11], grid_size: [1, 1], inputs: [layernorm_534_var.lc1, constant_1_layernorm_534_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_534_sqrt: {type: sqrt, grid_loc: [3, 0], grid_size: [1, 1], inputs: [layernorm_534_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_534_recip: {type: reciprocal, grid_loc: [3, 1], grid_size: [1, 1], inputs: [layernorm_534_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_534_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [3, 2], grid_size: [1, 1], inputs: [layernorm_534_recip, lc.input_tensor.layernorm_534_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_534_output: {type: multiply, grid_loc: [3, 3], grid_size: [1, 1], inputs: [layernorm_534_sub, layernorm_534_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_534_weights: {type: multiply, grid_loc: [3, 4], grid_size: [1, 1], inputs: [layernorm_534_output, e2e_bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_534_bias: {type: add, grid_loc: [3, 5], grid_size: [1, 1], inputs: [layernorm_534_weights, e2e_bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_7_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_7_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_7_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_7_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_7_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_547: {type: matmul, grid_loc: [4, 0], grid_size: [1, 12], inputs: [layernorm_534_bias, bert_encoder.layer_7_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_549: {type: add, grid_loc: [5, 0], grid_size: [1, 3], inputs: [matmul_547, bert_encoder.layer_7_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_550: {type: gelu, grid_loc: [5, 3], grid_size: [1, 3], inputs: [add_549],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_553: {type: matmul, grid_loc: [6, 0], grid_size: [1, 12], inputs: [gelu_550, bert_encoder.layer_7_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_555: {type: add, grid_loc: [7, 0], grid_size: [1, 1], inputs: [matmul_553, bert_encoder.layer_7_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_556: {type: add, grid_loc: [7, 1], grid_size: [1, 1], inputs: [add_555, layernorm_534_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_557_mean.lc1: {type: matmul, grid_loc: [7, 2], grid_size: [1, 1], inputs: [add_556, lc.input_tensor.layernorm_557_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_557_sub: {type: subtract, grid_loc: [7, 3], grid_size: [1, 1], inputs: [add_556, layernorm_557_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_557_sq: {type: multiply, grid_loc: [7, 4], grid_size: [1, 1], inputs: [layernorm_557_sub, layernorm_557_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_557_var.lc1: {type: matmul, grid_loc: [7, 5], grid_size: [1, 1], inputs: [layernorm_557_sq, lc.input_tensor.layernorm_557_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_557_var_plus_eps: {type: add, grid_loc: [7, 6], grid_size: [1, 1], inputs: [layernorm_557_var.lc1, constant_1_layernorm_557_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_557_sqrt: {type: sqrt, grid_loc: [7, 7], grid_size: [1, 1], inputs: [layernorm_557_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_557_recip: {type: reciprocal, grid_loc: [7, 8], grid_size: [1, 1], inputs: [layernorm_557_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_557_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [7, 9], grid_size: [1, 1], inputs: [layernorm_557_recip, lc.input_tensor.layernorm_557_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_557_output: {type: multiply, grid_loc: [7, 10], grid_size: [1, 1], inputs: [layernorm_557_sub, layernorm_557_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_557_weights: {type: multiply, grid_loc: [7, 11], grid_size: [1, 1], inputs: [layernorm_557_output, e2e_bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_557_bias: {type: add, grid_loc: [8, 0], grid_size: [1, 1], inputs: [layernorm_557_weights, e2e_bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [8, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_8_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [8, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_590: {type: matmul, grid_loc: [8, 3], grid_size: [1, 3], inputs: [layernorm_557_bias, bert_encoder.layer_8_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_592: {type: add, grid_loc: [8, 6], grid_size: [1, 1], inputs: [matmul_590, bert_encoder.layer_8_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_3_1.lc1: {type: matmul, grid_loc: [8, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_3_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_8_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [8, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_576: {type: matmul, grid_loc: [8, 9], grid_size: [1, 3], inputs: [layernorm_557_bias, bert_encoder.layer_8_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_578: {type: add, grid_loc: [9, 0], grid_size: [1, 1], inputs: [matmul_576, bert_encoder.layer_8_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_8_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [9, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_570: {type: matmul, grid_loc: [9, 2], grid_size: [1, 3], inputs: [layernorm_557_bias, bert_encoder.layer_8_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_572: {type: add, grid_loc: [9, 5], grid_size: [1, 1], inputs: [matmul_570, bert_encoder.layer_8_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_582: {type: matmul, grid_loc: [9, 6], grid_size: [1, 1], inputs: [add_572, add_578],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_585: {type: multiply, grid_loc: [9, 7], grid_size: [1, 1], inputs: [matmul_582, constant_1_multiply_585],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_586: {type: add, grid_loc: [9, 8], grid_size: [1, 1], inputs: [multiply_585, input_1_add_799_s_brcst_m2_3_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_587.dc.exp.0: {type: exp, grid_loc: [9, 9], grid_size: [1, 1], inputs: [add_586],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_587.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [9, 10], grid_size: [1, 1], inputs: [softmax_587.dc.exp.0, lc.input_tensor.softmax_587.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_587.dc.reciprocal.2: {type: reciprocal, grid_loc: [9, 11], grid_size: [1, 1], inputs: [softmax_587.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_7:
    target_device: 0
    input_count: 1
    softmax_587.dc.multiply.3: {type: multiply, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e_softmax_587.dc.exp.0_0, e2e_softmax_587.dc.reciprocal.2_0],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_597: {type: matmul, grid_loc: [0, 1], grid_size: [1, 1], inputs: [softmax_587.dc.multiply.3, e2e_add_592_0],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_601: {type: matmul, grid_loc: [0, 2], grid_size: [1, 3], inputs: [matmul_597, bert_encoder.layer_8_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_603: {type: add, grid_loc: [0, 5], grid_size: [1, 1], inputs: [matmul_601, e2e_bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_604: {type: add, grid_loc: [0, 6], grid_size: [1, 1], inputs: [add_603, e2e_layernorm_557_bias_0],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_605_mean.lc1: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [add_604, lc.input_tensor.layernorm_605_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_605_sub: {type: subtract, grid_loc: [0, 8], grid_size: [1, 1], inputs: [add_604, layernorm_605_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_605_sq: {type: multiply, grid_loc: [0, 9], grid_size: [1, 1], inputs: [layernorm_605_sub, layernorm_605_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_605_var.lc1: {type: matmul, grid_loc: [0, 10], grid_size: [1, 1], inputs: [layernorm_605_sq, lc.input_tensor.layernorm_605_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_605_var_plus_eps: {type: add, grid_loc: [0, 11], grid_size: [1, 1], inputs: [layernorm_605_var.lc1, constant_1_layernorm_605_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_605_sqrt: {type: sqrt, grid_loc: [1, 0], grid_size: [1, 1], inputs: [layernorm_605_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_605_recip: {type: reciprocal, grid_loc: [1, 1], grid_size: [1, 1], inputs: [layernorm_605_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_605_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [layernorm_605_recip, lc.input_tensor.layernorm_605_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_605_output: {type: multiply, grid_loc: [1, 3], grid_size: [1, 1], inputs: [layernorm_605_sub, layernorm_605_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_605_weights: {type: multiply, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layernorm_605_output, e2e_bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_605_bias: {type: add, grid_loc: [1, 5], grid_size: [1, 1], inputs: [layernorm_605_weights, e2e_bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_8_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_8_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_8_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [1, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_8_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_8_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_618: {type: matmul, grid_loc: [2, 0], grid_size: [1, 12], inputs: [layernorm_605_bias, bert_encoder.layer_8_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_620: {type: add, grid_loc: [3, 0], grid_size: [1, 3], inputs: [matmul_618, bert_encoder.layer_8_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_621: {type: gelu, grid_loc: [3, 3], grid_size: [1, 3], inputs: [add_620],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_624: {type: matmul, grid_loc: [4, 0], grid_size: [1, 12], inputs: [gelu_621, bert_encoder.layer_8_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_626: {type: add, grid_loc: [5, 0], grid_size: [1, 1], inputs: [matmul_624, bert_encoder.layer_8_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_627: {type: add, grid_loc: [5, 1], grid_size: [1, 1], inputs: [add_626, layernorm_605_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_628_mean.lc1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [add_627, lc.input_tensor.layernorm_628_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_628_sub: {type: subtract, grid_loc: [5, 3], grid_size: [1, 1], inputs: [add_627, layernorm_628_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_628_sq: {type: multiply, grid_loc: [5, 4], grid_size: [1, 1], inputs: [layernorm_628_sub, layernorm_628_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_628_var.lc1: {type: matmul, grid_loc: [5, 5], grid_size: [1, 1], inputs: [layernorm_628_sq, lc.input_tensor.layernorm_628_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_628_var_plus_eps: {type: add, grid_loc: [5, 6], grid_size: [1, 1], inputs: [layernorm_628_var.lc1, constant_1_layernorm_628_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_628_sqrt: {type: sqrt, grid_loc: [5, 7], grid_size: [1, 1], inputs: [layernorm_628_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_628_recip: {type: reciprocal, grid_loc: [5, 8], grid_size: [1, 1], inputs: [layernorm_628_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_628_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [5, 9], grid_size: [1, 1], inputs: [layernorm_628_recip, lc.input_tensor.layernorm_628_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_628_output: {type: multiply, grid_loc: [5, 10], grid_size: [1, 1], inputs: [layernorm_628_sub, layernorm_628_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_628_weights: {type: multiply, grid_loc: [5, 11], grid_size: [1, 1], inputs: [layernorm_628_output, e2e_bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_628_bias: {type: add, grid_loc: [6, 0], grid_size: [1, 1], inputs: [layernorm_628_weights, e2e_bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_9_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [6, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_9_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [6, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_661: {type: matmul, grid_loc: [6, 3], grid_size: [1, 3], inputs: [layernorm_628_bias, bert_encoder.layer_9_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_663: {type: add, grid_loc: [6, 6], grid_size: [1, 1], inputs: [matmul_661, bert_encoder.layer_9_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_2_1.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_2_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_9_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [6, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_647: {type: matmul, grid_loc: [6, 9], grid_size: [1, 3], inputs: [layernorm_628_bias, bert_encoder.layer_9_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_649: {type: add, grid_loc: [7, 0], grid_size: [1, 1], inputs: [matmul_647, bert_encoder.layer_9_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_9_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_641: {type: matmul, grid_loc: [7, 2], grid_size: [1, 3], inputs: [layernorm_628_bias, bert_encoder.layer_9_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_643: {type: add, grid_loc: [7, 5], grid_size: [1, 1], inputs: [matmul_641, bert_encoder.layer_9_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_653: {type: matmul, grid_loc: [7, 6], grid_size: [1, 1], inputs: [add_643, add_649],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_656: {type: multiply, grid_loc: [7, 7], grid_size: [1, 1], inputs: [matmul_653, constant_1_multiply_656],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_657: {type: add, grid_loc: [7, 8], grid_size: [1, 1], inputs: [multiply_656, input_1_add_799_s_brcst_m2_2_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_658.dc.exp.0: {type: exp, grid_loc: [7, 9], grid_size: [1, 1], inputs: [add_657],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_658.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [7, 10], grid_size: [1, 1], inputs: [softmax_658.dc.exp.0, lc.input_tensor.softmax_658.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_658.dc.reciprocal.2: {type: reciprocal, grid_loc: [7, 11], grid_size: [1, 1], inputs: [softmax_658.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_658.dc.multiply.3: {type: multiply, grid_loc: [8, 0], grid_size: [1, 1], inputs: [softmax_658.dc.exp.0, softmax_658.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_668: {type: matmul, grid_loc: [8, 1], grid_size: [1, 1], inputs: [softmax_658.dc.multiply.3, add_663],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_672: {type: matmul, grid_loc: [8, 2], grid_size: [1, 3], inputs: [matmul_668, bert_encoder.layer_9_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_674: {type: add, grid_loc: [8, 5], grid_size: [1, 1], inputs: [matmul_672, bert_encoder.layer_9_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_675: {type: add, grid_loc: [8, 6], grid_size: [1, 1], inputs: [add_674, layernorm_628_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_676_mean.lc1: {type: matmul, grid_loc: [8, 7], grid_size: [1, 1], inputs: [add_675, lc.input_tensor.layernorm_676_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_676_sub: {type: subtract, grid_loc: [8, 8], grid_size: [1, 1], inputs: [add_675, layernorm_676_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_676_sq: {type: multiply, grid_loc: [8, 9], grid_size: [1, 1], inputs: [layernorm_676_sub, layernorm_676_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_676_var.lc1: {type: matmul, grid_loc: [8, 10], grid_size: [1, 1], inputs: [layernorm_676_sq, lc.input_tensor.layernorm_676_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_676_var_plus_eps: {type: add, grid_loc: [8, 11], grid_size: [1, 1], inputs: [layernorm_676_var.lc1, constant_1_layernorm_676_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_676_sqrt: {type: sqrt, grid_loc: [9, 0], grid_size: [1, 1], inputs: [layernorm_676_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_676_recip: {type: reciprocal, grid_loc: [9, 1], grid_size: [1, 1], inputs: [layernorm_676_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_676_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [9, 2], grid_size: [1, 1], inputs: [layernorm_676_recip, lc.input_tensor.layernorm_676_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_676_output: {type: multiply, grid_loc: [9, 3], grid_size: [1, 1], inputs: [layernorm_676_sub, layernorm_676_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_676_weights: {type: multiply, grid_loc: [9, 4], grid_size: [1, 1], inputs: [layernorm_676_output, e2e_bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_676_bias: {type: add, grid_loc: [9, 5], grid_size: [1, 1], inputs: [layernorm_676_weights, e2e_bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [9, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [9, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_9_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}

  fwd_8:
    target_device: 0
    input_count: 1
    matmul_689: {type: matmul, grid_loc: [0, 0], grid_size: [1, 12], inputs: [e2e_layernorm_676_bias_0, bert_encoder.layer_9_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_691: {type: add, grid_loc: [1, 0], grid_size: [1, 3], inputs: [matmul_689, e2e_bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_692: {type: gelu, grid_loc: [1, 3], grid_size: [1, 3], inputs: [add_691],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_695: {type: matmul, grid_loc: [2, 0], grid_size: [1, 12], inputs: [gelu_692, bert_encoder.layer_9_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_697: {type: add, grid_loc: [3, 0], grid_size: [1, 1], inputs: [matmul_695, e2e_bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_698: {type: add, grid_loc: [3, 1], grid_size: [1, 1], inputs: [add_697, e2e_layernorm_676_bias_1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_699_mean.lc1: {type: matmul, grid_loc: [3, 2], grid_size: [1, 1], inputs: [add_698, lc.input_tensor.layernorm_699_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_699_sub: {type: subtract, grid_loc: [3, 3], grid_size: [1, 1], inputs: [add_698, layernorm_699_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_699_sq: {type: multiply, grid_loc: [3, 4], grid_size: [1, 1], inputs: [layernorm_699_sub, layernorm_699_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_699_var.lc1: {type: matmul, grid_loc: [3, 5], grid_size: [1, 1], inputs: [layernorm_699_sq, lc.input_tensor.layernorm_699_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_699_var_plus_eps: {type: add, grid_loc: [3, 6], grid_size: [1, 1], inputs: [layernorm_699_var.lc1, constant_1_layernorm_699_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_699_sqrt: {type: sqrt, grid_loc: [3, 7], grid_size: [1, 1], inputs: [layernorm_699_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_699_recip: {type: reciprocal, grid_loc: [3, 8], grid_size: [1, 1], inputs: [layernorm_699_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_699_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [3, 9], grid_size: [1, 1], inputs: [layernorm_699_recip, lc.input_tensor.layernorm_699_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_699_output: {type: multiply, grid_loc: [3, 10], grid_size: [1, 1], inputs: [layernorm_699_sub, layernorm_699_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_699_weights: {type: multiply, grid_loc: [3, 11], grid_size: [1, 1], inputs: [layernorm_699_output, e2e_bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_699_bias: {type: add, grid_loc: [4, 0], grid_size: [1, 1], inputs: [layernorm_699_weights, e2e_bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_10_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_10_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_732: {type: matmul, grid_loc: [4, 3], grid_size: [1, 3], inputs: [layernorm_699_bias, bert_encoder.layer_10_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_734: {type: add, grid_loc: [4, 6], grid_size: [1, 1], inputs: [matmul_732, bert_encoder.layer_10_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_1_1.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_1_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_10_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [4, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_718: {type: matmul, grid_loc: [4, 9], grid_size: [1, 3], inputs: [layernorm_699_bias, bert_encoder.layer_10_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_720: {type: add, grid_loc: [5, 0], grid_size: [1, 1], inputs: [matmul_718, bert_encoder.layer_10_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_10_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_712: {type: matmul, grid_loc: [5, 2], grid_size: [1, 3], inputs: [layernorm_699_bias, bert_encoder.layer_10_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_714: {type: add, grid_loc: [5, 5], grid_size: [1, 1], inputs: [matmul_712, bert_encoder.layer_10_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_724: {type: matmul, grid_loc: [5, 6], grid_size: [1, 1], inputs: [add_714, add_720],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_727: {type: multiply, grid_loc: [5, 7], grid_size: [1, 1], inputs: [matmul_724, constant_1_multiply_727],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_728: {type: add, grid_loc: [5, 8], grid_size: [1, 1], inputs: [multiply_727, input_1_add_799_s_brcst_m2_1_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_729.dc.exp.0: {type: exp, grid_loc: [5, 9], grid_size: [1, 1], inputs: [add_728],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_729.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [5, 10], grid_size: [1, 1], inputs: [softmax_729.dc.exp.0, lc.input_tensor.softmax_729.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_729.dc.reciprocal.2: {type: reciprocal, grid_loc: [5, 11], grid_size: [1, 1], inputs: [softmax_729.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_729.dc.multiply.3: {type: multiply, grid_loc: [6, 0], grid_size: [1, 1], inputs: [softmax_729.dc.exp.0, softmax_729.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_739: {type: matmul, grid_loc: [6, 1], grid_size: [1, 1], inputs: [softmax_729.dc.multiply.3, add_734],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_743: {type: matmul, grid_loc: [6, 2], grid_size: [1, 3], inputs: [matmul_739, bert_encoder.layer_10_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_745: {type: add, grid_loc: [6, 5], grid_size: [1, 1], inputs: [matmul_743, bert_encoder.layer_10_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_746: {type: add, grid_loc: [6, 6], grid_size: [1, 1], inputs: [add_745, layernorm_699_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_747_mean.lc1: {type: matmul, grid_loc: [6, 7], grid_size: [1, 1], inputs: [add_746, lc.input_tensor.layernorm_747_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_747_sub: {type: subtract, grid_loc: [6, 8], grid_size: [1, 1], inputs: [add_746, layernorm_747_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_747_sq: {type: multiply, grid_loc: [6, 9], grid_size: [1, 1], inputs: [layernorm_747_sub, layernorm_747_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_747_var.lc1: {type: matmul, grid_loc: [6, 10], grid_size: [1, 1], inputs: [layernorm_747_sq, lc.input_tensor.layernorm_747_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_747_var_plus_eps: {type: add, grid_loc: [6, 11], grid_size: [1, 1], inputs: [layernorm_747_var.lc1, constant_1_layernorm_747_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_747_sqrt: {type: sqrt, grid_loc: [7, 0], grid_size: [1, 1], inputs: [layernorm_747_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_747_recip: {type: reciprocal, grid_loc: [7, 1], grid_size: [1, 1], inputs: [layernorm_747_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_747_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [7, 2], grid_size: [1, 1], inputs: [layernorm_747_recip, lc.input_tensor.layernorm_747_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_747_output: {type: multiply, grid_loc: [7, 3], grid_size: [1, 1], inputs: [layernorm_747_sub, layernorm_747_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_747_weights: {type: multiply, grid_loc: [7, 4], grid_size: [1, 1], inputs: [layernorm_747_output, e2e_bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_747_bias: {type: add, grid_loc: [7, 5], grid_size: [1, 1], inputs: [layernorm_747_weights, e2e_bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_10_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [7, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_10_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_10_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_760: {type: matmul, grid_loc: [8, 0], grid_size: [1, 12], inputs: [layernorm_747_bias, bert_encoder.layer_10_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_762: {type: add, grid_loc: [9, 0], grid_size: [1, 3], inputs: [matmul_760, bert_encoder.layer_10_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_763: {type: gelu, grid_loc: [9, 3], grid_size: [1, 3], inputs: [add_762],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}

  fwd_9:
    target_device: 0
    input_count: 1
    matmul_766: {type: matmul, grid_loc: [0, 0], grid_size: [1, 12], inputs: [e2e_gelu_763_0, bert_encoder.layer_10_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_768: {type: add, grid_loc: [1, 0], grid_size: [1, 1], inputs: [matmul_766, e2e_bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_769: {type: add, grid_loc: [1, 1], grid_size: [1, 1], inputs: [add_768, e2e_layernorm_747_bias_0],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_770_mean.lc1: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [add_769, lc.input_tensor.layernorm_770_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_770_sub: {type: subtract, grid_loc: [1, 3], grid_size: [1, 1], inputs: [add_769, layernorm_770_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_770_sq: {type: multiply, grid_loc: [1, 4], grid_size: [1, 1], inputs: [layernorm_770_sub, layernorm_770_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_770_var.lc1: {type: matmul, grid_loc: [1, 5], grid_size: [1, 1], inputs: [layernorm_770_sq, lc.input_tensor.layernorm_770_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_770_var_plus_eps: {type: add, grid_loc: [1, 6], grid_size: [1, 1], inputs: [layernorm_770_var.lc1, constant_1_layernorm_770_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_770_sqrt: {type: sqrt, grid_loc: [1, 7], grid_size: [1, 1], inputs: [layernorm_770_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_770_recip: {type: reciprocal, grid_loc: [1, 8], grid_size: [1, 1], inputs: [layernorm_770_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_770_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [1, 9], grid_size: [1, 1], inputs: [layernorm_770_recip, lc.input_tensor.layernorm_770_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_770_output: {type: multiply, grid_loc: [1, 10], grid_size: [1, 1], inputs: [layernorm_770_sub, layernorm_770_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_770_weights: {type: multiply, grid_loc: [1, 11], grid_size: [1, 1], inputs: [layernorm_770_output, e2e_bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_770_bias: {type: add, grid_loc: [2, 0], grid_size: [1, 1], inputs: [layernorm_770_weights, e2e_bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_11_attention_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_attention_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_attention_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_11_attention_self_value_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 2], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_attention_self_value_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_attention_self_value_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_803: {type: matmul, grid_loc: [2, 3], grid_size: [1, 3], inputs: [layernorm_770_bias, bert_encoder.layer_11_attention_self_value_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_805: {type: add, grid_loc: [2, 6], grid_size: [1, 1], inputs: [matmul_803, bert_encoder.layer_11_attention_self_value_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    input_1_add_799_s_brcst_m2_0_1.lc1: {type: matmul, grid_loc: [2, 7], grid_size: [1, 1], inputs: [lc.input_tensor.input_1_add_799_s_brcst_m2_0_1.0, input_1_add_799],
         t: 12, mblock: [1, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}], input_0_tms: [broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_11_attention_self_key_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [2, 8], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_attention_self_key_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_attention_self_key_bias],
         t: 1, mblock: [1, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_789: {type: matmul, grid_loc: [2, 9], grid_size: [1, 3], inputs: [layernorm_770_bias, bert_encoder.layer_11_attention_self_key_weight],
         t: 1, mblock: [4, 1], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_791: {type: add, grid_loc: [3, 0], grid_size: [1, 1], inputs: [matmul_789, bert_encoder.layer_11_attention_self_key_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_11_attention_self_query_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [3, 1], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_attention_self_query_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_attention_self_query_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_783: {type: matmul, grid_loc: [3, 2], grid_size: [1, 3], inputs: [layernorm_770_bias, bert_encoder.layer_11_attention_self_query_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_785: {type: add, grid_loc: [3, 5], grid_size: [1, 1], inputs: [matmul_783, bert_encoder.layer_11_attention_self_query_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    matmul_795: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [add_785, add_791],
         t: 12, mblock: [2, 1], ublock: [2, 4], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12, transpose], input_0_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 2}}
    multiply_798: {type: multiply, grid_loc: [3, 7], grid_size: [1, 1], inputs: [matmul_795, constant_1_multiply_798],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {z: 12}, broadcast: {c: 4}, broadcast: {r: 4}]}
    add_799: {type: add, grid_loc: [3, 8], grid_size: [1, 1], inputs: [multiply_798, input_1_add_799_s_brcst_m2_0_1.lc1],
         t: 12, mblock: [1, 2], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    softmax_800.dc.exp.0: {type: exp, grid_loc: [3, 9], grid_size: [1, 1], inputs: [add_799],
         t: 12, mblock: [1, 4], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_800.dc.reduce_sum.1.lc1: {type: matmul, grid_loc: [3, 10], grid_size: [1, 1], inputs: [softmax_800.dc.exp.0, lc.input_tensor.softmax_800.dc.reduce_sum.1.0],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}, broadcast: {z: 12}],
         attributes: {m_k: 1, u_kt: 4}}
    softmax_800.dc.reciprocal.2: {type: reciprocal, grid_loc: [3, 11], grid_size: [1, 1], inputs: [softmax_800.dc.reduce_sum.1.lc1],
         t: 12, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    softmax_800.dc.multiply.3: {type: multiply, grid_loc: [4, 0], grid_size: [1, 1], inputs: [softmax_800.dc.exp.0, softmax_800.dc.reciprocal.2],
         t: 12, mblock: [4, 2], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 4}]}
    matmul_810: {type: matmul, grid_loc: [4, 1], grid_size: [1, 1], inputs: [softmax_800.dc.multiply.3, add_805],
         t: 12, mblock: [1, 1], ublock: [4, 2], buf_size_mb: 24, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [hslice: 12],
         attributes: {m_k: 1, u_kt: 4}}
    matmul_814: {type: matmul, grid_loc: [4, 2], grid_size: [1, 3], inputs: [matmul_810, bert_encoder.layer_11_attention_output_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [hstack: 12],
         attributes: {m_k: 24, u_kt: 1}}
    add_816: {type: add, grid_loc: [4, 5], grid_size: [1, 1], inputs: [matmul_814, bert_encoder.layer_11_attention_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_817: {type: add, grid_loc: [4, 6], grid_size: [1, 1], inputs: [add_816, layernorm_770_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_818_mean.lc1: {type: matmul, grid_loc: [4, 7], grid_size: [1, 1], inputs: [add_817, lc.input_tensor.layernorm_818_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_818_sub: {type: subtract, grid_loc: [4, 8], grid_size: [1, 1], inputs: [add_817, layernorm_818_mean.lc1],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_818_sq: {type: multiply, grid_loc: [4, 9], grid_size: [1, 1], inputs: [layernorm_818_sub, layernorm_818_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_818_var.lc1: {type: matmul, grid_loc: [4, 10], grid_size: [1, 1], inputs: [layernorm_818_sq, lc.input_tensor.layernorm_818_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_818_var_plus_eps: {type: add, grid_loc: [4, 11], grid_size: [1, 1], inputs: [layernorm_818_var.lc1, constant_1_layernorm_818_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_818_sqrt: {type: sqrt, grid_loc: [5, 0], grid_size: [1, 1], inputs: [layernorm_818_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_818_recip: {type: reciprocal, grid_loc: [5, 1], grid_size: [1, 1], inputs: [layernorm_818_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_818_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [layernorm_818_recip, lc.input_tensor.layernorm_818_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_818_output: {type: multiply, grid_loc: [5, 3], grid_size: [1, 1], inputs: [layernorm_818_sub, layernorm_818_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_818_weights: {type: multiply, grid_loc: [5, 4], grid_size: [1, 1], inputs: [layernorm_818_output, e2e_bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_818_bias: {type: add, grid_loc: [5, 5], grid_size: [1, 1], inputs: [layernorm_818_weights, e2e_bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    bert_encoder.layer_11_output_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 6], grid_size: [1, 1], inputs: [lc.input_tensor.bert_encoder.layer_11_output_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_output_dense_bias],
         t: 1, mblock: [1, 12], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    bert_encoder.layer_11_intermediate_dense_bias_s_brcst_m2_0_0.lc1: {type: matmul, grid_loc: [5, 7], grid_size: [1, 2], inputs: [lc.input_tensor.bert_encoder.layer_11_intermediate_dense_bias_s_brcst_m2_0_0.0, bert_encoder.layer_11_intermediate_dense_bias],
         t: 1, mblock: [1, 24], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    matmul_831: {type: matmul, grid_loc: [6, 0], grid_size: [1, 12], inputs: [layernorm_818_bias, bert_encoder.layer_11_intermediate_dense_weight],
         t: 1, mblock: [4, 4], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 24, u_kt: 1}}
    add_833: {type: add, grid_loc: [7, 0], grid_size: [1, 3], inputs: [matmul_831, bert_encoder.layer_11_intermediate_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    gelu_834: {type: gelu, grid_loc: [7, 3], grid_size: [1, 3], inputs: [add_833],
         t: 1, mblock: [1, 16], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    matmul_837: {type: matmul, grid_loc: [8, 0], grid_size: [1, 12], inputs: [gelu_834, bert_encoder.layer_11_output_dense_weight],
         t: 1, mblock: [4, 1], ublock: [1, 2], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 96, u_kt: 1}}
    add_839: {type: add, grid_loc: [9, 0], grid_size: [1, 1], inputs: [matmul_837, bert_encoder.layer_11_output_dense_bias_s_brcst_m2_0_0.lc1],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    add_840: {type: add, grid_loc: [9, 1], grid_size: [1, 1], inputs: [add_839, layernorm_818_bias],
         t: 1, mblock: [1, 24], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_841_mean.lc1: {type: matmul, grid_loc: [9, 2], grid_size: [1, 1], inputs: [add_840, lc.input_tensor.layernorm_841_mean.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_841_sub: {type: subtract, grid_loc: [9, 3], grid_size: [1, 1], inputs: [add_840, layernorm_841_mean.lc1],
         t: 1, mblock: [4, 24], ublock: [1, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_841_sq: {type: multiply, grid_loc: [9, 4], grid_size: [1, 1], inputs: [layernorm_841_sub, layernorm_841_sub],
         t: 1, mblock: [1, 12], ublock: [4, 2], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_841_var.lc1: {type: matmul, grid_loc: [9, 5], grid_size: [1, 1], inputs: [layernorm_841_sq, lc.input_tensor.layernorm_841_var.0],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 24}],
         attributes: {m_k: 1, u_kt: 24}}
    layernorm_841_var_plus_eps: {type: add, grid_loc: [9, 6], grid_size: [1, 1], inputs: [layernorm_841_var.lc1, constant_1_layernorm_841_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}
    layernorm_841_sqrt: {type: sqrt, grid_loc: [9, 7], grid_size: [1, 1], inputs: [layernorm_841_var_plus_eps],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_841_recip: {type: reciprocal, grid_loc: [9, 8], grid_size: [1, 1], inputs: [layernorm_841_sqrt],
         t: 1, mblock: [1, 1], ublock: [4, 1], buf_size_mb: 2, ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    layernorm_841_recip_s_brcst_m1_0_0.lc1: {type: matmul, grid_loc: [9, 9], grid_size: [1, 1], inputs: [layernorm_841_recip, lc.input_tensor.layernorm_841_recip_s_brcst_m1_0_0.0],
         t: 1, mblock: [4, 1], ublock: [1, 1], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         attributes: {m_k: 1, u_kt: 1}}
    layernorm_841_output: {type: multiply, grid_loc: [9, 10], grid_size: [1, 1], inputs: [layernorm_841_sub, layernorm_841_recip_s_brcst_m1_0_0.lc1],
         t: 1, mblock: [4, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {c: 24}]}
    layernorm_841_weights: {type: multiply, grid_loc: [9, 11], grid_size: [1, 1], inputs: [layernorm_841_output, e2e_bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0],
         t: 1, mblock: [4, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}

  fwd_10:
    target_device: 0
    input_count: 1
    layernorm_841_bias: {type: add, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e_layernorm_841_weights_0, e2e_bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0], untilize_output: true,
         t: 1, mblock: [4, 3], ublock: [1, 8], buf_size_mb: 2, ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_1_tms: [broadcast: {r: 4}]}


programs:
  - run_fwd:
    - param: [$p_loop_count]
    - var: {$c_microbatch_size: 1, $c_one: 1, $c_zero: 0}
    - staticvar: {$gptr_q0: 0, $gptr_q1_shadow: 0, $gptr_q1: 0, $gptr_q2_shadow: 0, $gptr_q2: 0, $lptr_q2: 0, $gptr_q3: 0, $lptr_q3: 0, $gptr_q17: 0, $gptr_q6: 0, $gptr_q4: 0, $lptr_q7: 0, $gptr_q18: 0, $gptr_q19: 0, $gptr_q7: 0, $gptr_q19_shadow: 0, $gptr_q20: 0, $lptr_q8: 0, $gptr_q21: 0, $lptr_q5: 0, $lptr_q21: 0, $lptr_q18: 0, $lptr_q20: 0, $gptr_q24: 0, $gptr_q9: 0, $lptr_q0: 0, $lptr_q29: 0, $gptr_q29: 0, $lptr_q17: 0, $lptr_q14: 0, $gptr_q13: 0, $lptr_q25: 0, $gptr_q28: 0, $lptr_q19: 0, $lptr_q26: 0, $lptr_q16: 0, $gptr_q12: 0, $gptr_q27: 0, $gptr_q15: 0, $lptr_q22: 0, $lptr_q12: 0, $gptr_q25: 0, $lptr_q24: 0, $lptr_q23: 0, $gptr_q16: 0, $lptr_q13: 0, $gptr_q16_shadow: 0, $gptr_q23: 0, $lptr_q15: 0, $lptr_q28: 0, $lptr_q27: 0, $lptr_q11: 0, $gptr_q14: 0, $gptr_q22_shadow: 0, $gptr_q8: 0, $lptr_q1: 0, $gptr_q22: 0, $gptr_q13_shadow: 0, $gptr_q11: 0, $gptr_q26: 0, $lptr_q9: 0, $lptr_q10: 0, $gptr_q10: 0, $gptr_q5: 0, $gptr_q4_shadow: 0, $gptr_q10_shadow: 0, $gptr_q7_shadow: 0, $lptr_q6: 0, $lptr_q4: 0}
    - varinst: [$gptr_q22, set, $gptr_q22_shadow]
    - varinst: [$gptr_q19, set, $gptr_q19_shadow]
    - varinst: [$gptr_q16, set, $gptr_q16_shadow]
    - varinst: [$gptr_q13, set, $gptr_q13_shadow]
    - varinst: [$gptr_q10, set, $gptr_q10_shadow]
    - varinst: [$gptr_q7, set, $gptr_q7_shadow]
    - varinst: [$gptr_q4, set, $gptr_q4_shadow]
    - varinst: [$gptr_q2, set, $gptr_q2_shadow]
    - varinst: [$gptr_q1, set, $gptr_q1_shadow]
    - loop: $p_loop_count
    -   execute: {graph_name: fwd_0, queue_settings: {
               lc.input_tensor.bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_attention_output_LayerNorm_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_output_LayerNorm_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_attention_output_LayerNorm_weight_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_output_LayerNorm_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_11_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_17: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_19.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_37_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_37_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_37_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_37_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_0_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_0_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_0_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_36: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1}} }
    -   varinst: [$gptr_q0, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q0, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q1_shadow, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q1, incwrap, $c_microbatch_size, 18]
    -   execute: {graph_name: fwd_1, queue_settings: {
               bert_encoder.layer_0_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_60_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_60_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_60_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_60_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_10_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_88: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_90.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_108_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_108_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_108_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_108_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_1_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_1_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_1_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_1_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_131_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_131_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_131_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_131_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               e2e_bert_encoder.layer_1_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_bert_encoder.layer_1_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_bert_encoder.layer_1_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_bert_encoder.layer_0_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_bert_encoder.layer_0_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_layernorm_37_bias_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_bert_encoder.layer_0_output_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_gelu_53_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3}} }
    -   varinst: [$lptr_q2, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q3, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q3, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q2_shadow, incwrap, $c_microbatch_size, 18]
    -   execute: {graph_name: fwd_2, queue_settings: {
               lc.input_tensor.bert_encoder.layer_2_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_9_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_159: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_161.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_179_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_179_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_179_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_179_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_2_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_2_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_2_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_2_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_202_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_202_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_202_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_202_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_8_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_3_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_230: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_232.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               e2e_bert_encoder.layer_2_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_bert_encoder.layer_2_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_bert_encoder.layer_2_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_bert_encoder.layer_2_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_bert_encoder.layer_1_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               e2e_layernorm_131_weights_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6}} }
    -   varinst: [$lptr_q4, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q5, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q4_shadow, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q5, incwrap, $c_microbatch_size, 4]
    -   varinst: [$gptr_q6, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q6, incwrap, $c_microbatch_size, 2]
    -   execute: {graph_name: fwd_3, queue_settings: {
               bert_encoder.layer_3_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_250_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_250_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_250_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_250_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_3_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_3_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_3_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_3_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_273_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_273_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_273_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_273_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_7_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_301: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_303.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_321_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_321_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_321_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_321_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_4_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               e2e_bert_encoder.layer_4_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bert_encoder.layer_4_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bert_encoder.layer_3_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bert_encoder.layer_3_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bert_encoder.layer_3_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_bert_encoder.layer_3_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q8, rd_ptr_global: $gptr_q8},
               e2e_layernorm_202_bias_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_bert_encoder.layer_3_attention_output_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_add_237_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_softmax_232.dc.exp.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9},
               e2e_softmax_232.dc.reciprocal.2_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q9, rd_ptr_global: $gptr_q9}} }
    -   varinst: [$gptr_q8, incwrap, $c_microbatch_size, 6]
    -   varinst: [$lptr_q8, incwrap, $c_microbatch_size, 6]
    -   varinst: [$gptr_q9, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q9, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q7_shadow, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q7, incwrap, $c_microbatch_size, 18]
    -   execute: {graph_name: fwd_4, queue_settings: {
               bert_encoder.layer_4_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_4_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_344_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_344_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_344_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_344_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_6_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_372: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_374.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_392_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_392_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_392_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_392_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_5_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_5_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_5_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q10, rd_ptr_global: $gptr_q10},
               e2e_bert_encoder.layer_5_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_bert_encoder.layer_5_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_bert_encoder.layer_4_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_bert_encoder.layer_4_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q11, rd_ptr_global: $gptr_q11},
               e2e_layernorm_321_bias_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12},
               e2e_layernorm_321_bias_1: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12},
               e2e_bert_encoder.layer_4_output_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12},
               e2e_bert_encoder.layer_4_intermediate_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q12, rd_ptr_global: $gptr_q12}} }
    -   varinst: [$gptr_q12, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q12, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q10_shadow, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q10, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q11, incwrap, $c_microbatch_size, 8]
    -   varinst: [$lptr_q11, incwrap, $c_microbatch_size, 8]
    -   execute: {graph_name: fwd_5, queue_settings: {
               bert_encoder.layer_5_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_415_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_415_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_415_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_415_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_5_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_443: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_445.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_463_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_463_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_463_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_463_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_6_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_6_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_6_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_6_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_486_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_486_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_486_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_486_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q13, rd_ptr_global: $gptr_q13},
               e2e_bert_encoder.layer_6_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               e2e_bert_encoder.layer_6_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               e2e_bert_encoder.layer_6_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               e2e_bert_encoder.layer_5_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               e2e_bert_encoder.layer_5_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q14, rd_ptr_global: $gptr_q14},
               e2e_layernorm_392_bias_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q15, rd_ptr_global: $gptr_q15},
               e2e_bert_encoder.layer_5_output_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q15, rd_ptr_global: $gptr_q15},
               e2e_gelu_408_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q15, rd_ptr_global: $gptr_q15}} }
    -   varinst: [$lptr_q13, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q14, incwrap, $c_microbatch_size, 10]
    -   varinst: [$lptr_q14, incwrap, $c_microbatch_size, 10]
    -   varinst: [$gptr_q15, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q15, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q13_shadow, incwrap, $c_microbatch_size, 18]
    -   execute: {graph_name: fwd_6, queue_settings: {
               lc.input_tensor.bert_encoder.layer_7_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_4_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_514: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_516.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_534_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_534_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_534_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_534_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_7_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_7_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_7_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_7_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_557_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_557_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_557_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_557_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_3_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_8_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_585: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_587.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q16, rd_ptr_global: $gptr_q16},
               e2e_bert_encoder.layer_7_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_bert_encoder.layer_7_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_bert_encoder.layer_7_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_bert_encoder.layer_7_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_bert_encoder.layer_6_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q17, rd_ptr_global: $gptr_q17},
               e2e_layernorm_486_weights_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q18, rd_ptr_global: $gptr_q18}} }
    -   varinst: [$lptr_q16, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q17, incwrap, $c_microbatch_size, 12]
    -   varinst: [$lptr_q17, incwrap, $c_microbatch_size, 12]
    -   varinst: [$gptr_q18, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q18, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q16_shadow, incwrap, $c_microbatch_size, 18]
    -   execute: {graph_name: fwd_7, queue_settings: {
               bert_encoder.layer_8_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_605_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_605_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_605_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_605_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_8_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_8_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_8_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_8_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_628_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_628_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_628_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_628_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_2_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_656: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_658.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_676_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_676_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_676_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_676_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_9_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q19, rd_ptr_global: $gptr_q19},
               e2e_bert_encoder.layer_9_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_bert_encoder.layer_9_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_bert_encoder.layer_8_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_bert_encoder.layer_8_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_bert_encoder.layer_8_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_bert_encoder.layer_8_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q20, rd_ptr_global: $gptr_q20},
               e2e_layernorm_557_bias_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q21, rd_ptr_global: $gptr_q21},
               e2e_bert_encoder.layer_8_attention_output_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q21, rd_ptr_global: $gptr_q21},
               e2e_add_592_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q21, rd_ptr_global: $gptr_q21},
               e2e_softmax_587.dc.exp.0_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q21, rd_ptr_global: $gptr_q21},
               e2e_softmax_587.dc.reciprocal.2_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q21, rd_ptr_global: $gptr_q21}} }
    -   varinst: [$gptr_q20, incwrap, $c_microbatch_size, 14]
    -   varinst: [$lptr_q20, incwrap, $c_microbatch_size, 14]
    -   varinst: [$gptr_q19_shadow, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q19, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q21, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q21, incwrap, $c_microbatch_size, 2]
    -   execute: {graph_name: fwd_8, queue_settings: {
               bert_encoder.layer_9_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_9_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_699_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_699_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_699_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_699_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_1_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_727: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_729.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_747_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_747_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_747_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_747_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_10_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_10_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_10_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q22, rd_ptr_global: $gptr_q22},
               e2e_bert_encoder.layer_10_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q23, rd_ptr_global: $gptr_q23},
               e2e_bert_encoder.layer_10_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q23, rd_ptr_global: $gptr_q23},
               e2e_bert_encoder.layer_9_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q23, rd_ptr_global: $gptr_q23},
               e2e_bert_encoder.layer_9_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q23, rd_ptr_global: $gptr_q23},
               e2e_layernorm_676_bias_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               e2e_layernorm_676_bias_1: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               e2e_bert_encoder.layer_9_output_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24},
               e2e_bert_encoder.layer_9_intermediate_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q24, rd_ptr_global: $gptr_q24}} }
    -   varinst: [$gptr_q24, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q24, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q22_shadow, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q22, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q23, incwrap, $c_microbatch_size, 16]
    -   varinst: [$lptr_q23, incwrap, $c_microbatch_size, 16]
    -   execute: {graph_name: fwd_9, queue_settings: {
               bert_encoder.layer_10_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_770_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_770_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_770_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_770_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_attention_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_attention_self_value_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_self_value_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_self_value_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.input_1_add_799_s_brcst_m2_0_1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_attention_self_key_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_self_key_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_self_key_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_attention_self_query_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_self_query_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_self_query_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               constant_1_multiply_798: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.softmax_800.dc.reduce_sum.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_attention_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_818_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_818_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_818_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_818_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_output_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_output_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.bert_encoder.layer_11_intermediate_dense_bias_s_brcst_m2_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               bert_encoder.layer_11_intermediate_dense_bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_11_intermediate_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               bert_encoder.layer_11_output_dense_weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.layernorm_841_mean.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_841_var.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               constant_1_layernorm_841_var_plus_eps: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.layernorm_841_recip_s_brcst_m1_0_0.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_799: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q25, rd_ptr_global: $gptr_q25},
               e2e_bert_encoder.layer_11_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q26, rd_ptr_global: $gptr_q26},
               e2e_bert_encoder.layer_11_attention_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q26, rd_ptr_global: $gptr_q26},
               e2e_bert_encoder.layer_11_attention_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q26, rd_ptr_global: $gptr_q26},
               e2e_bert_encoder.layer_10_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q26, rd_ptr_global: $gptr_q26},
               e2e_bert_encoder.layer_10_output_LayerNorm_weight_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q26, rd_ptr_global: $gptr_q26},
               e2e_layernorm_747_bias_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q27, rd_ptr_global: $gptr_q27},
               e2e_bert_encoder.layer_10_output_dense_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q27, rd_ptr_global: $gptr_q27},
               e2e_gelu_763_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q27, rd_ptr_global: $gptr_q27}} }
    -   varinst: [$gptr_q27, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q27, incwrap, $c_microbatch_size, 2]
    -   varinst: [$gptr_q25, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q25, incwrap, $c_microbatch_size, 18]
    -   varinst: [$gptr_q26, incwrap, $c_microbatch_size, 18]
    -   varinst: [$lptr_q26, incwrap, $c_microbatch_size, 18]
    -   execute: {graph_name: fwd_10, queue_settings: {
               e2e_bert_encoder.layer_11_output_LayerNorm_bias_s_brcst_m2_0_0.lc1_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q28, rd_ptr_global: $gptr_q28},
               e2e_layernorm_841_weights_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q29, rd_ptr_global: $gptr_q29}} }
    -   varinst: [$gptr_q28, incwrap, $c_microbatch_size, 20]
    -   varinst: [$lptr_q28, incwrap, $c_microbatch_size, 20]
    -   varinst: [$gptr_q29, incwrap, $c_microbatch_size, 2]
    -   varinst: [$lptr_q29, incwrap, $c_microbatch_size, 2]
    - endloop


