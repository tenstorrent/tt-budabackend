# test_config_id=39
devices:
  arch: grayskull

queues:
  dram_input0:
    type: queue
    input: HOST
    entries: 2
    grid_size: [6, 1]
    t: 1
    mblock: [1, 1]
    ublock: [1, 1]
    df: Float16
    target_device: 0
    loc: dram
    dram: [[2, 0x10000000], [2, 0x10001060], [2, 0x100020c0], [2, 0x10003120], [2, 0x10004180], [2, 0x100051e0]]

  dram_input1:
    type: queue
    input: HOST
    entries: 2
    grid_size: [1, 9]
    t: 16
    mblock: [5, 1]
    ublock: [1, 2]
    df: Float16
    target_device: 0
    loc: dram
    dram: [[0, 0x10000000], [0, 0x100a2820], [0, 0x10145040], [0, 0x101e7860], [0, 0x1028a080], [0, 0x1032c8a0], [0, 0x103cf0c0], [0, 0x104718e0], [0, 0x10514100]]

  dram_output:
    type: queue
    input: op0
    entries: 2
    grid_size: [3, 12]
    t: 2
    mblock: [2, 2]
    ublock: [1, 3]
    df: Float16
    target_device: 0
    loc: dram
    dram: [[5, 0x10000000], [5, 0x10018620], [5, 0x10030c40], [5, 0x10049260], [5, 0x10061880], [5, 0x10079ea0], [5, 0x100924c0], [5, 0x100aaae0], [5, 0x100c3100], [5, 0x100db720], [5, 0x100f3d40], [5, 0x1010c360], [5, 0x10124980], [5, 0x1013cfa0], [5, 0x101555c0], [5, 0x1016dbe0], [5, 0x10186200], [5, 0x1019e820], [5, 0x101b6e40], [5, 0x101cf460], [5, 0x101e7a80], [5, 0x102000a0], [5, 0x102186c0], [5, 0x10230ce0], [5, 0x10249300], [5, 0x10261920], [5, 0x10279f40], [5, 0x10292560], [5, 0x102aab80], [5, 0x102c31a0], [5, 0x102db7c0], [5, 0x102f3de0], [5, 0x1030c400], [5, 0x10324a20], [5, 0x1033d040], [5, 0x10355660]]

graphs:
  test_multi_tm_datacopy_matmul:
    target_device: 0
    input_count: 2
    feeder0:
      type: datacopy
      grid_loc: [4, 0]
      grid_size: [6, 1]
      inputs: [dram_input0]
      in_df: [Float16]
      acc_df: Float16
      out_df: Float16
      intermed_df: Float16
      ublock_order: r
      buf_size_mb: 2
      math_fidelity: HiFi4
      untilize_output: false
      t: 1
      mblock: [1, 1]
      ublock: [1, 1]
    feeder1:
      type: datacopy
      grid_loc: [4, 1]
      grid_size: [1, 9]
      inputs: [dram_input1]
      in_df: [Float16]
      acc_df: Float16
      out_df: Float16
      intermed_df: Float16
      ublock_order: r
      buf_size_mb: 16
      math_fidelity: HiFi4
      untilize_output: false
      t: 16
      mblock: [5, 1]
      ublock: [1, 2]
    op0:
      type: matmul
      grid_loc: [1, 0]
      grid_size: [3, 12]
      inputs: [feeder0, feeder1]
      in_df: [Float16, Float16]
      acc_df: Float16
      out_df: Float16
      intermed_df: Float16
      ublock_order: r
      buf_size_mb: 4
      math_fidelity: HiFi4
      attributes: {m_k: 2, u_kt: 5}
      untilize_output: false
      t: 2
      mblock: [2, 2]
      ublock: [1, 3]
      input_0_tms: [broadcast: {c: 20}, hslice: 2]
      input_1_tms: [vstack: 2, hstack: 4]

programs:
  - test_multi_tm_datacopy_matmul_program:
    - param: [$p_microbatch_count, $p_microbatch_size]
    - staticvar: [$lptr, $gptr]
    - var: {$c_zero: 0, $c_wrap: 2}                         # c_wrap = 2 - finally need to be equal to 2*entries == 2*microbatch_size*microbatch_count
    - varinst: [$c_wrap, mul, $c_wrap, $p_microbatch_size]  # c_wrap = 2*microbatch_size
    - varinst: [$c_wrap, mul, $c_wrap, $p_microbatch_count] # c_wrap = 2*microbatch_size*microbatch_count
    - loop: $p_microbatch_count #loop over number of microbatches that make a minibatch
    -   execute: {
          graph_name: test_multi_tm_datacopy_matmul,
          queue_settings: {
            dram_input0: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr},
            dram_input1: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr}
          }
        }
    -   varinst: [$lptr, incwrap, $p_microbatch_size, $c_wrap]
    -   varinst: [$gptr, incwrap, $p_microbatch_size, $c_wrap]
    - endloop

test-config:
  test-args:
    microbatch_count: 1 # entries / input_count
    microbatch_size: 2 # input_count
    minibatch_count: 1 # host loop iterations