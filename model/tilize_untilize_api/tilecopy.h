// SPDX-FileCopyrightText: Â© 2024 Tenstorrent AI ULC
//
// SPDX-License-Identifier: Apache-2.0
#pragma once

#include <algorithm>
#include <cstdint>

#include "element_types.h"
#include "alignment.h"
#include "visibility.h"
#include "netlist/tt_backend_api_types.hpp"
#include "common/io_lib.hpp"
#include "model/tilize_untilize_api/tilize.h"

// Asserts that the tagged pointer parameter does not alias with any other pointer parameter,
// i.e. that any value accessed through this pointer is never accessed through any pointer parameter.
#define NO_PTR_ALIAS __restrict__

template <std::uint_fast32_t TileX, std::uint_fast32_t TileY, class Converter, bool DataShuffling>
void tensor_to_quad_tiles(const typename Converter::in_type * NO_PTR_ALIAS in,
                          typename Converter::out_type * NO_PTR_ALIAS out,
                          std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format = false, std::vector<bool>& fill_data_for_faces = {true, true}, int num_rows_with_data = -1, uint32_t global_face_offset = -1, uint32_t quad_height = 16, uint32_t num_faces_y = 2, uint32_t num_faces_x = 2, uint8_t* exp_host = nullptr, bool truncate_bfp_mantissa = false);

template <std::uint_fast32_t TileX, std::uint_fast32_t TileY, class Converter>
void tensor_to_megarow_quad(const typename Converter::in_type * NO_PTR_ALIAS in,
                          typename Converter::out_type * NO_PTR_ALIAS out,
                          std::uint_fast32_t tensor_row_pitch);

template <std::uint_fast32_t TileX, class Converter>
void row_copy(const typename Converter::in_type * NO_PTR_ALIAS in, typename Converter::out_type * NO_PTR_ALIAS out, uint32_t copy_size_bytes);


tt::tt_PytorchTensorDesc shuffle_for_conv_fp32_stride1(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint32_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp32_stride2(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint32_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp32_stride4(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint32_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp16_stride1(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint16_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp16_stride2(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint16_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp16_stride4(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint16_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx);


tt::tt_PytorchTensorDesc shuffle_for_conv_fp32_stride1_scalar_fallback(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint32_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx, std::unordered_map<uint32_t, uint32_t>& scalar_output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp32_stride2_scalar_fallback(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint32_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& input_idx, const std::vector<uint32_t>& output_idx, std::unordered_map<uint32_t, uint32_t>& scalar_output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp32_stride4_scalar_fallback(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint32_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx, std::unordered_map<uint32_t, uint32_t>& scalar_output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp16_stride1_scalar_fallback(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint16_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx, std::unordered_map<uint32_t, uint32_t>& scalar_output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp16_stride2_scalar_fallback(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint16_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& input_idx, const std::vector<uint32_t>& output_idx, std::unordered_map<uint32_t, uint32_t>& scalar_output_idx);
tt::tt_PytorchTensorDesc shuffle_for_conv_fp16_stride4_scalar_fallback(const tt::tt_PytorchTensorDesc &py_tensor_desc, aligned_vector<std::uint16_t>& shuffled_data, uint32_t num_rows, uint32_t input_face_shape, uint32_t shuffled_row_size, TT_ThreadPool& thread_pool, const std::vector<uint32_t>& output_idx, std::unordered_map<uint32_t, uint32_t>& scalar_output_idx);

// The following specializations are provided.

extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Fp32, true>(const float* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Fp16b, true>(const float* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Fp16b, true>(const std::uint16_t* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Bfp8_all, true>(const float* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Bfp8_all, true>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Bfp8, true>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Bfp8b, true>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Fp32, true>(const std::uint16_t* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Fp32, true>(const std::uint16_t* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Fp16, true>(const float* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Fp16, true>(const std::uint16_t* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Fp16b, true>(const std::uint16_t* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Int8_Int8, true>(const int8_t* NO_PTR_ALIAS in, int8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Int8_Bfp8, true>(const uint8_t* NO_PTR_ALIAS in, uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);

extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Fp32, false>(const float* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Fp16b, false>(const float* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Fp16b, false>(const float* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Fp16, false>(const float* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Fp16b, false>(const std::uint16_t* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Fp16, false>(const std::uint16_t* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp32_Bfp8_all, false>(const float* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Bfp8_all, false>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16b_Fp32, false>(const std::uint16_t* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Bfp8, false>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Bfp8b, false>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Fp16b, false>(const std::uint16_t* NO_PTR_ALIAS in, std::uint16_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Fp16_Fp32, false>(const std::uint16_t* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Int8_Int8, false>(const int8_t* NO_PTR_ALIAS in, int8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);
extern template HIDDEN_TEMPLATE void tensor_to_quad_tiles<16, 16, Int8_Bfp8, false>(const uint8_t* NO_PTR_ALIAS in, uint8_t* NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch, bool conversion_from_b_to_a_format, std::vector<bool>& fill_data_for_faces, int num_rows_with_data, uint32_t global_face_offset, uint32_t quad_height, uint32_t num_faces_y, uint32_t num_faces_x, uint8_t* exp_host, bool truncate_bfp_mantissa);

/////////////////// The following are for pushing raw data to DRAM ///////////////////
extern template HIDDEN_TEMPLATE void tensor_to_megarow_quad<32, 32, RawUInt32_RawUInt32>(const std::uint32_t*  NO_PTR_ALIAS in, std::uint32_t*  NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch);
extern template HIDDEN_TEMPLATE void tensor_to_megarow_quad<32, 32, RawUInt16_RawUInt16>(const std::uint16_t*  NO_PTR_ALIAS in, std::uint16_t*  NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch);
extern template HIDDEN_TEMPLATE void tensor_to_megarow_quad<32, 32, RawUInt8_RawUInt8>(const std::uint8_t*  NO_PTR_ALIAS in, std::uint8_t*  NO_PTR_ALIAS out, std::uint_fast32_t tensor_row_pitch);

/////////////////// The following are for pushing single rows to DRAM (for embeddings) ///////////////////
extern template HIDDEN_TEMPLATE void row_copy<32, RawUInt32_RawUInt32>(const std::uint32_t*  NO_PTR_ALIAS in, std::uint32_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, RawUInt16_RawUInt16>(const std::uint16_t*  NO_PTR_ALIAS in, std::uint16_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, RawUInt8_RawUInt8>(const std::uint8_t*  NO_PTR_ALIAS in, std::uint8_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp32_Fp32>(const float*  NO_PTR_ALIAS in, float*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp32_Fp16b>(const float*  NO_PTR_ALIAS in, std::uint16_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp32_Fp16>(const float*  NO_PTR_ALIAS in, std::uint16_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16b_Fp16b>(const std::uint16_t*  NO_PTR_ALIAS in, std::uint16_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16b_Fp16>(const std::uint16_t*  NO_PTR_ALIAS in, std::uint16_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16_Fp16b>(const std::uint16_t*  NO_PTR_ALIAS in, std::uint16_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);

extern template HIDDEN_TEMPLATE void row_copy<32, Fp32_Bfp8_all>(const float* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16b_Bfp8_all>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16b_Fp32>(const std::uint16_t* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16_Bfp8>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16_Bfp8b>(const std::uint16_t* NO_PTR_ALIAS in, std::uint8_t* NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Fp16_Fp32>(const std::uint16_t* NO_PTR_ALIAS in, float* NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Int8_Int8>(const std::int8_t*  NO_PTR_ALIAS in, std::int8_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);
extern template HIDDEN_TEMPLATE void row_copy<32, Int8_Bfp8>(const std::uint8_t*  NO_PTR_ALIAS in, std::uint8_t*  NO_PTR_ALIAS out, uint32_t copy_size_bytes);