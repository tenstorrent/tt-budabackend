# git checkout 4a62b4c36
# pytest pybuda/test/benchmark/benchmark.py -m mobilenet_v2 -c 224 -opt 4 --loop_count 32 -mb 64 -bp Ribbon -df Fp16_b -mf HiFi2 -o perf.json --auto_transpose

devices:
  arch: wormhole_b0

queues:

  # input
  features_1:                                                                                {input: HOST, type: queue, entries: 128, grid_size: [1, 1], t: 1, mblock: [1, 392], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x0]]}

  # output
  pt_mobilenet_v2_224.output_add_761:                                                        {input: add_761, type: queue, entries: 128, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x6388020]]}

  # parameter
  mobilenet_v2.conv_stem.first_conv.convolution.weight:                                      {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4282d60], [5, 0x401a14c0]]}
  mobilenet_v2.conv_stem.first_conv.convolution.weight_fork_clone1876:                       {input: HOST, type: ram, entries: 1, grid_size: [2, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29e0ec0], [0, 0x4013c0e0]]}
  mobilenet_v2.conv_stem.conv_3x3.convolution.weight_fork_clone1295:                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40135c40]]}
  mobilenet_v2.conv_stem.conv_3x3.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98a93e0]]}
  mobilenet_v2.conv_stem.conv_3x3.convolution.weight_fork_clone1293:                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4019e3c0]]}
  mobilenet_v2.conv_stem.reduce_1x1.convolution.weight:                                      {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29e4300]]}
  mobilenet_v2.layer.0.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98aee20], [4, 0x400eab00], [5, 0x4288f20]]}
  mobilenet_v2.layer.0.conv_3x3.convolution.weight_fork_clone1329:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4012c840]]}
  mobilenet_v2.layer.0.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x41c6660]]}
  mobilenet_v2.layer.0.conv_3x3.convolution.weight_fork_clone1327:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42835a0]]}
  mobilenet_v2.layer.0.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4012afc0]]}
  mobilenet_v2.layer.1.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 5], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6892000], [3, 0x4011e0a0], [4, 0x98a62e0], [4, 0x400e0780], [5, 0x423f560]]}
  mobilenet_v2.layer.1.conv_3x3.convolution.weight_fork_clone1363:                           {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 5], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2a99f60], [2, 0x4012d640], [3, 0x688f740]]}
  mobilenet_v2.layer.1.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 5], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4011a7a0], [4, 0x98a35e0], [4, 0x400dda80]]}
  mobilenet_v2.layer.1.conv_3x3.convolution.weight_fork_clone1361:                           {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 5], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29d6a40], [0, 0x40132760], [1, 0x41b5640]]}
  mobilenet_v2.layer.1.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [5, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400db1c0]]}
  mobilenet_v2.layer.2.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 5], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400d2c60], [2, 0x2a974a0], [2, 0x4012ab80], [3, 0x688cc80], [3, 0x40119f60]]}
  mobilenet_v2.layer.2.conv_3x3.convolution.weight_fork_clone1397:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 5], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x41bac60]]}
  mobilenet_v2.layer.2.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 5], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40120160]]}
  mobilenet_v2.layer.2.conv_3x3.convolution.weight_fork_clone1395:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 5], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40154e20]]}
  mobilenet_v2.layer.2.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [5, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400e0fc0]]}
  mobilenet_v2.layer.3.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6892840], [3, 0x4011e8e0]]}
  mobilenet_v2.layer.3.conv_3x3.convolution.weight_fork_clone1431:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x41cd9e0]]}
  mobilenet_v2.layer.3.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40107060]]}
  mobilenet_v2.layer.3.conv_3x3.convolution.weight_fork_clone1429:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2aafb00]]}
  mobilenet_v2.layer.3.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [6, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40147580]]}
  mobilenet_v2.layer.4.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x401102c0], [5, 0x42a3560]]}
  mobilenet_v2.layer.4.conv_3x3.convolution.weight_fork_clone1465:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4014a660]]}
  mobilenet_v2.layer.4.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x42078e0]]}
  mobilenet_v2.layer.4.conv_3x3.convolution.weight_fork_clone1463:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98b70a0]]}
  mobilenet_v2.layer.4.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [6, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4204800]]}
  mobilenet_v2.layer.5.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401d1aa0], [0, 0x2a0f5e0]]}
  mobilenet_v2.layer.5.conv_3x3.convolution.weight_fork_clone1499:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 6], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x68a4360]]}
  mobilenet_v2.layer.5.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 6], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40137b60]]}
  mobilenet_v2.layer.5.conv_3x3.convolution.weight_fork_clone1497:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 6], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4013f520]]}
  mobilenet_v2.layer.5.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [6, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400eb340]]}
  mobilenet_v2.layer.6.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [2, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x689b5a0], [3, 0x401319c0]]}
  mobilenet_v2.layer.6.conv_3x3.convolution.weight_fork_clone1533:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29e4b40]]}
  mobilenet_v2.layer.6.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400f2520]]}
  mobilenet_v2.layer.6.conv_3x3.convolution.weight_fork_clone1531:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29f9aa0]]}
  mobilenet_v2.layer.6.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400e23a0]]}
  mobilenet_v2.layer.7.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [2, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x401418a0], [3, 0x68ad5c0]]}
  mobilenet_v2.layer.7.conv_3x3.convolution.weight_fork_clone1567:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401bcfa0]]}
  mobilenet_v2.layer.7.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400c78a0]]}
  mobilenet_v2.layer.7.conv_3x3.convolution.weight_fork_clone1565:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 12], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40f3780]]}
  mobilenet_v2.layer.7.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2916b40]]}
  mobilenet_v2.layer.8.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [2, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x97e70e0], [4, 0x4003fe40]]}
  mobilenet_v2.layer.8.conv_3x3.convolution.weight_fork_clone1601:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40042400]]}
  mobilenet_v2.layer.8.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40053ce0]]}
  mobilenet_v2.layer.8.conv_3x3.convolution.weight_fork_clone1599:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 12], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4106c60]]}
  mobilenet_v2.layer.8.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 1], ublock: [4, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4006c320]]}
  mobilenet_v2.layer.9.expand_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [2, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x411b200], [5, 0x40066180]]}
  mobilenet_v2.layer.9.conv_3x3.convolution.weight_fork_clone1635:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2925660]]}
  mobilenet_v2.layer.9.conv_3x3.convolution.weight:                                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4003bb80]]}
  mobilenet_v2.layer.9.conv_3x3.convolution.weight_fork_clone1633:                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 12], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40013500]]}
  mobilenet_v2.layer.9.reduce_1x1.convolution.weight:                                        {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [4, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40da7e0]]}
  mobilenet_v2.layer.10.expand_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [3, 9], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40001640], [0, 0x28ea7e0]]}
  mobilenet_v2.layer.10.conv_3x3.convolution.weight_fork_clone1669:                          {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x28e1580], [0, 0x40001480], [1, 0x40d1580]]}
  mobilenet_v2.layer.10.conv_3x3.convolution.weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40009260], [2, 0x28e9360], [2, 0x40009260]]}
  mobilenet_v2.layer.10.conv_3x3.convolution.weight_fork_clone1667:                          {input: HOST, type: ram, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40000000], [2, 0x28e0100], [2, 0x40000000]]}
  mobilenet_v2.layer.10.reduce_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [6, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40024760]]}
  mobilenet_v2.layer.11.expand_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [3, 6], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40edfe0], [1, 0x4003f300], [2, 0x291fae0], [2, 0x400269e0], [3, 0x67df1c0], [3, 0x400439c0], [4, 0x97e3fe0], [4, 0x40022ee0], [5, 0x40d8940], [5, 0x40012480], [0, 0x29152c0], [0, 0x4000e820], [1, 0x40ef860], [1, 0x40040b80], [2, 0x2921360], [2, 0x40028260], [3, 0x67e0a40], [3, 0x40045240]]}
  mobilenet_v2.layer.11.conv_3x3.convolution.weight_fork_clone1703:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x67c2780]]}
  mobilenet_v2.layer.11.conv_3x3.convolution.weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x28f8360]]}
  mobilenet_v2.layer.11.conv_3x3.convolution.weight_fork_clone1701:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40005f80]]}
  mobilenet_v2.layer.11.reduce_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [6, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x41f1da0]]}
  mobilenet_v2.layer.12.expand_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 6], t: 1, mblock: [3, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400b3c80], [2, 0x2a4b9a0], [2, 0x4010be00], [3, 0x6886ec0], [3, 0x400e7680], [4, 0x989d3a0]]}
  mobilenet_v2.layer.12.conv_3x3.convolution.weight_fork_clone1737:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x686b7e0]]}
  mobilenet_v2.layer.12.conv_3x3.convolution.weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400c3b80]]}
  mobilenet_v2.layer.12.conv_3x3.convolution.weight_fork_clone1735:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 3], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x41d4e40]]}
  mobilenet_v2.layer.12.reduce_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [6, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400b8ae0]]}
  mobilenet_v2.layer.13.expand_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 5], ublock: [5, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4196880], [1, 0x4009a620], [2, 0x2a32340]]}
  mobilenet_v2.layer.13.conv_3x3.convolution.weight_fork_clone1771:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2a502e0]]}
  mobilenet_v2.layer.13.conv_3x3.convolution.weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400ebfc0]]}
  mobilenet_v2.layer.13.conv_3x3.convolution.weight_fork_clone1769:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x420d480]]}
  mobilenet_v2.layer.13.reduce_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [6, 5], ublock: [5, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400e5c40]]}
  mobilenet_v2.layer.14.expand_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 5], ublock: [5, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400b9600], [2, 0x2a7de40], [2, 0x40111520]]}
  mobilenet_v2.layer.14.conv_3x3.convolution.weight_fork_clone1805:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40091ca0]]}
  mobilenet_v2.layer.14.conv_3x3.convolution.weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x97f5bc0]]}
  mobilenet_v2.layer.14.conv_3x3.convolution.weight_fork_clone1803:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4002e900]]}
  mobilenet_v2.layer.14.reduce_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [6, 5], ublock: [5, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4119100]]}
  mobilenet_v2.layer.15.expand_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 5], ublock: [5, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4122400], [5, 0x40078640], [0, 0x2979c20]]}
  mobilenet_v2.layer.15.conv_3x3.convolution.weight_fork_clone1839:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2a047e0]]}
  mobilenet_v2.layer.15.conv_3x3.convolution.weight:                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40096020]]}
  mobilenet_v2.layer.15.conv_3x3.convolution.weight_fork_clone1837:                          {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [3, 5], ublock: [1, 6], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x41a72e0]]}
  mobilenet_v2.layer.15.reduce_1x1.convolution.weight:                                       {input: HOST, type: ram, entries: 1, grid_size: [1, 2], t: 1, mblock: [6, 5], ublock: [5, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x29b8500], [2, 0x400bcc80]]}
  mobilenet_v2.conv_1x1.convolution.weight:                                                  {input: HOST, type: ram, entries: 1, grid_size: [2, 8], t: 1, mblock: [5, 5], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x418dc60], [5, 0x40110c20], [0, 0x2994b00], [0, 0x4007c9a0], [1, 0x4186440], [1, 0x4008a440], [2, 0x29ab9c0], [2, 0x400b0140], [3, 0x683dc40], [3, 0x400a6e40], [4, 0x9877400], [4, 0x400a1ee0], [5, 0x419a7a0], [5, 0x4011d760], [0, 0x29a1640], [0, 0x400894e0]]}
  classifier.weight:                                                                         {input: HOST, type: ram, entries: 1, grid_size: [1, 8], t: 1, mblock: [2, 1], ublock: [20, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2957ce0], [2, 0x4005c460], [3, 0x67e9f60], [3, 0x40053160], [4, 0x9823720], [4, 0x4004e200], [5, 0x413c840], [5, 0x400bf800]]}
  classifier.bias:                                                                           {input: HOST, type: ram, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 8], ublock: [1, 4], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40077760]]}

  # constant
  lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x4002c180], [3, 0x67e53a0], [3, 0x40049ba0], [4, 0x97ed280]]}
  lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x29e1700], [0, 0x4013c920], [1, 0x41c5620], [1, 0x400db240]]}
  lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 7], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x6898580], [3, 0x4012a600], [4, 0x98abba0], [4, 0x400e7880]]}
  lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1:  {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x41c45e0], [1, 0x400da200], [2, 0x2aa34a0], [2, 0x401374c0]]}
  input_1_add_2_fork_clone1167:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401a0c80]]}
  lc.input_tensor.conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 11], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x401296c0], [4, 0x98aac60], [4, 0x400e6940], [5, 0x4281e20]]}
  lc.input_tensor.conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x68961e0], [3, 0x40127b60], [4, 0x98a83a0], [4, 0x400e48c0]]}
  lc.input_tensor.conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 11], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x4013b1a0], [1, 0x41c36a0], [1, 0x400d92c0], [2, 0x2aa2560]]}
  lc.input_tensor.conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x400e5900], [5, 0x4280de0], [5, 0x4019fc40], [0, 0x29dfe80]]}
  lc.input_tensor.conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 8], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2aa1a40], [2, 0x40135120], [3, 0x6897220], [3, 0x40128ba0]]}
  lc.input_tensor.conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [4, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x29dee40], [0, 0x4013a160], [1, 0x41c2660], [1, 0x400d8280]]}
  input_1_add_18:                                                                            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42805a0]]}
  input_1_add_18_fork_clone1142:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6897d40]]}
  input_1_add_32_fork_clone1115:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401a3700]]}
  input_1_add_45_fork_clone1083:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x4013a320], [3, 0x689ad60], [3, 0x40131180]]}
  lc.input_tensor.conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [3, 2], t: 1, mblock: [1, 7], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x401a2d40], [0, 0x29e3940], [0, 0x4013eb60], [1, 0x41cafa0], [1, 0x400dd2c0], [2, 0x2aa6300]]}
  lc.input_tensor.conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x98adde0], [4, 0x400e9ac0], [5, 0x4287ee0]]}
  lc.input_tensor.conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2aa44e0], [2, 0x40138500], [3, 0x6898f40]]}
  lc.input_tensor.conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400dc280]]}
  lc.input_tensor.conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 13], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x29e2740], [0, 0x4013d960]]}
  lc.input_tensor.conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x401a1d00]]}
  input_1_add_61:                                                                            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400e8240]]}
  input_1_add_61_fork_clone1033:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98ac560]]}
  input_1_add_75_fork_clone987:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29dc220]]}
  input_1_add_88_fork_clone1089:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 5], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40135460], [1, 0x41b8340], [1, 0x400d4920], [2, 0x2a9c820], [2, 0x4012ff00]]}
  lc.input_tensor.conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 5], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x98a5ea0], [4, 0x400e0340], [5, 0x423f120], [5, 0x401549e0], [0, 0x29d9740]]}
  lc.input_tensor.conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x4011d060]]}
  lc.input_tensor.conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 5], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x401545a0], [0, 0x29d9300], [0, 0x40135020], [1, 0x41b7f00], [1, 0x400d44e0]]}
  lc.input_tensor.conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x423e0e0]]}
  lc.input_tensor.conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 4], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x688c840], [3, 0x40119b20], [4, 0x98a2960], [4, 0x400dad80]]}
  lc.input_tensor.conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400d34a0]]}
  input_1_add_104:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40151ce0]]}
  input_1_add_104_fork_clone1039:                                                            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x423b820]]}
  input_1_add_118_fork_clone992:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98a2da0]]}
  input_1_add_132_fork_clone937:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 5], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x423afe0], [5, 0x401514a0], [0, 0x29d6200], [0, 0x40131f20], [1, 0x41b4e00]]}
  lc.input_tensor.conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 25], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2a97ce0], [2, 0x4012b3c0], [3, 0x688d4c0]]}
  lc.input_tensor.conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400d7240], [2, 0x2aa0a00], [2, 0x401340e0]]}
  lc.input_tensor.conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 26], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x4019bfe0], [0, 0x29dca60], [0, 0x40137d80]]}
  lc.input_tensor.conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x98a7360], [4, 0x400e3880], [5, 0x427f560]]}
  lc.input_tensor.conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 24], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2a9e8e0], [2, 0x40131fc0], [3, 0x68940c0]]}
  lc.input_tensor.conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x40136d40], [1, 0x41b9c20], [1, 0x400d6200]]}
  input_1_add_148:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [25, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4015c820]]}
  input_1_add_148_fork_clone862:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [25, 5], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x423fda0]]}
  input_1_add_162_fork_clone800:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98a6b20]]}
  input_1_add_175_fork_clone943:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2a9d060], [2, 0x40130740]]}
  lc.input_tensor.conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 12], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x40135ca0], [1, 0x41b8b80], [1, 0x400d5160]]}
  lc.input_tensor.conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x2aa52c0], [2, 0x401392e0], [3, 0x6899d20]]}
  lc.input_tensor.conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 12], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x400ee6c0], [2, 0x2aaea60], [2, 0x40147a40]]}
  lc.input_tensor.conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x68b3760], [3, 0x40146540], [4, 0x98b5820]]}
  lc.input_tensor.conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x42a2780], [5, 0x401cf440], [0, 0x2a0cf80]]}
  lc.input_tensor.conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x40177d60], [1, 0x4202720], [1, 0x400ef760]]}
  input_1_add_191:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [25, 3], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x40148ae0]]}
  input_1_add_191_fork_clone868:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [25, 3], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x68b47a0]]}
  input_1_add_205_fork_clone805:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98b6860]]}
  input_1_add_219_fork_clone930:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401d0220], [0, 0x2a0dd60]]}
  lc.input_tensor.conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 12], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x40178da0], [1, 0x4203760], [1, 0x400f07a0]]}
  lc.input_tensor.conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x2a0bf40], [0, 0x40176d20], [1, 0x42016e0]]}
  lc.input_tensor.conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 12], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x401975c0], [3, 0x6903280], [3, 0x401538c0]]}
  lc.input_tensor.conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x4013db20], [2, 0x2b07840], [2, 0x40198660]]}
  lc.input_tensor.conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x401d3320], [0, 0x2a10e60], [0, 0x4017a680]]}
  lc.input_tensor.conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x98c0300], [4, 0x401133c0], [5, 0x42a6660]]}
  input_1_add_235:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [25, 3], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2abb560]]}
  input_1_add_235_fork_clone856:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [25, 3], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x400f1840]]}
  input_1_add_249_fork_clone791:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40179e40]]}
  input_1_add_263_fork_clone726:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40111b40], [5, 0x42a4de0]]}
  lc.input_tensor.conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 29], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2ab8d60], [2, 0x40194dc0], [3, 0x6900a80]]}
  lc.input_tensor.conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400e1360], [2, 0x2aac9c0], [2, 0x40140860]]}
  lc.input_tensor.conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 31], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x401b94a0], [0, 0x29f6fe0], [0, 0x401497c0]]}
  lc.input_tensor.conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x98b06c0], [4, 0x400f14e0], [5, 0x429ecc0]]}
  lc.input_tensor.conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 32], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2aa9da0], [2, 0x4013dc40], [3, 0x68a1740]]}
  lc.input_tensor.conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x40148780], [1, 0x41cc9a0], [1, 0x400e0320]]}
  input_1_add_279:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401a3f40]]}
  input_1_add_279_fork_clone630:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4289760]]}
  input_1_add_293_fork_clone549:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98af660]]}
  input_1_add_306_fork_clone732:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2aa6cc0], [2, 0x4013ab60]]}
  lc.input_tensor.conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x400ddc80]]}
  lc.input_tensor.conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x41cb960]]}
  lc.input_tensor.conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x40140dc0]]}
  lc.input_tensor.conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x98b1700]]}
  lc.input_tensor.conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 19], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x429fd00]]}
  lc.input_tensor.conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x401bbf60]]}
  input_1_add_322:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4014c280]]}
  input_1_add_322_fork_clone636:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x41d6c40]]}
  input_1_add_336_fork_clone554:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2aada00]]}
  input_1_add_350_fork_clone716:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40143460], [4, 0x98b2740]]}
  lc.input_tensor.conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x401049c0]]}
  lc.input_tensor.conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x42a1740]]}
  lc.input_tensor.conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x29d9b80]]}
  lc.input_tensor.conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x40045fe0]]}
  lc.input_tensor.conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 19], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2923c20]]}
  lc.input_tensor.conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400548a0]]}
  input_1_add_366:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x400110e0]]}
  input_1_add_366_fork_clone617:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2922e60]]}
  input_1_add_380_fork_clone536:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x411a1a0]]}
  input_1_add_394_fork_clone702:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x67e22c0], [3, 0x40046ac0]]}
  lc.input_tensor.conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x40029ae0]]}
  lc.input_tensor.conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x2922be0]]}
  lc.input_tensor.conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x40f10e0]]}
  lc.input_tensor.conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x400100a0]]}
  lc.input_tensor.conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 19], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x2937b00]]}
  lc.input_tensor.conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x40057f80]]}
  input_1_add_410:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4004e020]]}
  input_1_add_410_fork_clone603:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x294f180]]}
  input_1_add_424_fork_clone521:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x41213a0]]}
  input_1_add_438_fork_clone463:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 3], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4004a2a0], [4, 0x97ed980]]}
  lc.input_tensor.conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x67e5aa0]]}
  lc.input_tensor.conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x4002c880]]}
  lc.input_tensor.conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 28], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x400558e0]]}
  lc.input_tensor.conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x4105c20]]}
  lc.input_tensor.conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 19], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x291e0a0]]}
  lc.input_tensor.conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x40047020]]}
  input_1_add_454:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x28f3600]]}
  input_1_add_454_fork_clone388:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 4], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40013500]]}
  input_1_add_468_fork_clone326:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x4000a6e0]]}
  input_1_add_481_fork_clone469:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40001640], [5, 0x40d1740]]}
  lc.input_tensor.conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 13], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x67c1580], [3, 0x40001480], [4, 0x97a1580]]}
  lc.input_tensor.conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400124c0], [2, 0x28f25c0], [2, 0x400124c0]]}
  lc.input_tensor.conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 13], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x40000440], [5, 0x40d0540], [5, 0x40000440]]}
  lc.input_tensor.conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x67c0540], [3, 0x40000440], [4, 0x97a0540]]}
  lc.input_tensor.conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [3, 3], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x67c0100], [3, 0x40000000], [4, 0x97a0100], [4, 0x40000000], [5, 0x40d0100], [5, 0x40000000], [0, 0x28e1140], [0, 0x40001040], [1, 0x40d1140]]}
  lc.input_tensor.conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [3, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x28e0100], [0, 0x40000000], [1, 0x40d0100]]}
  input_1_add_497:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 9], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40013d00]]}
  input_1_add_497_fork_clone394:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 9], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40da1c0]]}
  input_1_add_511_fork_clone331:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x97e5860]]}
  input_1_add_525_fork_clone456:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 6], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x97e2760], [4, 0x40021660], [5, 0x40d70c0], [5, 0x40010c00], [0, 0x2913a40], [0, 0x4000cfa0]]}
  lc.input_tensor.conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 14], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x67dde60], [3, 0x40042660]]}
  lc.input_tensor.conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x400259a0]]}
  lc.input_tensor.conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 14], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x40ecc80], [1, 0x4003dfa0]]}
  lc.input_tensor.conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x4000bf60]]}
  lc.input_tensor.conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 19], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x4000f1c0]]}
  lc.input_tensor.conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x40d6080]]}
  input_1_add_541:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 9], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x97a2780]]}
  input_1_add_541_fork_clone382:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [7, 9], ublock: [1, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x40002680]]}
  input_1_add_555_fork_clone317:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x294d900]]}
  input_1_add_569_fork_clone260:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 6], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400c6020], [5, 0x41f0520], [5, 0x4012c320], [0, 0x29b1080], [0, 0x400df260], [1, 0x41afee0]]}
  lc.input_tensor.conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 22], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x989b540]]}
  lc.input_tensor.conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x400e6640]]}
  lc.input_tensor.conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 22], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x40109fa0]]}
  lc.input_tensor.conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x40108f60]]}
  lc.input_tensor.conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 25], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x29aee00]]}
  lc.input_tensor.conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x4012b2e0]]}
  input_1_add_585:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 9], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x400b3b80]]}
  input_1_add_585_fork_clone185:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 9], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98890a0]]}
  input_1_add_599_fork_clone125:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6868f20]]}
  input_1_add_612_fork_clone266:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 5], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x4012dba0], [0, 0x29b2900], [0, 0x400e0ae0]]}
  lc.input_tensor.conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x41b1760]]}
  lc.input_tensor.conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x400b85c0]]}
  lc.input_tensor.conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[2, 0x40110740]]}
  lc.input_tensor.conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x688b800]]}
  lc.input_tensor.conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[4, 0x98a1ce0]]}
  lc.input_tensor.conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x400d9d40]]}
  input_1_add_628:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 15], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x40132d00]]}
  input_1_add_628_fork_clone191:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 15], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29b7a60]]}
  input_1_add_642_fork_clone130:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x41b2540]]}
  input_1_add_656_fork_clone253:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 5], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x400b3980], [4, 0x9883f40], [4, 0x400aea20]]}
  lc.input_tensor.conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x4007b380]]}
  lc.input_tensor.conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[0, 0x2993280]]}
  lc.input_tensor.conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[5, 0x413ba60]]}
  lc.input_tensor.conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[4, 0x4004d1c0]]}
  lc.input_tensor.conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x400524e0]]}
  lc.input_tensor.conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[2, 0x4002d8c0]]}
  input_1_add_672:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 15], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[2, 0x2939540]]}
  input_1_add_672_fork_clone179:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 15], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x40058fc0]]}
  input_1_add_686_fork_clone119:                                                             {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x40078ac0]]}
  input_1_add_700_fork_clone85:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 3], t: 1, mblock: [1, 5], ublock: [1, 2], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x4004d380], [4, 0x97f0a60], [4, 0x40048060]]}
  lc.input_tensor.conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[3, 0x67e8140]]}
  lc.input_tensor.conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[3, 0x67e8f20]]}
  lc.input_tensor.conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 10], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[1, 0x40099840]]}
  lc.input_tensor.conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[1, 0x4195840]]}
  lc.input_tensor.conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 9], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Bfp2_b, target_device: 0, loc: dram, dram: [[0, 0x29ae180]]}
  lc.input_tensor.conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1:            {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: RawUInt32, target_device: 0, loc: dram, dram: [[5, 0x4012a2a0]]}
  input_1_add_716:                                                                           {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 15], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x41653e0]]}
  input_1_add_716_fork_clone60:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 1], t: 1, mblock: [1, 15], ublock: [2, 2], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x684a780]]}
  input_1_add_730_fork_clone37:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4192f80], [1, 0x40096f80]]}
  input_1_add_743_fork_clone20:                                                              {input: HOST, type: queue, entries: 1, grid_size: [1, 8], t: 1, mblock: [1, 5], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4183b80], [1, 0x40087b80], [2, 0x29a9100], [2, 0x400ad880], [3, 0x683b380], [3, 0x400a4580], [4, 0x9874b40], [4, 0x4009f620]]}
  lc.input_tensor.avg_pool2d_756.dc.reduce_avg.2.0:                                          {input: HOST, type: queue, entries: 1, grid_size: [1, 2], t: 1, mblock: [1, 1], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x29942c0], [0, 0x4007c160]]}

  # epoch_to_epoch
  e2e_conv2d_44.dc.matmul.8_0:                                                               {input: conv2d_44.dc.matmul.8, type: queue, entries: 64, grid_size: [2, 3], t: 14, mblock: [7, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x98c1340], [4, 0x40114400], [5, 0x42a76a0], [5, 0x401d4100], [0, 0x2a11c40], [0, 0x4017b460]]}
  e2e_conv2d_60.dc.conv2d.5.dc.depthwise.10_0:                                               {input: conv2d_60.dc.conv2d.5.dc.depthwise.10, type: queue, entries: 64, grid_size: [2, 1], t: 1, mblock: [7, 3], ublock: [7, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x6904320], [3, 0x40154960]]}
  e2e_conv2d_131.dc.matmul.8_0:                                                              {input: conv2d_131.dc.matmul.8, type: queue, entries: 64, grid_size: [1, 5], t: 7, mblock: [7, 1], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4210b40], [1, 0x4013eb60], [2, 0x2b08880], [2, 0x401996a0], [3, 0x7badb40]]}
  e2e_conv2d_262.dc.matmul.8_0:                                                              {input: conv2d_262.dc.matmul.8, type: queue, entries: 64, grid_size: [1, 2], t: 1, mblock: [25, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[3, 0x413fe180], [4, 0xb1a3360]]}
  e2e_conv2d_278.dc.conv2d.1.dc.depthwise.10_0:                                              {input: conv2d_278.dc.conv2d.1.dc.depthwise.10, type: queue, entries: 64, grid_size: [1, 1], t: 1, mblock: [1, 6], ublock: [7, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40114400]]}
  e2e_conv2d_278.dc.conv2d.5.dc.depthwise.10_0:                                              {input: conv2d_278.dc.conv2d.5.dc.depthwise.10, type: queue, entries: 64, grid_size: [1, 1], t: 1, mblock: [1, 6], ublock: [7, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x42a76a0]]}
  e2e_conv2d_480.dc.matmul.8_0:                                                              {input: conv2d_480.dc.matmul.8, type: queue, entries: 64, grid_size: [1, 2], t: 7, mblock: [1, 9], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x2a11c40], [0, 0x4017b460]]}
  e2e_conv2d_467.dc.matmul.8_0:                                                              {input: conv2d_467.dc.matmul.8, type: queue, entries: 64, grid_size: [1, 1], t: 7, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x401d4100]]}
  e2e_add_523_0:                                                                             {input: add_523, type: queue, entries: 64, grid_size: [1, 1], t: 1, mblock: [7, 3], ublock: [1, 1], ublock_order: c, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4210b40]]}
  e2e_conv2d_524.dc.matmul.8_0:                                                              {input: conv2d_524.dc.matmul.8, type: queue, entries: 64, grid_size: [7, 6], t: 1, mblock: [1, 3], ublock: [1, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x4013eb60], [2, 0x2b08880], [2, 0x401996a0], [3, 0x6904320], [3, 0x40154960], [4, 0x98c1340], [4, 0x40114400], [5, 0x42a76a0], [5, 0x4047e920], [0, 0x3211460], [0, 0x4097ac80], [1, 0x44bb360], [1, 0x401a0380], [2, 0x2b6a0a0], [2, 0x401faec0], [3, 0x6965b40], [3, 0x401b6180], [4, 0x9922b60], [4, 0x40175c20], [5, 0x4308ec0], [5, 0x404e0140], [0, 0x3272c80], [0, 0x409dc4a0], [1, 0x451cb80], [1, 0x40201ba0], [2, 0x2bcb8c0], [2, 0x4025c6e0], [3, 0x69c7360], [3, 0x402179a0], [4, 0x9984380], [4, 0x401d7440], [5, 0x436a6e0], [5, 0x40541960], [0, 0x32d44a0], [0, 0x40a3dcc0], [1, 0x457e3a0], [1, 0x402633c0], [2, 0x2c2d0e0], [2, 0x402bdf00], [3, 0x6a28b80], [3, 0x402791c0], [4, 0x99e5ba0]]}
  e2e_conv2d_729.dc.matmul.8_0:                                                              {input: conv2d_729.dc.matmul.8, type: queue, entries: 64, grid_size: [1, 2], t: 1, mblock: [1, 5], ublock: [2, 1], ublock_order: r, tile_dim: [32, 32], df: Float16_b, target_device: 0, loc: dram, dram: [[4, 0x40238c60], [5, 0x43cbf00]]}

graphs:
  fwd_0_0_temporal_epoch_0:
    target_device: 0
    input_count: 64
    conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0, features_1, lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1],
         t: 14, mblock: [2, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 5, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 196}}
    conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.matmul.11: {type: matmul, grid_loc: [0, 1], grid_size: [2, 1], inputs: [conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, mobilenet_v2.conv_stem.first_conv.convolution.weight],
         t: 14, mblock: [2, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 14}, hslice: 14], input_0_tms: [vslice: 56, hstack: 2, vstack: 28],
         attributes: {l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0, features_1, lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 14, mblock: [2, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [transpose],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 7, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 196}}
    conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.matmul.11: {type: matmul, grid_loc: [0, 6], grid_size: [2, 1], inputs: [conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.lc2, mobilenet_v2.conv_stem.first_conv.convolution.weight_fork_clone1876], grid_transpose: true,
         t: 14, mblock: [2, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 14}, hslice: 14], input_0_tms: [vslice: 56, hstack: 2, vstack: 28],
         attributes: {l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    _fused_op_0: {type: fused_op, grid_loc: [1, 2], grid_size: [2, 1], inputs: [conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.matmul.11, conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.matmul.11, input_1_add_2_fork_clone1167], grid_transpose: true,
         t: 1, mblock: [98, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 392}], input_1_tms: [vstack: 14], input_0_tms: [vstack: 14],
         attributes: {fused_op_id: 0, kernel_broadcast: {input_2: 1}}}
    conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 4], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 14, mblock: [3, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 11, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 196}}
    conv2d_17.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [2, 1], grid_size: [2, 1], inputs: [conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.conv_stem.conv_3x3.convolution.weight_fork_clone1295],
         t: 14, mblock: [2, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 14}, hslice: 14], input_0_tms: [vslice: 84, hstack: 3, vstack: 28],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 14, mblock: [3, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 11, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 196}}
    conv2d_17.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [2, 6], grid_size: [2, 1], inputs: [conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.conv_stem.conv_3x3.convolution.weight], grid_transpose: true,
         t: 14, mblock: [2, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 14}, hslice: 14], input_0_tms: [vslice: 84, hstack: 3, vstack: 28],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 2], grid_size: [4, 1], inputs: [lc.input_tensor.conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, _fused_op_0, lc.input_tensor.conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 14, mblock: [3, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 8, sparse_tile_ptr_bits: 4, sparse_ublock_idx_bits: 4, u_kt: 196}}
    conv2d_17.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [3, 6], grid_size: [2, 1], inputs: [conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.conv_stem.conv_3x3.convolution.weight_fork_clone1293], grid_transpose: true,
         t: 14, mblock: [2, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 14}, hslice: 14], input_0_tms: [vslice: 84, hstack: 3, vstack: 28],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_1: {type: fused_op, grid_loc: [4, 0], grid_size: [2, 1], inputs: [conv2d_17.dc.conv2d.1.dc.depthwise.10, conv2d_17.dc.conv2d.3.dc.depthwise.10, conv2d_17.dc.conv2d.5.dc.depthwise.10, input_1_add_18, input_1_add_18_fork_clone1142], grid_transpose: true,
         t: 14, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [broadcast: {r: 392}, vslice: 14], input_3_tms: [broadcast: {r: 392}, vslice: 14],
         attributes: {fused_op_id: 1, kernel_broadcast: {input_4: 1, input_3: 1}}}
    conv2d_31.dc.matmul.8: {type: matmul, grid_loc: [4, 2], grid_size: [2, 1], inputs: [_fused_op_1, mobilenet_v2.conv_stem.reduce_1x1.convolution.weight, input_1_add_32_fork_clone1115], grid_transpose: true,
         t: 14, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 392}, vslice: 14], input_1_tms: [broadcast: {c: 14}, hslice: 14],
         attributes: {bias: true, kernel_broadcast: {input_2: 1, input_1: 1}, m_k: 1, min_buffer_input: 0, u_kt: 1}}
    conv2d_44.dc.matmul.8: {type: matmul, grid_loc: [4, 4], grid_size: [2, 3], inputs: [conv2d_31.dc.matmul.8, mobilenet_v2.layer.0.expand_1x1.convolution.weight, input_1_add_45_fork_clone1083],
         t: 14, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 392}, vslice: 14], input_1_tms: [broadcast: {c: 14}, hslice: 14],
         attributes: {bias: true, kernel_broadcast: {input_2: 2, input_1: 14}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 0], grid_size: [3, 3], inputs: [lc.input_tensor.conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_44.dc.matmul.8, lc.input_tensor.conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [14, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 3}], input_1_tms: [vstack: 14], input_0_tms: [broadcast: {c: 3}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 28, num_index_tiles: 1, num_sparse_tiles: 14, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 14}}
    conv2d_60.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [4, 7], grid_size: [2, 1], inputs: [conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.0.conv_3x3.convolution.weight_fork_clone1329],
         t: 1, mblock: [7, 3], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}

  fwd_0_1_temporal_epoch_1:
    target_device: 0
    input_count: 64
    conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [1, 3], inputs: [lc.input_tensor.conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_44.dc.matmul.8_0, lc.input_tensor.conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [6, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 3}], input_1_tms: [vstack: 14], input_0_tms: [broadcast: {c: 3}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 30, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 98}}
    conv2d_60.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [0, 3], grid_size: [2, 1], inputs: [conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.0.conv_3x3.convolution.weight], grid_transpose: true,
         t: 7, mblock: [1, 3], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 42, hstack: 3, vstack: 14],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 5], grid_size: [1, 3], inputs: [lc.input_tensor.conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_44.dc.matmul.8_0, lc.input_tensor.conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [6, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 3}], input_1_tms: [vstack: 14], input_0_tms: [broadcast: {c: 3}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 4, num_index_tiles: 1, num_sparse_tiles: 26, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 98}}
    conv2d_60.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [1, 0], grid_size: [2, 1], inputs: [conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.0.conv_3x3.convolution.weight_fork_clone1327], grid_transpose: true,
         t: 7, mblock: [1, 3], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 42, hstack: 3, vstack: 14],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_2: {type: fused_op, grid_loc: [1, 2], grid_size: [1, 1], inputs: [conv2d_60.dc.conv2d.1.dc.depthwise.10, conv2d_60.dc.conv2d.3.dc.depthwise.10, e2e_conv2d_60.dc.conv2d.5.dc.depthwise.10_0, input_1_add_61, input_1_add_61_fork_clone1033],
         t: 7, mblock: [7, 3], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 48, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [broadcast: {r: 98}, vslice: 7], input_3_tms: [broadcast: {r: 98}, vslice: 7], input_2_tms: [vslice: 7],
         attributes: {fused_op_id: 2}}
    conv2d_74.dc.matmul.8: {type: matmul, grid_loc: [1, 3], grid_size: [1, 1], inputs: [_fused_op_2, mobilenet_v2.layer.0.reduce_1x1.convolution.weight, input_1_add_75_fork_clone987],
         t: 7, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 98}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_87.dc.matmul.8: {type: matmul, grid_loc: [2, 0], grid_size: [1, 5], inputs: [conv2d_74.dc.matmul.8, mobilenet_v2.layer.1.expand_1x1.convolution.weight, input_1_add_88_fork_clone1089],
         t: 7, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 98}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 2, input_1: 7}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 0], grid_size: [1, 5], inputs: [lc.input_tensor.conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_87.dc.matmul.8, lc.input_tensor.conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [6, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 5}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 5}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 15, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 14}}
    conv2d_103.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [1, 5], grid_size: [7, 1], inputs: [conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.1.conv_3x3.convolution.weight_fork_clone1363],
         t: 7, mblock: [2, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 42, hstack: 3, vstack: 14],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [1, 5], inputs: [lc.input_tensor.conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_87.dc.matmul.8, lc.input_tensor.conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [6, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 5}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 5}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 15, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 14}}
    conv2d_103.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [1, 6], grid_size: [7, 1], inputs: [conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.1.conv_3x3.convolution.weight],
         t: 7, mblock: [2, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 42, hstack: 3, vstack: 14],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 0], grid_size: [1, 5], inputs: [lc.input_tensor.conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_87.dc.matmul.8, lc.input_tensor.conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [6, 1], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 5}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 5}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 14, num_index_tiles: 1, num_sparse_tiles: 12, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 7}}
    conv2d_103.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [1, 7], grid_size: [7, 1], inputs: [conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.1.conv_3x3.convolution.weight_fork_clone1361],
         t: 7, mblock: [2, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 42, hstack: 3, vstack: 14],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_3: {type: fused_op, grid_loc: [6, 0], grid_size: [1, 1], inputs: [conv2d_103.dc.conv2d.1.dc.depthwise.10, conv2d_103.dc.conv2d.3.dc.depthwise.10, conv2d_103.dc.conv2d.5.dc.depthwise.10, input_1_add_104, input_1_add_104_fork_clone1039],
         t: 7, mblock: [7, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [broadcast: {r: 98}, vslice: 7], input_3_tms: [broadcast: {r: 98}, vslice: 7],
         attributes: {fused_op_id: 3}}
    conv2d_117.dc.matmul.8: {type: matmul, grid_loc: [6, 1], grid_size: [1, 1], inputs: [_fused_op_3, mobilenet_v2.layer.1.reduce_1x1.convolution.weight, input_1_add_118_fork_clone992],
         t: 7, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 98}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 5}}
    buffer_0_conv2d_74.dc.matmul.8_add_130: {type: nop, grid_loc: [1, 4], grid_size: [1, 1], inputs: [conv2d_74.dc.matmul.8],
         t: 7, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [410], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_130: {type: add, grid_loc: [6, 2], grid_size: [1, 1], inputs: [buffer_0_conv2d_74.dc.matmul.8_add_130, conv2d_117.dc.matmul.8],
         t: 7, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}
    conv2d_131.dc.matmul.8: {type: matmul, grid_loc: [7, 0], grid_size: [1, 5], inputs: [add_130, mobilenet_v2.layer.2.expand_1x1.convolution.weight, input_1_add_132_fork_clone937],
         t: 7, mblock: [7, 1], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 98}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 2, input_1: 7}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}

  fwd_0_2_temporal_epoch_2:
    target_device: 0
    input_count: 64
    conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_131.dc.matmul.8_0, lc.input_tensor.conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [25, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 7],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 25, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 14}}
    conv2d_147.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [0, 1], grid_size: [1, 1], inputs: [conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.2.conv_3x3.convolution.weight_fork_clone1397],
         t: 1, mblock: [25, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 2], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_131.dc.matmul.8_0, lc.input_tensor.conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 1, mblock: [25, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 7],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 26, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 14}}
    conv2d_147.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [0, 5], grid_size: [1, 1], inputs: [conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.2.conv_3x3.convolution.weight],
         t: 1, mblock: [25, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 6], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_131.dc.matmul.8_0, lc.input_tensor.conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [25, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 7],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 24, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 14}}
    conv2d_147.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [0, 7], grid_size: [1, 1], inputs: [conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.2.conv_3x3.convolution.weight_fork_clone1395],
         t: 1, mblock: [25, 1], ublock: [1, 5], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_4: {type: fused_op, grid_loc: [1, 1], grid_size: [1, 1], inputs: [conv2d_147.dc.conv2d.1.dc.depthwise.10, conv2d_147.dc.conv2d.3.dc.depthwise.10, conv2d_147.dc.conv2d.5.dc.depthwise.10, input_1_add_148, input_1_add_148_fork_clone862],
         t: 1, mblock: [25, 5], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 49, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 4}}
    conv2d_161.dc.matmul.8: {type: matmul, grid_loc: [1, 2], grid_size: [1, 1], inputs: [_fused_op_4, mobilenet_v2.layer.2.reduce_1x1.convolution.weight, input_1_add_162_fork_clone800],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 25}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 5}}
    conv2d_174.dc.matmul.8: {type: matmul, grid_loc: [1, 3], grid_size: [1, 2], inputs: [conv2d_161.dc.matmul.8, mobilenet_v2.layer.3.expand_1x1.convolution.weight, input_1_add_175_fork_clone943],
         t: 1, mblock: [25, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 25}],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 7], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_174.dc.matmul.8, lc.input_tensor.conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 12, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_190.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [2, 1], grid_size: [1, 1], inputs: [conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.3.conv_3x3.convolution.weight_fork_clone1431],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 2], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_174.dc.matmul.8, lc.input_tensor.conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 12, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_190.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [2, 5], grid_size: [1, 1], inputs: [conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.3.conv_3x3.convolution.weight],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 0], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_174.dc.matmul.8, lc.input_tensor.conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_190.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [3, 3], grid_size: [1, 1], inputs: [conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.3.conv_3x3.convolution.weight_fork_clone1429],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_5: {type: fused_op, grid_loc: [3, 4], grid_size: [1, 1], inputs: [conv2d_190.dc.conv2d.1.dc.depthwise.10, conv2d_190.dc.conv2d.3.dc.depthwise.10, conv2d_190.dc.conv2d.5.dc.depthwise.10, input_1_add_191, input_1_add_191_fork_clone868],
         t: 1, mblock: [25, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 24, 24], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 5}}
    conv2d_204.dc.matmul.8: {type: matmul, grid_loc: [3, 5], grid_size: [1, 1], inputs: [_fused_op_5, mobilenet_v2.layer.3.reduce_1x1.convolution.weight, input_1_add_205_fork_clone805],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 25}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 6}}
    buffer_0_conv2d_161.dc.matmul.8_add_217: {type: nop, grid_loc: [1, 5], grid_size: [1, 1], inputs: [conv2d_161.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [389], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_217: {type: add, grid_loc: [3, 6], grid_size: [1, 1], inputs: [buffer_0_conv2d_161.dc.matmul.8_add_217, conv2d_204.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}
    conv2d_218.dc.matmul.8: {type: matmul, grid_loc: [4, 0], grid_size: [1, 2], inputs: [add_217, mobilenet_v2.layer.4.expand_1x1.convolution.weight, input_1_add_219_fork_clone930],
         t: 1, mblock: [25, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 25}],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    buffer_1_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [4, 3], grid_size: [1, 1], inputs: [conv2d_218.dc.matmul.8],
         t: 1, mblock: [25, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [5, 6], grid_size: [1, 1], inputs: [buffer_1_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2],
         t: 1, mblock: [25, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 7], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 12, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_234.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [6, 0], grid_size: [1, 1], inputs: [conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.4.conv_3x3.convolution.weight_fork_clone1465],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    buffer_1_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [4, 4], grid_size: [1, 1], inputs: [conv2d_218.dc.matmul.8],
         t: 1, mblock: [25, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    buffer_0_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [5, 1], grid_size: [1, 1], inputs: [buffer_1_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2],
         t: 1, mblock: [25, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 2], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_218.dc.matmul.8_conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 12, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_234.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [5, 5], grid_size: [1, 1], inputs: [conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.4.conv_3x3.convolution.weight],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 5], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_218.dc.matmul.8, lc.input_tensor.conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 5}}
    conv2d_234.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [5, 0], grid_size: [1, 1], inputs: [conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.4.conv_3x3.convolution.weight_fork_clone1463],
         t: 1, mblock: [25, 1], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_6: {type: fused_op, grid_loc: [6, 1], grid_size: [1, 1], inputs: [conv2d_234.dc.conv2d.1.dc.depthwise.10, conv2d_234.dc.conv2d.3.dc.depthwise.10, conv2d_234.dc.conv2d.5.dc.depthwise.10, input_1_add_235, input_1_add_235_fork_clone856],
         t: 1, mblock: [25, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 24, 24], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 5}}
    conv2d_248.dc.matmul.8: {type: matmul, grid_loc: [6, 2], grid_size: [1, 1], inputs: [_fused_op_6, mobilenet_v2.layer.4.reduce_1x1.convolution.weight, input_1_add_249_fork_clone791],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 25}],
         attributes: {bias: true, kernel_broadcast: {input_2: 1}, m_k: 1, min_buffer_input: 0, u_kt: 6}}
    buffer_0_add_217_add_261: {type: nop, grid_loc: [4, 2], grid_size: [1, 1], inputs: [add_217],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [389], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_261: {type: add, grid_loc: [6, 3], grid_size: [1, 1], inputs: [buffer_0_add_217_add_261, conv2d_248.dc.matmul.8],
         t: 1, mblock: [25, 1], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}
    conv2d_262.dc.matmul.8: {type: matmul, grid_loc: [6, 4], grid_size: [1, 2], inputs: [add_261, mobilenet_v2.layer.5.expand_1x1.convolution.weight, input_1_add_263_fork_clone726],
         t: 1, mblock: [25, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 25}],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [7, 0], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_262.dc.matmul.8, lc.input_tensor.conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 29, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 5}}
    conv2d_278.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [6, 6], grid_size: [1, 1], inputs: [conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.5.conv_3x3.convolution.weight_fork_clone1499],
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [7, 3], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_262.dc.matmul.8, lc.input_tensor.conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1], grid_transpose: true,
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 31, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 5}}
    conv2d_278.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [7, 6], grid_size: [1, 1], inputs: [conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.5.conv_3x3.convolution.weight],
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}

  fwd_0_3_temporal_epoch_3:
    target_device: 0
    input_count: 64
    conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [3, 1], inputs: [lc.input_tensor.conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_262.dc.matmul.8_0, lc.input_tensor.conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 30, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 5, num_index_tiles: 1, num_sparse_tiles: 32, sparse_tile_ptr_bits: 8, sparse_ublock_idx_bits: 8, u_kt: 5}}
    conv2d_278.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [0, 1], grid_size: [1, 1], inputs: [conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.5.conv_3x3.convolution.weight_fork_clone1497],
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_7: {type: fused_op, grid_loc: [0, 2], grid_size: [1, 1], inputs: [e2e_conv2d_278.dc.conv2d.1.dc.depthwise.10_0, conv2d_278.dc.conv2d.3.dc.depthwise.10, e2e_conv2d_278.dc.conv2d.5.dc.depthwise.10_0, input_1_add_279, input_1_add_279_fork_clone630],
         t: 1, mblock: [7, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [24, 0, 24, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 7}}
    conv2d_292.dc.matmul.8: {type: matmul, grid_loc: [0, 3], grid_size: [1, 1], inputs: [_fused_op_7, mobilenet_v2.layer.5.reduce_1x1.convolution.weight, input_1_add_293_fork_clone549],
         t: 1, mblock: [7, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, m_k: 1, min_buffer_input: 0, u_kt: 6}}
    conv2d_305.dc.matmul.8: {type: matmul, grid_loc: [0, 4], grid_size: [1, 2], inputs: [conv2d_292.dc.matmul.8, mobilenet_v2.layer.6.expand_1x1.convolution.weight, input_1_add_306_fork_clone732],
         t: 1, mblock: [7, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}],
         attributes: {bias: true, kernel_broadcast: {input_2: 6}, m_k: 2, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 3], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_305.dc.matmul.8, lc.input_tensor.conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_321.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [1, 4], grid_size: [1, 1], inputs: [conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.6.conv_3x3.convolution.weight_fork_clone1533],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 6], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_305.dc.matmul.8, lc.input_tensor.conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_321.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [0, 7], grid_size: [1, 1], inputs: [conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.6.conv_3x3.convolution.weight],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 1], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_305.dc.matmul.8, lc.input_tensor.conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 19, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_321.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [1, 2], grid_size: [1, 1], inputs: [conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.6.conv_3x3.convolution.weight_fork_clone1531],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_8: {type: fused_op, grid_loc: [1, 5], grid_size: [1, 1], inputs: [conv2d_321.dc.conv2d.1.dc.depthwise.10, conv2d_321.dc.conv2d.3.dc.depthwise.10, conv2d_321.dc.conv2d.5.dc.depthwise.10, input_1_add_322, input_1_add_322_fork_clone636],
         t: 7, mblock: [1, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [vslice: 7], input_3_tms: [vslice: 7],
         attributes: {fused_op_id: 8}}
    conv2d_335.dc.matmul.8: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [_fused_op_8, mobilenet_v2.layer.6.reduce_1x1.convolution.weight, input_1_add_336_fork_clone554],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 4}}
    add_348: {type: add, grid_loc: [1, 7], grid_size: [1, 1], inputs: [conv2d_292.dc.matmul.8, conv2d_335.dc.matmul.8],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 7]}
    conv2d_349.dc.matmul.8: {type: matmul, grid_loc: [2, 1], grid_size: [1, 2], inputs: [add_348, mobilenet_v2.layer.7.expand_1x1.convolution.weight, input_1_add_350_fork_clone716],
         t: 7, mblock: [1, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 6}, m_k: 2, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    buffer_0_conv2d_349.dc.matmul.8_conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [2, 4], grid_size: [1, 1], inputs: [conv2d_349.dc.matmul.8],
         t: 1, mblock: [7, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 7]}
    conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 3], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_349.dc.matmul.8_conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_365.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [3, 4], grid_size: [1, 1], inputs: [conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.7.conv_3x3.convolution.weight_fork_clone1567],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    buffer_0_conv2d_349.dc.matmul.8_conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [2, 5], grid_size: [1, 1], inputs: [conv2d_349.dc.matmul.8],
         t: 1, mblock: [7, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 7]}
    conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_349.dc.matmul.8_conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_365.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [2, 7], grid_size: [1, 1], inputs: [conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.7.conv_3x3.convolution.weight],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 0], grid_size: [1, 2], inputs: [lc.input_tensor.conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_349.dc.matmul.8, lc.input_tensor.conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [3, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 2}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 2}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 19, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_365.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [3, 2], grid_size: [1, 1], inputs: [conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.7.conv_3x3.convolution.weight_fork_clone1565],
         t: 1, mblock: [1, 12], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_9: {type: fused_op, grid_loc: [3, 5], grid_size: [1, 1], inputs: [conv2d_365.dc.conv2d.1.dc.depthwise.10, conv2d_365.dc.conv2d.3.dc.depthwise.10, conv2d_365.dc.conv2d.5.dc.depthwise.10, input_1_add_366, input_1_add_366_fork_clone617],
         t: 7, mblock: [1, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [vslice: 7], input_3_tms: [vslice: 7], input_1_tms: [vslice: 7],
         attributes: {fused_op_id: 8}}
    conv2d_379.dc.matmul.8: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [_fused_op_9, mobilenet_v2.layer.7.reduce_1x1.convolution.weight, input_1_add_380_fork_clone536],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 4}}
    buffer_0_add_348_add_392: {type: nop, grid_loc: [2, 3], grid_size: [1, 1], inputs: [add_348],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [434], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_392: {type: add, grid_loc: [3, 7], grid_size: [1, 1], inputs: [buffer_0_add_348_add_392, conv2d_379.dc.matmul.8],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}
    conv2d_393.dc.matmul.8: {type: matmul, grid_loc: [4, 0], grid_size: [1, 2], inputs: [add_392, mobilenet_v2.layer.8.expand_1x1.convolution.weight, input_1_add_394_fork_clone702],
         t: 7, mblock: [1, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 6}, m_k: 2, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    buffer_0_conv2d_393.dc.matmul.8_conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [4, 3], grid_size: [1, 1], inputs: [conv2d_393.dc.matmul.8],
         t: 1, mblock: [7, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 7]}
    conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 2], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_393.dc.matmul.8_conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_409.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [5, 3], grid_size: [1, 1], inputs: [conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.8.conv_3x3.convolution.weight_fork_clone1601],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    buffer_0_conv2d_393.dc.matmul.8_conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [4, 4], grid_size: [1, 1], inputs: [conv2d_393.dc.matmul.8],
         t: 1, mblock: [7, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 7]}
    conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 0], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_393.dc.matmul.8_conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_409.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [5, 1], grid_size: [1, 1], inputs: [conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.8.conv_3x3.convolution.weight],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 5], grid_size: [1, 2], inputs: [lc.input_tensor.conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_393.dc.matmul.8, lc.input_tensor.conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [3, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 2}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 2}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 19, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_409.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [4, 7], grid_size: [1, 1], inputs: [conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.8.conv_3x3.convolution.weight_fork_clone1599],
         t: 1, mblock: [1, 12], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_10: {type: fused_op, grid_loc: [5, 4], grid_size: [1, 1], inputs: [conv2d_409.dc.conv2d.1.dc.depthwise.10, conv2d_409.dc.conv2d.3.dc.depthwise.10, conv2d_409.dc.conv2d.5.dc.depthwise.10, input_1_add_410, input_1_add_410_fork_clone603],
         t: 7, mblock: [1, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [vslice: 7], input_3_tms: [vslice: 7], input_1_tms: [vslice: 7],
         attributes: {fused_op_id: 8}}
    conv2d_423.dc.matmul.8: {type: matmul, grid_loc: [5, 5], grid_size: [1, 1], inputs: [_fused_op_10, mobilenet_v2.layer.8.reduce_1x1.convolution.weight, input_1_add_424_fork_clone521],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 2}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 4}}
    buffer_0_add_392_add_436: {type: nop, grid_loc: [4, 2], grid_size: [1, 1], inputs: [add_392],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [434], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_436: {type: add, grid_loc: [5, 6], grid_size: [1, 1], inputs: [buffer_0_add_392_add_436, conv2d_423.dc.matmul.8],
         t: 7, mblock: [1, 1], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}
    conv2d_437.dc.matmul.8: {type: matmul, grid_loc: [6, 0], grid_size: [1, 2], inputs: [add_436, mobilenet_v2.layer.9.expand_1x1.convolution.weight, input_1_add_438_fork_clone463],
         t: 7, mblock: [1, 3], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 6}, m_k: 2, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    buffer_0_conv2d_437.dc.matmul.8_conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [5, 7], grid_size: [1, 1], inputs: [conv2d_437.dc.matmul.8],
         t: 1, mblock: [7, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 7]}
    conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [6, 6], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_437.dc.matmul.8_conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_453.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [6, 7], grid_size: [1, 1], inputs: [conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.9.conv_3x3.convolution.weight_fork_clone1635],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    buffer_0_conv2d_437.dc.matmul.8_conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: nop, grid_loc: [6, 2], grid_size: [1, 1], inputs: [conv2d_437.dc.matmul.8],
         t: 1, mblock: [7, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0], ublock_order: r, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3,
         input_0_tms: [vstack: 7]}
    conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [7, 0], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, buffer_0_conv2d_437.dc.matmul.8_conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, lc.input_tensor.conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_453.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [7, 1], grid_size: [1, 1], inputs: [conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.9.conv_3x3.convolution.weight],
         t: 7, mblock: [1, 2], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [6, 3], grid_size: [1, 2], inputs: [lc.input_tensor.conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_437.dc.matmul.8, lc.input_tensor.conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [3, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 2}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 2}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 19, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_453.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [6, 5], grid_size: [1, 1], inputs: [conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.9.conv_3x3.convolution.weight_fork_clone1633],
         t: 1, mblock: [1, 12], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_11: {type: fused_op, grid_loc: [7, 2], grid_size: [1, 1], inputs: [conv2d_453.dc.conv2d.1.dc.depthwise.10, conv2d_453.dc.conv2d.3.dc.depthwise.10, conv2d_453.dc.conv2d.5.dc.depthwise.10, input_1_add_454, input_1_add_454_fork_clone388],
         t: 7, mblock: [1, 3], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [vslice: 7], input_3_tms: [vslice: 7], input_1_tms: [vslice: 7],
         attributes: {fused_op_id: 8}}
    conv2d_467.dc.matmul.8: {type: matmul, grid_loc: [7, 3], grid_size: [1, 1], inputs: [_fused_op_11, mobilenet_v2.layer.9.reduce_1x1.convolution.weight, input_1_add_468_fork_clone326],
         t: 7, mblock: [1, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 4}}
    conv2d_480.dc.matmul.8: {type: matmul, grid_loc: [7, 4], grid_size: [1, 2], inputs: [conv2d_467.dc.matmul.8, mobilenet_v2.layer.10.expand_1x1.convolution.weight, input_1_add_481_fork_clone469],
         t: 7, mblock: [1, 9], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 9}, m_k: 3, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}

  fwd_0_4_temporal_epoch_4:
    target_device: 0
    input_count: 64
    conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 0], grid_size: [3, 3], inputs: [lc.input_tensor.conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_480.dc.matmul.8_0, lc.input_tensor.conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 3}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 3}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 13, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_496.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [7, 0], grid_size: [7, 1], inputs: [conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.10.conv_3x3.convolution.weight_fork_clone1669], grid_transpose: true,
         t: 1, mblock: [1, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [3, 3], inputs: [lc.input_tensor.conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_480.dc.matmul.8_0, lc.input_tensor.conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 3}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 3}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 13, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_496.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [0, 3], grid_size: [7, 1], inputs: [conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.10.conv_3x3.convolution.weight],
         t: 1, mblock: [1, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 4], grid_size: [3, 3], inputs: [lc.input_tensor.conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_480.dc.matmul.8_0, lc.input_tensor.conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [1, 6], ublock: [7, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 48, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 3}], input_1_tms: [vstack: 7], input_0_tms: [broadcast: {c: 3}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_496.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [0, 7], grid_size: [7, 1], inputs: [conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.10.conv_3x3.convolution.weight_fork_clone1667],
         t: 1, mblock: [1, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_12: {type: fused_op, grid_loc: [3, 4], grid_size: [1, 1], inputs: [conv2d_496.dc.conv2d.1.dc.depthwise.10, conv2d_496.dc.conv2d.3.dc.depthwise.10, conv2d_496.dc.conv2d.5.dc.depthwise.10, input_1_add_497, input_1_add_497_fork_clone394],
         t: 1, mblock: [7, 9], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 48, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 12}}
    conv2d_510.dc.matmul.8: {type: matmul, grid_loc: [3, 5], grid_size: [1, 1], inputs: [_fused_op_12, mobilenet_v2.layer.10.reduce_1x1.convolution.weight, input_1_add_511_fork_clone331],
         t: 1, mblock: [7, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    add_523: {type: add, grid_loc: [3, 6], grid_size: [1, 1], inputs: [e2e_conv2d_467.dc.matmul.8_0, conv2d_510.dc.matmul.8],
         t: 1, mblock: [7, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [49, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vstack: 7]}

  fwd_0_5_temporal_epoch_5:
    target_device: 0
    input_count: 64
    conv2d_524.dc.matmul.8: {type: matmul, grid_loc: [0, 0], grid_size: [7, 6], inputs: [e2e_add_523_0, mobilenet_v2.layer.11.expand_1x1.convolution.weight, input_1_add_525_fork_clone456],
         t: 1, mblock: [1, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 3}}

  fwd_0_6_temporal_epoch_6:
    target_device: 0
    input_count: 64
    conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 0], grid_size: [1, 2], inputs: [lc.input_tensor.conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_524.dc.matmul.8_0, lc.input_tensor.conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 3], ublock: [1, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 2}], input_0_tms: [broadcast: {c: 2}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_540.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [1, 2], grid_size: [1, 1], inputs: [conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.11.conv_3x3.convolution.weight_fork_clone1703],
         t: 7, mblock: [1, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 0], grid_size: [1, 2], inputs: [lc.input_tensor.conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_524.dc.matmul.8_0, lc.input_tensor.conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 3], ublock: [1, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 2}], input_0_tms: [broadcast: {c: 2}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 28, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_540.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [0, 2], grid_size: [1, 1], inputs: [conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.11.conv_3x3.convolution.weight],
         t: 7, mblock: [1, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [0, 3], grid_size: [1, 2], inputs: [lc.input_tensor.conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, e2e_conv2d_524.dc.matmul.8_0, lc.input_tensor.conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 7, mblock: [3, 3], ublock: [1, 3], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 49, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {c: 2}], input_0_tms: [broadcast: {c: 2}],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, m_k: 1, num_index_tiles: 1, num_sparse_tiles: 19, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 7}}
    conv2d_540.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [0, 5], grid_size: [1, 1], inputs: [conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.11.conv_3x3.convolution.weight_fork_clone1701],
         t: 7, mblock: [1, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [broadcast: {c: 7}, hslice: 7], input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_13: {type: fused_op, grid_loc: [0, 6], grid_size: [1, 1], inputs: [conv2d_540.dc.conv2d.1.dc.depthwise.10, conv2d_540.dc.conv2d.3.dc.depthwise.10, conv2d_540.dc.conv2d.5.dc.depthwise.10, input_1_add_541, input_1_add_541_fork_clone382],
         t: 7, mblock: [1, 9], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_4_tms: [vslice: 7], input_3_tms: [vslice: 7],
         attributes: {fused_op_id: 13}}
    conv2d_554.dc.matmul.8: {type: matmul, grid_loc: [0, 7], grid_size: [1, 1], inputs: [_fused_op_13, mobilenet_v2.layer.11.reduce_1x1.convolution.weight, input_1_add_555_fork_clone317],
         t: 7, mblock: [1, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    add_567: {type: add, grid_loc: [1, 3], grid_size: [1, 1], inputs: [e2e_add_523_0, conv2d_554.dc.matmul.8],
         t: 7, mblock: [1, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [49, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 7]}
    conv2d_568.dc.matmul.8: {type: matmul, grid_loc: [2, 0], grid_size: [1, 6], inputs: [add_567, mobilenet_v2.layer.12.expand_1x1.convolution.weight, input_1_add_569_fork_clone260],
         t: 7, mblock: [1, 3], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 7}, vslice: 7], input_1_tms: [broadcast: {c: 7}, hslice: 7],
         attributes: {bias: true, kernel_broadcast: {input_2: 3}, m_k: 3, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 1}}
    conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 4], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_568.dc.matmul.8, lc.input_tensor.conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 7],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 22, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_584.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [1, 5], grid_size: [1, 1], inputs: [conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.12.conv_3x3.convolution.weight_fork_clone1737],
         t: 1, mblock: [2, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [1, 6], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_568.dc.matmul.8, lc.input_tensor.conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 7],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 22, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_584.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [1, 7], grid_size: [1, 1], inputs: [conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.12.conv_3x3.convolution.weight],
         t: 1, mblock: [2, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [2, 6], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_568.dc.matmul.8, lc.input_tensor.conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 7],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 7, num_index_tiles: 1, num_sparse_tiles: 25, sparse_tile_ptr_bits: 6, sparse_ublock_idx_bits: 6, u_kt: 1}}
    conv2d_584.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [2, 7], grid_size: [1, 1], inputs: [conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.12.conv_3x3.convolution.weight_fork_clone1735],
         t: 1, mblock: [2, 3], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_14: {type: fused_op, grid_loc: [3, 0], grid_size: [1, 1], inputs: [conv2d_584.dc.conv2d.1.dc.depthwise.10, conv2d_584.dc.conv2d.3.dc.depthwise.10, conv2d_584.dc.conv2d.5.dc.depthwise.10, input_1_add_585, input_1_add_585_fork_clone185],
         t: 1, mblock: [1, 9], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 14}}
    conv2d_598.dc.matmul.8: {type: matmul, grid_loc: [3, 1], grid_size: [1, 1], inputs: [_fused_op_14, mobilenet_v2.layer.12.reduce_1x1.convolution.weight, input_1_add_599_fork_clone125],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}],
         attributes: {bias: true, kernel_broadcast: {input_2: 10}, l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 6}}
    conv2d_611.dc.matmul.8: {type: matmul, grid_loc: [3, 2], grid_size: [1, 3], inputs: [conv2d_598.dc.matmul.8, mobilenet_v2.layer.13.expand_1x1.convolution.weight, input_1_add_612_fork_clone266],
         t: 2, mblock: [1, 5], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 10}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 5}}
    conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [3, 6], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_611.dc.matmul.8, lc.input_tensor.conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_627.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [3, 7], grid_size: [1, 1], inputs: [conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.13.conv_3x3.convolution.weight_fork_clone1771],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 0], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_611.dc.matmul.8, lc.input_tensor.conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_627.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [4, 1], grid_size: [1, 1], inputs: [conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.13.conv_3x3.convolution.weight],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [4, 2], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_611.dc.matmul.8, lc.input_tensor.conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_627.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [4, 3], grid_size: [1, 1], inputs: [conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.13.conv_3x3.convolution.weight_fork_clone1769],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_15: {type: fused_op, grid_loc: [4, 4], grid_size: [1, 1], inputs: [conv2d_627.dc.conv2d.1.dc.depthwise.10, conv2d_627.dc.conv2d.3.dc.depthwise.10, conv2d_627.dc.conv2d.5.dc.depthwise.10, input_1_add_628, input_1_add_628_fork_clone191],
         t: 1, mblock: [1, 15], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 15}}
    conv2d_641.dc.matmul.8: {type: matmul, grid_loc: [4, 5], grid_size: [1, 1], inputs: [_fused_op_15, mobilenet_v2.layer.13.reduce_1x1.convolution.weight, input_1_add_642_fork_clone130],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}],
         attributes: {bias: true, kernel_broadcast: {input_2: 10}, l1_acc: true, m_k: 6, min_buffer_input: 0, u_kt: 5}}
    buffer_0_conv2d_598.dc.matmul.8_add_654: {type: nop, grid_loc: [3, 5], grid_size: [1, 1], inputs: [conv2d_598.dc.matmul.8],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [418], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_654: {type: add, grid_loc: [4, 6], grid_size: [1, 1], inputs: [buffer_0_conv2d_598.dc.matmul.8_add_654, conv2d_641.dc.matmul.8],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}
    conv2d_655.dc.matmul.8: {type: matmul, grid_loc: [5, 0], grid_size: [1, 3], inputs: [add_654, mobilenet_v2.layer.14.expand_1x1.convolution.weight, input_1_add_656_fork_clone253],
         t: 2, mblock: [1, 5], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 10}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 5}}
    conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 3], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_655.dc.matmul.8, lc.input_tensor.conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_671.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [5, 4], grid_size: [1, 1], inputs: [conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.14.conv_3x3.convolution.weight_fork_clone1805],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [5, 5], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_655.dc.matmul.8, lc.input_tensor.conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_671.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [5, 6], grid_size: [1, 1], inputs: [conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.14.conv_3x3.convolution.weight],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [6, 0], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_655.dc.matmul.8, lc.input_tensor.conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_671.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [6, 1], grid_size: [1, 1], inputs: [conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.14.conv_3x3.convolution.weight_fork_clone1803],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_16: {type: fused_op, grid_loc: [5, 7], grid_size: [1, 1], inputs: [conv2d_671.dc.conv2d.1.dc.depthwise.10, conv2d_671.dc.conv2d.3.dc.depthwise.10, conv2d_671.dc.conv2d.5.dc.depthwise.10, input_1_add_672, input_1_add_672_fork_clone179],
         t: 1, mblock: [1, 15], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 15}}
    conv2d_685.dc.matmul.8: {type: matmul, grid_loc: [6, 2], grid_size: [1, 1], inputs: [_fused_op_16, mobilenet_v2.layer.14.reduce_1x1.convolution.weight, input_1_add_686_fork_clone119],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}],
         attributes: {bias: true, kernel_broadcast: {input_2: 10}, l1_acc: true, m_k: 6, min_buffer_input: 0, u_kt: 5}}
    buffer_0_add_654_add_698: {type: nop, grid_loc: [4, 7], grid_size: [1, 1], inputs: [add_654],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_buf_min_size_tiles: [418], input_dram_io_buf_size_tiles: [0], ublock_order: c, in_df: [Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi3}
    add_698: {type: add, grid_loc: [6, 3], grid_size: [1, 1], inputs: [buffer_0_add_654_add_698, conv2d_685.dc.matmul.8],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: c, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}
    conv2d_699.dc.matmul.8: {type: matmul, grid_loc: [6, 4], grid_size: [1, 3], inputs: [add_698, mobilenet_v2.layer.15.expand_1x1.convolution.weight, input_1_add_700_fork_clone85],
         t: 2, mblock: [1, 5], ublock: [1, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}, vslice: 2], input_1_tms: [broadcast: {c: 2}, hslice: 2], input_0_tms: [vslice: 2],
         attributes: {bias: true, kernel_broadcast: {input_2: 10}, m_k: 1, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 5}}
    conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [7, 0], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_699.dc.matmul.8, lc.input_tensor.conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_715.dc.conv2d.5.dc.depthwise.10: {type: depthwise, grid_loc: [7, 1], grid_size: [1, 1], inputs: [conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.15.conv_3x3.convolution.weight_fork_clone1839],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [7, 2], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_699.dc.matmul.8, lc.input_tensor.conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 10, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_715.dc.conv2d.1.dc.depthwise.10: {type: depthwise, grid_loc: [7, 3], grid_size: [1, 1], inputs: [conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.15.conv_3x3.convolution.weight],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2: {type: matmul, grid_loc: [7, 4], grid_size: [1, 1], inputs: [lc.input_tensor.conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0, conv2d_699.dc.matmul.8, lc.input_tensor.conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1],
         t: 1, mblock: [6, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Bfp2_b, Float16_b, RawUInt32], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [vstack: 2],
         attributes: {act_t: 1, fracture_factor: 1, identity: true, l1_acc: true, m_k: 2, num_index_tiles: 1, num_sparse_tiles: 9, sparse_tile_ptr_bits: 5, sparse_ublock_idx_bits: 5, u_kt: 1}}
    conv2d_715.dc.conv2d.3.dc.depthwise.10: {type: depthwise, grid_loc: [7, 5], grid_size: [1, 1], inputs: [conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.lc2, mobilenet_v2.layer.15.conv_3x3.convolution.weight_fork_clone1837],
         t: 1, mblock: [2, 5], ublock: [1, 6], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [vslice: 3, hstack: 3],
         attributes: {l1_acc: true, m_k: 3, min_buffer_input: 0, u_kt: 1}}
    _fused_op_17: {type: fused_op, grid_loc: [6, 7], grid_size: [1, 1], inputs: [conv2d_715.dc.conv2d.1.dc.depthwise.10, conv2d_715.dc.conv2d.3.dc.depthwise.10, conv2d_715.dc.conv2d.5.dc.depthwise.10, input_1_add_716, input_1_add_716_fork_clone60],
         t: 1, mblock: [1, 15], ublock: [2, 2], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0, 0, 0], ublock_order: c, in_df: [Float16_b, Float16_b, Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         attributes: {fused_op_id: 15}}
    conv2d_729.dc.matmul.8: {type: matmul, grid_loc: [7, 6], grid_size: [1, 2], inputs: [_fused_op_17, mobilenet_v2.layer.15.reduce_1x1.convolution.weight, input_1_add_730_fork_clone37],
         t: 1, mblock: [1, 5], ublock: [2, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}],
         attributes: {bias: true, kernel_broadcast: {input_2: 10}, l1_acc: true, m_k: 6, min_buffer_input: 0, u_kt: 5}}

  fwd_0_7_temporal_epoch_7:
    target_device: 0
    input_count: 64
    conv2d_742.dc.matmul.8: {type: matmul, grid_loc: [0, 0], grid_size: [2, 8], inputs: [e2e_conv2d_729.dc.matmul.8_0, mobilenet_v2.conv_1x1.convolution.weight, input_1_add_743_fork_clone20],
         t: 1, mblock: [1, 5], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [48, 0, 0], ublock_order: r, in_df: [Float16_b, Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_2_tms: [broadcast: {r: 2}],
         attributes: {bias: true, kernel_broadcast: {input_2: 5}, m_k: 5, min_buffer_input: 0, relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00, u_kt: 2}}
    avg_pool2d_756.dc.reduce_avg.2.lc1: {type: matmul, grid_loc: [2, 0], grid_size: [1, 4], inputs: [lc.input_tensor.avg_pool2d_756.dc.reduce_avg.2.0, conv2d_742.dc.matmul.8],
         t: 2, mblock: [1, 5], ublock: [1, 1], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_1_tms: [hslice: 2], input_0_tms: [broadcast: {r: 2}, vslice: 2],
         attributes: {l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 1}}
    matmul_760: {type: matmul, grid_loc: [3, 0], grid_size: [1, 8], inputs: [avg_pool2d_756.dc.reduce_avg.2.lc1, classifier.weight],
         t: 1, mblock: [1, 1], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2,
         input_0_tms: [hstack: 2],
         attributes: {l1_acc: true, m_k: 2, min_buffer_input: 0, u_kt: 20}}
    add_761: {type: add, grid_loc: [2, 4], grid_size: [1, 1], inputs: [matmul_760, classifier.bias], untilize_output: true,
         t: 1, mblock: [1, 8], ublock: [1, 4], tile_dim: [32, 32], buf_size_mb: 2, input_dram_io_buf_size_tiles: [0, 0], ublock_order: r, in_df: [Float16_b, Float16_b], out_df: Float16_b, intermed_df: Float16_b, acc_df: Float16_b, math_fidelity: HiFi2}


programs:
  - run_fwd_0:
    - param: [$p_loop_count]
    - var: {$gptr_q5_shadow: 0, $gptr_q1: 0, $lptr_q2: 0, $lptr_q1: 0, $c_zero: 0, $c_one: 1, $lptr_q7: 0, $c_microbatch_size: 64, $gptr_q6: 0, $lptr_q6: 0, $lptr_q5: 0, $gptr_q5: 0, $gptr_q2: 0, $gptr_q3: 0, $lptr_q4: 0, $lptr_q3: 0, $gptr_q7: 0, $gptr_q4: 0}
    - staticvar: {$gptr_q0: 0, $lptr_q0: 0}
    - loop: $p_loop_count
    -   varinst: [$gptr_q5, set, $gptr_q5_shadow]
    -   allocate_queue: [e2e_conv2d_44.dc.matmul.8_0, e2e_conv2d_60.dc.conv2d.5.dc.depthwise.10_0]
    -   execute: {graph_name: fwd_0_0_temporal_epoch_0, queue_settings: {
               features_1: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0},
               lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.1.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.conv_stem.first_conv.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_1.dc.conv2d.3.dc.conv2d.3.dc.sparse_matmul.9.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.conv_stem.first_conv.convolution.weight_fork_clone1876: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_2_fork_clone1167: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_17.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.conv_stem.conv_3x3.convolution.weight_fork_clone1295: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_17.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.conv_stem.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_17.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.conv_stem.conv_3x3.convolution.weight_fork_clone1293: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_18: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_18_fork_clone1142: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.conv_stem.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_32_fork_clone1115: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.0.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_45_fork_clone1083: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_60.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.0.conv_3x3.convolution.weight_fork_clone1329: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q0, incwrap, $c_microbatch_size, 256]
    -   varinst: [$lptr_q0, incwrap, $c_microbatch_size, 256]
    -   allocate_queue: [e2e_conv2d_131.dc.matmul.8_0]
    -   execute: {graph_name: fwd_0_1_temporal_epoch_1, queue_settings: {
               e2e_conv2d_44.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               e2e_conv2d_60.dc.conv2d.5.dc.depthwise.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q1, rd_ptr_global: $gptr_q1},
               lc.input_tensor.conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_60.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.0.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_60.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.0.conv_3x3.convolution.weight_fork_clone1327: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_61: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_61_fork_clone1033: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.0.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_75_fork_clone987: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.1.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_88_fork_clone1089: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_103.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.1.conv_3x3.convolution.weight_fork_clone1363: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_103.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.1.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_103.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.1.conv_3x3.convolution.weight_fork_clone1361: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_104: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_104_fork_clone1039: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.1.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_118_fork_clone992: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.2.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_132_fork_clone937: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_44.dc.matmul.8_0, e2e_conv2d_60.dc.conv2d.5.dc.depthwise.10_0]
    -   varinst: [$gptr_q1, incwrap, $c_microbatch_size, 128]
    -   varinst: [$lptr_q1, incwrap, $c_microbatch_size, 128]
    -   allocate_queue: [e2e_conv2d_262.dc.matmul.8_0, e2e_conv2d_278.dc.conv2d.5.dc.depthwise.10_0, e2e_conv2d_278.dc.conv2d.1.dc.depthwise.10_0]
    -   execute: {graph_name: fwd_0_2_temporal_epoch_2, queue_settings: {
               e2e_conv2d_131.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q2, rd_ptr_global: $gptr_q2},
               lc.input_tensor.conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_147.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.2.conv_3x3.convolution.weight_fork_clone1397: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_147.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.2.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_147.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.2.conv_3x3.convolution.weight_fork_clone1395: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_148: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_148_fork_clone862: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.2.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_162_fork_clone800: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.3.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_175_fork_clone943: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_190.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.3.conv_3x3.convolution.weight_fork_clone1431: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_190.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.3.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_190.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.3.conv_3x3.convolution.weight_fork_clone1429: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_191: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_191_fork_clone868: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.3.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_205_fork_clone805: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.4.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_219_fork_clone930: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_234.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.4.conv_3x3.convolution.weight_fork_clone1465: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_234.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.4.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_234.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.4.conv_3x3.convolution.weight_fork_clone1463: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_235: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_235_fork_clone856: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.4.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_249_fork_clone791: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.5.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_263_fork_clone726: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_278.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.5.conv_3x3.convolution.weight_fork_clone1499: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_278.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.5.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_131.dc.matmul.8_0]
    -   varinst: [$gptr_q2, incwrap, $c_microbatch_size, 128]
    -   varinst: [$lptr_q2, incwrap, $c_microbatch_size, 128]
    -   allocate_queue: [e2e_conv2d_467.dc.matmul.8_0, e2e_conv2d_480.dc.matmul.8_0]
    -   execute: {graph_name: fwd_0_3_temporal_epoch_3, queue_settings: {
               e2e_conv2d_262.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_conv2d_278.dc.conv2d.5.dc.depthwise.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               e2e_conv2d_278.dc.conv2d.1.dc.depthwise.10_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q3, rd_ptr_global: $gptr_q3},
               lc.input_tensor.conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_278.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.5.conv_3x3.convolution.weight_fork_clone1497: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_279: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_279_fork_clone630: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.5.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_293_fork_clone549: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.6.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_306_fork_clone732: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_321.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.6.conv_3x3.convolution.weight_fork_clone1533: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_321.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.6.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_321.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.6.conv_3x3.convolution.weight_fork_clone1531: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_322: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_322_fork_clone636: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.6.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_336_fork_clone554: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.7.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_350_fork_clone716: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_365.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.7.conv_3x3.convolution.weight_fork_clone1567: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_365.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.7.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_365.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.7.conv_3x3.convolution.weight_fork_clone1565: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_366: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_366_fork_clone617: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.7.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_380_fork_clone536: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.8.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_394_fork_clone702: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_409.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.8.conv_3x3.convolution.weight_fork_clone1601: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_409.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.8.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_409.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.8.conv_3x3.convolution.weight_fork_clone1599: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_410: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_410_fork_clone603: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.8.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_424_fork_clone521: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.9.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_438_fork_clone463: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_453.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.9.conv_3x3.convolution.weight_fork_clone1635: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_453.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.9.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_453.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.9.conv_3x3.convolution.weight_fork_clone1633: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_454: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_454_fork_clone388: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.9.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_468_fork_clone326: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.10.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_481_fork_clone469: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_262.dc.matmul.8_0, e2e_conv2d_278.dc.conv2d.5.dc.depthwise.10_0, e2e_conv2d_278.dc.conv2d.1.dc.depthwise.10_0]
    -   varinst: [$gptr_q3, incwrap, $c_microbatch_size, 128]
    -   varinst: [$lptr_q3, incwrap, $c_microbatch_size, 128]
    -   allocate_queue: [e2e_add_523_0]
    -   execute: {graph_name: fwd_0_4_temporal_epoch_4, queue_settings: {
               e2e_conv2d_467.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               e2e_conv2d_480.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q4, rd_ptr_global: $gptr_q4},
               lc.input_tensor.conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_496.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.10.conv_3x3.convolution.weight_fork_clone1669: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_496.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.10.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_496.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.10.conv_3x3.convolution.weight_fork_clone1667: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_497: {prologue: false, epilogue: false, zero: False, rd_ptr_autoinc: 0, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_497_fork_clone394: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.10.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_511_fork_clone331: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_467.dc.matmul.8_0, e2e_conv2d_480.dc.matmul.8_0]
    -   varinst: [$gptr_q4, incwrap, $c_microbatch_size, 128]
    -   varinst: [$lptr_q4, incwrap, $c_microbatch_size, 128]
    -   allocate_queue: [e2e_conv2d_524.dc.matmul.8_0]
    -   execute: {graph_name: fwd_0_5_temporal_epoch_5, queue_settings: {
               e2e_add_523_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q5, rd_ptr_global: $gptr_q5},
               mobilenet_v2.layer.11.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_525_fork_clone456: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   varinst: [$gptr_q5_shadow, incwrap, $c_microbatch_size, 128]
    -   varinst: [$lptr_q5, incwrap, $c_microbatch_size, 128]
    -   allocate_queue: [e2e_conv2d_729.dc.matmul.8_0]
    -   execute: {graph_name: fwd_0_6_temporal_epoch_6, queue_settings: {
               e2e_add_523_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               e2e_conv2d_524.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q6, rd_ptr_global: $gptr_q6},
               lc.input_tensor.conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_540.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.11.conv_3x3.convolution.weight_fork_clone1703: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_540.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.11.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_540.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.11.conv_3x3.convolution.weight_fork_clone1701: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_541: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_541_fork_clone382: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.11.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_555_fork_clone317: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.12.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_569_fork_clone260: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_584.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.12.conv_3x3.convolution.weight_fork_clone1737: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_584.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.12.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_584.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.12.conv_3x3.convolution.weight_fork_clone1735: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_585: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_585_fork_clone185: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.12.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_599_fork_clone125: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.13.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_612_fork_clone266: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_627.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.13.conv_3x3.convolution.weight_fork_clone1771: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_627.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.13.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_627.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.13.conv_3x3.convolution.weight_fork_clone1769: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_628: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_628_fork_clone191: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.13.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_642_fork_clone130: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.14.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_656_fork_clone253: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_671.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.14.conv_3x3.convolution.weight_fork_clone1805: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_671.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.14.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_671.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.14.conv_3x3.convolution.weight_fork_clone1803: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_672: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_672_fork_clone179: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.14.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_686_fork_clone119: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.15.expand_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_700_fork_clone85: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_715.dc.conv2d.5.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.15.conv_3x3.convolution.weight_fork_clone1839: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_715.dc.conv2d.1.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.15.conv_3x3.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               lc.input_tensor.conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.conv2d_715.dc.conv2d.3.dc.sparse_matmul.8.dc.sparse_matmul.1.1: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.15.conv_3x3.convolution.weight_fork_clone1837: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_716: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               input_1_add_716_fork_clone60: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               mobilenet_v2.layer.15.reduce_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_730_fork_clone37: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_add_523_0, e2e_conv2d_524.dc.matmul.8_0]
    -   varinst: [$gptr_q6, incwrap, $c_microbatch_size, 128]
    -   varinst: [$lptr_q6, incwrap, $c_microbatch_size, 128]
    -   execute: {graph_name: fwd_0_7_temporal_epoch_7, queue_settings: {
               e2e_conv2d_729.dc.matmul.8_0: {prologue: false, epilogue: false, zero: False, rd_ptr_local: $lptr_q7, rd_ptr_global: $gptr_q7},
               mobilenet_v2.conv_1x1.convolution.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               input_1_add_743_fork_clone20: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               lc.input_tensor.avg_pool2d_756.dc.reduce_avg.2.0: {prologue: true, epilogue: false, zero: False, rd_ptr_local: $c_zero, rd_ptr_global: $c_zero},
               classifier.weight: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero},
               classifier.bias: {prologue: true, epilogue: false, zero: False, rd_ptr_global: $c_zero, wr_ptr_global: $c_zero}} }
    -   deallocate_queue: [e2e_conv2d_729.dc.matmul.8_0]
    -   varinst: [$gptr_q7, incwrap, $c_microbatch_size, 128]
    -   varinst: [$lptr_q7, incwrap, $c_microbatch_size, 128]
    - endloop


fused_ops:
  0: 
    inputs: 3
    intermediates: 0
    schedules: 
      -
        - conv2d_1.dc.conv2d.3.dc.add.4.0: { type: add, inputs: [input0, input1], mblock: [98, 1], ublock: [2, 1], output: dest}
        - add_13.0: { type: add, inputs: [dest, input2], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [98, 1], ublock: [2, 1], output: output}
  1: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_17.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [7, 1], ublock: [2, 1], output: dest}
        - conv2d_17.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [7, 1], ublock: [2, 1], output: dest}
        - multiply_24.0: { type: multiply, inputs: [dest, input3], mblock: [7, 1], ublock: [2, 1], output: dest}
        - add_29.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [7, 1], ublock: [2, 1], output: output}
  2: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_60.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [7, 3], ublock: [2, 1], output: dest}
        - conv2d_60.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [7, 3], ublock: [2, 1], output: dest}
        - multiply_67.0: { type: multiply, inputs: [dest, input3], mblock: [7, 3], ublock: [2, 1], output: dest}
        - add_72.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [7, 3], ublock: [2, 1], output: output}
  3: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_103.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [7, 5], ublock: [2, 1], output: dest}
        - conv2d_103.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [7, 5], ublock: [2, 1], output: dest}
        - multiply_110.0: { type: multiply, inputs: [dest, input3], mblock: [7, 5], ublock: [2, 1], output: dest}
        - add_115.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [7, 5], ublock: [2, 1], output: output}
  4: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_147.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [25, 5], ublock: [1, 1], output: dest}
        - conv2d_147.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [25, 5], ublock: [1, 1], output: dest}
        - multiply_154.0: { type: multiply, inputs: [dest, input3], mblock: [25, 5], ublock: [1, 1], output: dest}
        - add_159.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [25, 5], ublock: [1, 1], output: output}
  5: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_190.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [25, 3], ublock: [1, 2], output: dest}
        - conv2d_190.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [25, 3], ublock: [1, 2], output: dest}
        - multiply_197.0: { type: multiply, inputs: [dest, input3], mblock: [25, 3], ublock: [1, 2], output: dest}
        - add_202.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [25, 3], ublock: [1, 2], output: output}
  7: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_278.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [7, 3], ublock: [1, 2], output: dest}
        - conv2d_278.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [7, 3], ublock: [1, 2], output: dest}
        - multiply_285.0: { type: multiply, inputs: [dest, input3], mblock: [7, 3], ublock: [1, 2], output: dest}
        - add_290.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [7, 3], ublock: [1, 2], output: output}
  8: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_321.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [1, 3], ublock: [1, 4], output: dest}
        - conv2d_321.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [1, 3], ublock: [1, 4], output: dest}
        - multiply_328.0: { type: multiply, inputs: [dest, input3], mblock: [1, 3], ublock: [1, 4], output: dest}
        - add_333.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [1, 3], ublock: [1, 4], output: output}
  12: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_496.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [7, 9], ublock: [1, 2], output: dest}
        - conv2d_496.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [7, 9], ublock: [1, 2], output: dest}
        - multiply_503.0: { type: multiply, inputs: [dest, input3], mblock: [7, 9], ublock: [1, 2], output: dest}
        - add_508.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [7, 9], ublock: [1, 2], output: output}
  13: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_540.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [1, 9], ublock: [1, 2], output: dest}
        - conv2d_540.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [1, 9], ublock: [1, 2], output: dest}
        - multiply_547.0: { type: multiply, inputs: [dest, input3], mblock: [1, 9], ublock: [1, 2], output: dest}
        - add_552.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [1, 9], ublock: [1, 2], output: output}
  14: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_584.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [1, 9], ublock: [2, 2], output: dest}
        - conv2d_584.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [1, 9], ublock: [2, 2], output: dest}
        - multiply_591.0: { type: multiply, inputs: [dest, input3], mblock: [1, 9], ublock: [2, 2], output: dest}
        - add_596.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [1, 9], ublock: [2, 2], output: output}
  15: 
    inputs: 5
    intermediates: 0
    schedules: 
      -
        - conv2d_627.dc.add.6.0: { type: add, inputs: [input0, input1], mblock: [1, 15], ublock: [2, 2], output: dest}
        - conv2d_627.dc.add.7.0: { type: add, inputs: [input2, dest], mblock: [1, 15], ublock: [2, 2], output: dest}
        - multiply_634.0: { type: multiply, inputs: [dest, input3], mblock: [1, 15], ublock: [2, 2], output: dest}
        - add_639.0: { type: add, inputs: [dest, input4], attributes: {relu_en: true, relu_mode: max, relu_threshold: 6.000000e+00}, mblock: [1, 15], ublock: [2, 2], output: output}

performance-check:
  host:
    backend-samples-per-second:
      expected: 0
      rtol: 0.08
    test-group: "perf_infra_wormhole_b0_silicon_push"
    test-name: "mobilenet_v2_hifi2_fp16b"