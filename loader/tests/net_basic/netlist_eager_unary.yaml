devices:
  arch: [grayskull, wormhole, wormhole_b0]

queues:
  # inputs -- from previous op masquerading as host input
  op1_in: {type: queue, input: net2net_op0_out    , entries: 256, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 2], df: Float16, target_device: 0, loc: dram, dram: [[2, 0x31000000]]}

  # outputs -- final output with various flavours
  op1_dq_tilized: {type: queue, input: format_converter, entries: 256, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 2], df: Float16_b, target_device: 0, loc: dram, dram: [[5, 0x30000000]]}
  op1_dq_untilized: {type: queue, input: untilize_nop1, entries: 256, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 2], df: Float16, target_device: 0, loc: dram, dram: [[0, 0x30000000]]}
  op1_hq_untilized: {type: queue, input: untilize_nop2, entries: 256, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 2], df: Float16, target_device: 0, loc: host, host: [0x0]}

graphs:
  graph_op1:
    target_device: 0
    input_count: 256
    format_converter: {type: nop, grid_loc: [0, 0], grid_size: [1, 1], inputs: [op1_in], in_df: [Float16], acc_df: Float16_b, out_df: Float16_b,  intermed_df: Float16_b, ublock_order: r, buf_size_mb: 2, math_fidelity: HiFi3, untilize_output: false, t: 1, mblock: [2, 2], ublock: [2, 2], attributes: {m_k: 2, u_kt: 2}}
    untilize_nop1: {type: nop, grid_loc: [0, 1], grid_size: [1, 1], inputs: [op1_in], in_df: [Float16], acc_df: Float16, out_df: Float16,  intermed_df: Float16, ublock_order: r, buf_size_mb: 2, math_fidelity: HiFi3, untilize_output: true, t: 1, mblock: [2, 2], ublock: [2, 2], attributes: {m_k: 2, u_kt: 2}}
    untilize_nop2: {type: nop, grid_loc: [0, 2], grid_size: [1, 1], inputs: [op1_in], in_df: [Float16], acc_df: Float16, out_df: Float16,  intermed_df: Float16, ublock_order: r, buf_size_mb: 2, math_fidelity: HiFi3, untilize_output: true, t: 1, mblock: [2, 2], ublock: [2, 2], attributes: {m_k: 2, u_kt: 2}}

programs:
  - op_unary:
    - var: {$p_microbatch_count: 1}
    - var: {$c_microbatch_size: 256, $c_one: 1, $c_zero: 0}
    - staticvar: {$gptr_q0: 0, $lptr_q0: 0}
    - loop: $p_microbatch_count
    -   execute: {graph_name: graph_op1, queue_settings: {
          op1_in: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr_q0, rd_ptr_global: $gptr_q0}}}
    -   varinst: [$lptr_q0, incwrap, $c_microbatch_size, 512]
    -   varinst: [$gptr_q0, incwrap, $c_microbatch_size, 512]
    - endloop

test-config:
  comparison-config:
    type: AllCloseHw
    atol: 0.01
    rtol: 0.15
    check_pct: 0.99
    check_pcc: 0.99
    verbosity: Concise
  stimulus-config:
    type: Normal
    normal_mean: 0.0
    normal_stddev: 0.25
