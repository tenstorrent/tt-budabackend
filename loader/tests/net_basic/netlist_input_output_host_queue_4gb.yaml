# Untilize directly to queue allocated in host memory
# Modified from original test to have output queues in HOST, and cover multiple host channels. And microbatch looping.

devices:
  arch: [grayskull, wormhole, wormhole_b0]

queues:
  in_hq: {type: queue, input: HOST   , entries: 128, grid_size: [3, 2], t: 1, mblock: [1, 1], ublock: [2, 4], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x0], [1, 0x2000000], [2, 0x4000000], [3, 0x6000000], [1, 0x0], [2, 0x0]]}
  e2e_hq: {type: queue, input: unary_hq , entries: 128, grid_size: [3, 2], t: 1, mblock: [1, 1], ublock: [2, 4], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x20000000], [2, 0x20000000], [3, 0x20000000], [1, 0x22000000], [2, 0x22000000], [3, 0x22000000]]}
  copy_from_hq: {type: queue, input: unary_hq2 , entries: 128, grid_size: [1, 1], t: 1, mblock: [3, 2], ublock: [2, 4], df: Float16_b, target_device: 0, loc: host, host: [[3, 0x0]]}

  in_dq: {type: queue, input: HOST   , entries: 128, grid_size: [2, 2], t: 1, mblock: [1, 1], ublock: [2, 4], df: Float16_b, target_device: 0, loc: dram, dram: [[0, 0x30000000], [5, 0x32000000], [0, 0x34000000], [5, 0x36000000]]}
  e2e_dq: {type: queue, input: unary_dq   , entries: 128, grid_size: [2, 2], t: 1, mblock: [1, 1], ublock: [2, 4], df: Float16_b, target_device: 0, loc: dram, dram: [[1, 0x30000000], [2, 0x32000000], [3, 0x34000000], [4, 0x36000000]]}
  copy_from_dq: {type: queue, input: unary_dq2 , entries: 128, grid_size: [1, 1], t: 1, mblock: [2, 2], ublock: [2, 4], df: Float16_b, target_device: 0, loc: host, host: [[0, 0x2000000]]}

graphs:
  test_unary_hq:
    target_device: 0
    input_count: 32
    unary_hq: {type: nop, grid_loc: [0, 0], grid_size: [3, 2], inputs: [in_hq], in_df: [Float16_b], acc_df: Float16_b, out_df: Float16_b, intermed_df: Float16_b, ublock_order: r, buf_size_mb: 2, math_fidelity: LoFi, untilize_output: false, t: 1, mblock: [1, 1], ublock: [2, 4]}

  test_unary_hq2:
    target_device: 0
    input_count: 32
    unary_hq2: {type: nop, grid_loc: [0, 0], grid_size: [1, 1], inputs: [e2e_hq], in_df: [Float16_b], acc_df: Float16_b, out_df: Float16_b, intermed_df: Float16_b, ublock_order: r, buf_size_mb: 2, math_fidelity: LoFi, untilize_output: false, t: 1, mblock: [3, 2], ublock: [2, 4]}

  test_unary_dq:
    target_device: 0
    input_count: 32
    unary_dq: {type: nop, grid_loc: [0, 0], grid_size: [2, 2], inputs: [in_dq], in_df: [Float16_b], acc_df: Float16_b, out_df: Float16_b, intermed_df: Float16_b, ublock_order: r, buf_size_mb: 2, math_fidelity: LoFi, untilize_output: false, t: 1, mblock: [1, 1], ublock: [2, 4]}

  test_unary_dq2:
    target_device: 0
    input_count: 32
    unary_dq2: {type: nop, grid_loc: [2, 2], grid_size: [1, 1], inputs: [e2e_dq], in_df: [Float16_b], acc_df: Float16_b, out_df: Float16_b, intermed_df: Float16_b, ublock_order: r, buf_size_mb: 2, math_fidelity: LoFi, untilize_output: false, t: 1, mblock: [2, 2], ublock: [2, 4]}

programs:
  - program_unary:
      - param: [$p_loop_count]
      - var: {$c_input_count: 32, $c_input_wrap: 256}
      - staticvar: {$lptr: 0, $gptr: 0}
      - loop: $p_loop_count
      - execute: {graph_name: test_unary_hq, queue_settings: {
          in_hq:  {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr}}}
      - execute: {graph_name: test_unary_hq2, queue_settings: {
          e2e_hq: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr}}}
      - execute: {graph_name: test_unary_dq, queue_settings: {
          in_dq:  {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr}}}
      - execute: {graph_name: test_unary_dq2, queue_settings: {
          e2e_dq: {prologue: false, epilogue: false, zero: false, rd_ptr_local: $lptr, rd_ptr_global: $gptr}}}
      - varinst: [$lptr, incwrap, $c_input_count, $c_input_wrap] # incr ptr by input_count
      - varinst: [$gptr, incwrap, $c_input_count, $c_input_wrap] # incr ptr by input_count
      - endloop 

test-config:
  comparison-config:
    type: AllCloseHw
    atol: 0.01
    rtol: 0.15
    check_pct: 0.99
    check_pcc: 0.99
    verbosity: Concise
  stimulus-config:
    type: Uniform
    uniform_lower_bound: -1.0
    uniform_upper_bound: 1.0
  io-config:
    inputs: [in_hq, in_dq]
    outputs: [copy_from_hq, copy_from_dq]
  test-args:
    microbatch_count: 4
